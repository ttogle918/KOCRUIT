from fastapi import FastAPI, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
import uvicorn
import asyncio
import time
from starlette.middleware.base import BaseHTTPMiddleware

from app.core.config import settings
from app.api.v1.api import api_router
from app.core.database import engine, Base
try:
    from apscheduler.schedulers.background import BackgroundScheduler
except ImportError:
    print("âš ï¸ APScheduler not available, using fallback")
    BackgroundScheduler = None
from app.core.database import SessionLocal
from app.models.interview_evaluation import auto_process_applications
from sqlalchemy import text, inspect
import logging

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[logging.StreamHandler()]
)
from app.scheduler.job_status_scheduler import JobStatusScheduler
from app.scheduler.question_generation_scheduler import QuestionGenerationScheduler

def safe_create_tables():
    """ì•ˆì „í•œ í…Œì´ë¸” ìƒì„± - ê¸°ì¡´ í…Œì´ë¸”ì€ ê±´ë“œë¦¬ì§€ ì•Šê³  ìƒˆë¡œìš´ í…Œì´ë¸”ë§Œ ìƒì„±"""
    try:
        inspector = inspect(engine)
        existing_tables = inspector.get_table_names()
        
        # ìƒˆë¡œìš´ í…Œì´ë¸”ë“¤ë§Œ ìƒì„±
        new_tables = [
            'interview_evaluation_item'  # ìƒˆë¡œ ì¶”ê°€ëœ í…Œì´ë¸”
        ]
        
        for table_name in new_tables:
            if table_name not in existing_tables:
                print(f"Creating new table: {table_name}")
                # í•´ë‹¹ í…Œì´ë¸”ë§Œ ìƒì„±
                table = Base.metadata.tables.get(table_name)
                if table:
                    table.create(bind=engine, checkfirst=True)
                    print(f"âœ… Table {table_name} created successfully")
                else:
                    print(f"âš ï¸ Table {table_name} not found in metadata")
            else:
                print(f"âœ… Table {table_name} already exists")
        
        # ê¸°ì¡´ í…Œì´ë¸”ì— ìƒˆë¡œìš´ ì»¬ëŸ¼ ì¶”ê°€ (í•„ìš”í•œ ê²½ìš°)
        try:
            # interview_evaluation í…Œì´ë¸”ì— updated_at ì»¬ëŸ¼ ì¶”ê°€
            with engine.connect() as conn:
                result = conn.execute(text("SHOW COLUMNS FROM interview_evaluation LIKE 'updated_at'"))
                if not result.fetchone():
                    print("Adding updated_at column to interview_evaluation table")
                    conn.execute(text("ALTER TABLE interview_evaluation ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP"))
                    conn.commit()
                    print("âœ… updated_at column added successfully")
                else:
                    print("âœ… updated_at column already exists")
        except Exception as e:
            print(f"âš ï¸ Column update check failed: {e}")
            
    except Exception as e:
        print(f"âŒ Safe table creation failed: {e}")
# safe_create_tables í•¨ìˆ˜ ì œê±° - Base.metadata.create_all()ì´ ëª¨ë“  í…Œì´ë¸”ì„ ì•ˆì „í•˜ê²Œ ìƒì„±í•¨
from app.models.interview_evaluation import auto_process_applications
from app.models.interview_question import InterviewQuestion, QuestionType


# JobPost ìƒíƒœ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
from app.scheduler.job_status_scheduler import JobStatusScheduler
job_status_scheduler = JobStatusScheduler()

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("=== FastAPI ì„œë²„ ì‹œì‘ ===")
    
    # Startup
    print("ğŸš€ Starting application...")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸ ë° í…Œì´ë¸” ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œë„ {attempt + 1}/{max_retries}...")
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸ - ë‹¨ìˆœí™”
            with engine.connect() as connection:
                connection.execute(text("SELECT 1"))
                print("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!")
            
            # í…Œì´ë¸” ìƒì„±
            Base.metadata.create_all(bind=engine)
            print("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            break
            
        except Exception as e:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                print(f"{retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
                await asyncio.sleep(retry_delay)
                retry_delay *= 2  # ì§€ìˆ˜ ë°±ì˜¤í”„
            else:
                print("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                raise e
    
    # JobPost ìƒíƒœ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    print("ğŸ”„ Starting JobPost status scheduler...")
    asyncio.create_task(job_status_scheduler.start())
    print("JobPost ìƒíƒœ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ")

    # ì‹œë“œ ë°ì´í„° ì‹¤í–‰
    try:
        import subprocess
        import os
        
        # 2_seed_data.py íŒŒì¼ì´ ìˆìœ¼ë©´ ì‹¤í–‰
        seed_script_path = "/docker-entrypoint-initdb.d/2_seed_data.py"
        if os.path.exists(seed_script_path):
            print("ì‹œë“œ ë°ì´í„° ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
            result = subprocess.run(["python3", seed_script_path], 
                                  capture_output=True, text=True, check=True)
            print("ì‹œë“œ ë°ì´í„° ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ!")
            if result.stdout:
                print("ì¶œë ¥:", result.stdout)
        else:
            print("ì‹œë“œ ë°ì´í„° ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"ì‹œë“œ ë°ì´í„° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ì„œë²„ ì‹œì‘ ì‹œ ì¦‰ì‹œ AI í‰ê°€ ì‹¤í–‰ (ì„ì‹œ ë¹„í™œì„±í™”)
    print("=== AI í‰ê°€ ì‹¤í–‰ ì‹œì‘ ===")
    try:
        print("ì„œë²„ ì‹œì‘ ì‹œ AI í‰ê°€ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        # run_auto_process()  # ì„ì‹œë¡œ ë¹„í™œì„±í™” - final_status ë°ì´í„° ë³´í˜¸
        print("AI í‰ê°€ ì‹¤í–‰ ì™„ë£Œ! (ë¹„í™œì„±í™”ë¨)")
    except Exception as e:
        print(f"AI í‰ê°€ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

    print("=== FastAPI ì„œë²„ ì‹œì‘ ì™„ë£Œ ===")
    
    yield
    
    # Shutdown
    print("ğŸ”„ Stopping JobPost status scheduler...")
    await job_status_scheduler.stop()
    print("JobPost ìƒíƒœ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ ì™„ë£Œ")


app = FastAPI(
    title="KOSA Recruit API",
    description="Team project for FastAPI",
    version="1.0.0",
    lifespan=lifespan
)

# Static files (interview videos ë“±) ì œê³µ - ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
import os
if os.path.exists("app/scripts/interview_videos"):
    app.mount(
        "/static/interview_videos",
        StaticFiles(directory="app/scripts/interview_videos"),
        name="interview_videos"
    )
else:
    print("âš ï¸ interview_videos ë””ë ‰í† ë¦¬ê°€ ì—†ì–´ì„œ StaticFiles ë§ˆìš´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

# FastAPI ë“±ë¡ëœ ê²½ë¡œ ëª©ë¡ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
@app.on_event("startup")
async def print_routes():
    print("=== FastAPI ë“±ë¡ëœ ê²½ë¡œ ëª©ë¡ ===")
    for route in app.routes:
        try:
            # íƒ€ì… ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ë¼ìš°íŠ¸ ì •ë³´ ì¶œë ¥
            route_info = str(route)
            if hasattr(route, 'path'):
                path = getattr(route, 'path', 'N/A')
                methods = getattr(route, 'methods', set())
                print(f"{path} - {methods}")
            else:
                print(f"Route: {type(route).__name__}")
        except Exception as e:
            print(f"Route info error: {e}")

# ë¸Œë¼ìš°ì € ìºì‹± ë¯¸ë“¤ì›¨ì–´
class CacheMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        
        # GET ìš”ì²­ì— ëŒ€í•´ì„œë§Œ ìºì‹± ì ìš©
        if request.method == "GET":
            # API ì—”ë“œí¬ì¸íŠ¸ë³„ ìºì‹œ ì„¤ì •
            path = request.url.path
            
            if "/api/v1/applications/" in path:
                # ì§€ì›ì ê´€ë ¨ API: 5ë¶„ ìºì‹œ
                response.headers["Cache-Control"] = "public, max-age=300"
            elif "/api/v1/resumes/" in path:
                # ì´ë ¥ì„œ ê´€ë ¨ API: 5ë¶„ ìºì‹œ
                response.headers["Cache-Control"] = "public, max-age=300"
            elif "/api/v1/company/jobposts/" in path:
                # ì±„ìš©ê³µê³  ê´€ë ¨ API: 5ë¶„ ìºì‹œ
                response.headers["Cache-Control"] = "public, max-age=300"
            elif "/api/v1/interview-questions/" in path:
                # ë©´ì ‘ ì§ˆë¬¸ API: 30ë¶„ ìºì‹œ (LLM ê²°ê³¼)
                response.headers["Cache-Control"] = "public, max-age=1800"
            else:
                # ê¸°ë³¸: 1ë¶„ ìºì‹œ
                response.headers["Cache-Control"] = "public, max-age=60"
        
        return response

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173", 
        "http://localhost:3000",
        "http://127.0.0.1:5173",
        "http://127.0.0.1:3000",
        "http://kocruit_react:5173",
        "http://frontend:5173"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# ë¸Œë¼ìš°ì € ìºì‹± ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(CacheMiddleware)

# API ë¼ìš°í„° ë“±ë¡
#app.include_router(api_router)
app.include_router(api_router, prefix="/api/v1")

# í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "message": "Kocruit API is running"}

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": "Welcome to Kocruit API"}

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì—”ë“œí¬ì¸íŠ¸
@app.get("/performance")
async def performance_info():
    """ì„±ëŠ¥ ì •ë³´ ì—”ë“œí¬ì¸íŠ¸"""
    from app.core.database import get_connection_info
    from app.core.cache import get_cache_stats
    from app.utils.llm_cache import get_cache_stats as llm_cache_stats
    
    try:
        db_info = get_connection_info()
        cache_stats = llm_cache_stats()
        
        return {
            "database": db_info,
            "cache": cache_stats,
            "timestamp": time.time()
        }
        cache_info = get_cache_stats()
        
        return {
            "database": db_info,
            "cache": cache_info,
            "timestamp": time.time()
        }
    except Exception as e:
        return {"error": str(e)}

def run_auto_process():
    print("run_auto_process called") 
    """ìë™ ì²˜ë¦¬ í•¨ìˆ˜"""
    db = SessionLocal()
    try:
        # ê¸°ì¡´ ìë™ ì²˜ë¦¬
        auto_process_applications(db)
        
        # AI í‰ê°€ ë°°ì¹˜ í”„ë¡œì„¸ìŠ¤ ì¶”ê°€ (ì„ì‹œ ë¹„í™œì„±í™”)
        # auto_evaluate_all_applications(db)  # final_status ë°ì´í„° ë³´í˜¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”
        
        print("ìë™ ì²˜ë¦¬ ì™„ë£Œ")
    except Exception as e:
        print(f"ìë™ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        db.close()

# APScheduler ë“±ë¡ (ì˜ˆ: 10ë¶„ë§ˆë‹¤ ì‹¤í–‰)
if BackgroundScheduler:
    scheduler = BackgroundScheduler()
    scheduler.add_job(run_auto_process, 'interval', minutes=10)
    scheduler.start()
    print("âœ… APScheduler started successfully")
else:
    print("âš ï¸ APScheduler not available, skipping scheduled jobs")


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    ) 