from fastapi import FastAPI, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
import uvicorn
import asyncio
import time
from starlette.middleware.base import BaseHTTPMiddleware

from app.core.config import settings
from app.api.v1.api import api_router
from app.core.database import engine, Base

try:
    from apscheduler.schedulers.background import BackgroundScheduler
except ImportError:
    print("‚ö†Ô∏è APScheduler not available, using fallback")
    BackgroundScheduler = None
from app.core.database import SessionLocal
# from app.models.interview_evaluation import auto_process_applications # <- Ï†úÍ±∞
from sqlalchemy import text, inspect
import logging

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[logging.StreamHandler()]
)
from app.scheduler.job_status_scheduler import JobStatusScheduler
from app.scheduler.question_generation_scheduler import QuestionGenerationScheduler

def safe_create_tables():
    """ÏïàÏ†ÑÌïú ÌÖåÏù¥Î∏î ÏÉùÏÑ± - Í∏∞Ï°¥ ÌÖåÏù¥Î∏îÏùÄ Í±¥ÎìúÎ¶¨ÏßÄ ÏïäÍ≥† ÏÉàÎ°úÏö¥ ÌÖåÏù¥Î∏îÎßå ÏÉùÏÑ±"""
    try:
        inspector = inspect(engine)
        existing_tables = inspector.get_table_names()
        
        # ÏÉàÎ°úÏö¥ ÌÖåÏù¥Î∏îÎì§Îßå ÏÉùÏÑ±
        new_tables = [
            'interview_evaluation_item'  # ÏÉàÎ°ú Ï∂îÍ∞ÄÎêú ÌÖåÏù¥Î∏î
        ]
        
        for table_name in new_tables:
            if table_name not in existing_tables:
                print(f"Creating new table: {table_name}")
                # Ìï¥Îãπ ÌÖåÏù¥Î∏îÎßå ÏÉùÏÑ±
                table = Base.metadata.tables.get(table_name)
                if table:
                    table.create(bind=engine, checkfirst=True)
                    print(f"‚úÖ Table {table_name} created successfully")
                else:
                    print(f"‚ö†Ô∏è Table {table_name} not found in metadata")
            else:
                print(f"‚úÖ Table {table_name} already exists")
        
        # Í∏∞Ï°¥ ÌÖåÏù¥Î∏îÏóê ÏÉàÎ°úÏö¥ Ïª¨Îüº Ï∂îÍ∞Ä (ÌïÑÏöîÌïú Í≤ΩÏö∞)
        try:
            # interview_evaluation ÌÖåÏù¥Î∏îÏóê updated_at Ïª¨Îüº Ï∂îÍ∞Ä
            with engine.connect() as conn:
                result = conn.execute(text("SHOW COLUMNS FROM interview_evaluation LIKE 'updated_at'"))
                if not result.fetchone():
                    print("Adding updated_at column to interview_evaluation table")
                    conn.execute(text("ALTER TABLE interview_evaluation ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP"))
                    conn.commit()
                    print("‚úÖ updated_at column added successfully")
                else:
                    print("‚úÖ updated_at column already exists")
        except Exception as e:
            print(f"‚ö†Ô∏è Column update check failed: {e}")
            
    except Exception as e:
        print(f"‚ùå Safe table creation failed: {e}")
from app.services.application_evaluation_service import auto_evaluate_all_applications
# safe_create_tables Ìï®Ïàò Ï†úÍ±∞ - Base.metadata.create_all()Ïù¥ Î™®Îì† ÌÖåÏù¥Î∏îÏùÑ ÏïàÏ†ÑÌïòÍ≤å ÏÉùÏÑ±Ìï®
from app.models.interview_evaluation import auto_process_applications, auto_evaluate_all_applications
from app.models.interview_question import InterviewQuestion, QuestionType


# JobPost ÏÉÅÌÉú Ïä§ÏºÄÏ§ÑÎü¨ Ïù∏Ïä§ÌÑ¥Ïä§ (Ïã±Í∏ÄÌÜ§)
from app.scheduler.job_status_scheduler import JobStatusScheduler
job_status_scheduler = JobStatusScheduler()

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("=== FastAPI ÏÑúÎ≤Ñ ÏãúÏûë ===")
    
    # Startup
    print("üöÄ Starting application...")
    
    # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ ÌôïÏù∏ Î∞è ÌÖåÏù¥Î∏î ÏÉùÏÑ± (Ïû¨ÏãúÎèÑ Î°úÏßÅ Ìè¨Ìï®)
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            print(f"Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ ÏãúÎèÑ {attempt + 1}/{max_retries}...")
            
            # Ïó∞Í≤∞ ÌÖåÏä§Ìä∏ - Îã®ÏàúÌôî
            with engine.connect() as connection:
                connection.execute(text("SELECT 1"))
                print("Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ ÏÑ±Í≥µ!")
            
            # ÌÖåÏù¥Î∏î ÏÉùÏÑ±
            Base.metadata.create_all(bind=engine)
            print("Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÖåÏù¥Î∏î ÏÉùÏÑ± ÏôÑÎ£å")
            break
            
        except Exception as e:
            print(f"Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Ïã§Ìå® (ÏãúÎèÑ {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                print(f"{retry_delay}Ï¥à ÌõÑ Ïû¨ÏãúÎèÑ...")
                await asyncio.sleep(retry_delay)
                retry_delay *= 2  # ÏßÄÏàò Î∞±Ïò§ÌîÑ
            else:
                print("ÏµúÎåÄ Ïû¨ÏãúÎèÑ ÌöüÏàò Ï¥àÍ≥º. Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖòÏùÑ Ï¢ÖÎ£åÌï©ÎãàÎã§.")
                raise e
    
    # JobPost ÏÉÅÌÉú Ïä§ÏºÄÏ§ÑÎü¨ ÏãúÏûë
    print("üîÑ Starting JobPost status scheduler...")
    asyncio.create_task(job_status_scheduler.start())
    print("JobPost ÏÉÅÌÉú Ïä§ÏºÄÏ§ÑÎü¨ ÏãúÏûë ÏôÑÎ£å")

    # ÏãúÎìú Îç∞Ïù¥ÌÑ∞ Ïã§Ìñâ
    try:
        import subprocess
        import os
        
        # 2_seed_data.py ÌååÏùºÏù¥ ÏûàÏúºÎ©¥ Ïã§Ìñâ
        seed_script_path = "/docker-entrypoint-initdb.d/2_seed_data.py"
        if os.path.exists(seed_script_path):
            print("ÏãúÎìú Îç∞Ïù¥ÌÑ∞ Ïä§ÌÅ¨Î¶ΩÌä∏Î•º Ïã§ÌñâÌï©ÎãàÎã§...")
            result = subprocess.run(["python3", seed_script_path], 
                                  capture_output=True, text=True, check=True)
            print("ÏãúÎìú Îç∞Ïù¥ÌÑ∞ Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ ÏôÑÎ£å!")
            if result.stdout:
                print("Ï∂úÎ†•:", result.stdout)
        else:
            print("ÏãúÎìú Îç∞Ïù¥ÌÑ∞ Ïä§ÌÅ¨Î¶ΩÌä∏Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
            
    except Exception as e:
        print(f"ÏãúÎìú Îç∞Ïù¥ÌÑ∞ Ïã§Ìñâ Ï§ë Ïò§Î•ò: {e}")
    
    # ÏÑúÎ≤Ñ ÏãúÏûë Ïãú Ï¶âÏãú AI ÌèâÍ∞Ä Ïã§Ìñâ
    print("=== AI ÌèâÍ∞Ä Ïã§Ìñâ ÏãúÏûë ===")
    try:
        print("ÏÑúÎ≤Ñ ÏãúÏûë Ïãú AI ÌèâÍ∞ÄÎ•º Ïã§ÌñâÌï©ÎãàÎã§...")
        # run_auto_process()  # ÏûÑÏãúÎ°ú ÎπÑÌôúÏÑ±Ìôî
        print("AI ÌèâÍ∞Ä Ïã§Ìñâ ÏôÑÎ£å!")
    except Exception as e:
        print(f"AI ÌèâÍ∞Ä Ïã§Ìñâ Ï§ë Ïò§Î•ò: {e}")
        import traceback
        print(f"ÏÉÅÏÑ∏ Ïò§Î•ò: {traceback.format_exc()}")

    print("=== FastAPI ÏÑúÎ≤Ñ ÏãúÏûë ÏôÑÎ£å ===")
    
    yield
    
    # Shutdown
    print("üîÑ Stopping JobPost status scheduler...")
    await job_status_scheduler.stop()
    print("JobPost ÏÉÅÌÉú Ïä§ÏºÄÏ§ÑÎü¨ Ï§ëÏßÄ ÏôÑÎ£å")


app = FastAPI(
    title="KOSA Recruit API",
    description="Team project for FastAPI",
    version="1.0.0",
    lifespan=lifespan
)

# Static files (interview videos Îì±) Ï†úÍ≥µ - ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏúºÎ©¥ Í±¥ÎÑàÎõ∞Í∏∞
import os
if os.path.exists("app/scripts/interview_videos"):
    app.mount(
        "/static/interview_videos",
        StaticFiles(directory="app/scripts/interview_videos"),
        name="interview_videos"
    )
else:
    print("‚ö†Ô∏è interview_videos ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏñ¥ÏÑú StaticFiles ÎßàÏö¥Ìä∏Î•º Í±¥ÎÑàÎúÅÎãàÎã§.")

# FastAPI Îì±Î°ùÎêú Í≤ΩÎ°ú Î™©Î°ù Ï∂úÎ†• (ÎîîÎ≤ÑÍπÖÏö©)
@app.on_event("startup")
async def print_routes():
    print("=== FastAPI Îì±Î°ùÎêú Í≤ΩÎ°ú Î™©Î°ù ===")
    for route in app.routes:
        try:
            # ÌÉÄÏûÖ ÏïàÏ†ÑÌïú Î∞©ÏãùÏúºÎ°ú ÎùºÏö∞Ìä∏ Ï†ïÎ≥¥ Ï∂úÎ†•
            route_info = str(route)
            if hasattr(route, 'path'):
                path = getattr(route, 'path', 'N/A')
                methods = getattr(route, 'methods', set())
                print(f"{path} - {methods}")
            else:
                print(f"Route: {type(route).__name__}")
        except Exception as e:
            print(f"Route info error: {e}")

# Î∏åÎùºÏö∞Ï†Ä Ï∫êÏã± ÎØ∏Îì§Ïõ®Ïñ¥
class CacheMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        
        # GET ÏöîÏ≤≠Ïóê ÎåÄÌï¥ÏÑúÎßå Ï∫êÏã± Ï†ÅÏö©
        if request.method == "GET":
            # API ÏóîÎìúÌè¨Ïù∏Ìä∏Î≥Ñ Ï∫êÏãú ÏÑ§Ï†ï
            path = request.url.path
            
            if "/api/v1/applications/" in path:
                # ÏßÄÏõêÏûê Í¥ÄÎ†® API: 5Î∂Ñ Ï∫êÏãú
                response.headers["Cache-Control"] = "public, max-age=300"
            elif "/api/v1/resumes/" in path:
                # Ïù¥Î†•ÏÑú Í¥ÄÎ†® API: 5Î∂Ñ Ï∫êÏãú
                response.headers["Cache-Control"] = "public, max-age=300"
            elif "/api/v1/company/jobposts/" in path:
                # Ï±ÑÏö©Í≥µÍ≥† Í¥ÄÎ†® API: 5Î∂Ñ Ï∫êÏãú
                response.headers["Cache-Control"] = "public, max-age=300"
            elif "/api/v1/interview-questions/" in path:
                # Î©¥Ï†ë ÏßàÎ¨∏ API: 30Î∂Ñ Ï∫êÏãú (LLM Í≤∞Í≥º)
                response.headers["Cache-Control"] = "public, max-age=1800"
            else:
                # Í∏∞Î≥∏: 1Î∂Ñ Ï∫êÏãú
                response.headers["Cache-Control"] = "public, max-age=60"
        
        return response

# CORS ÏÑ§Ï†ï
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173", 
        "http://localhost:3000",
        "http://127.0.0.1:5173",
        "http://127.0.0.1:3000",
        "http://kocruit_react:5173",
        "http://frontend:5173"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# Î∏åÎùºÏö∞Ï†Ä Ï∫êÏã± ÎØ∏Îì§Ïõ®Ïñ¥ Ï∂îÍ∞Ä
app.add_middleware(CacheMiddleware)

# API ÎùºÏö∞ÌÑ∞ Îì±Î°ù
#app.include_router(api_router)
app.include_router(api_router, prefix="/api/v1")

# Ìó¨Ïä§Ï≤¥ÌÅ¨ ÏóîÎìúÌè¨Ïù∏Ìä∏
@app.get("/health")
async def health_check():
    """ÏÑúÎ≤Ñ ÏÉÅÌÉú ÌôïÏù∏ ÏóîÎìúÌè¨Ïù∏Ìä∏"""
    return {"status": "healthy", "message": "Kocruit API is running"}

@app.get("/")
async def root():
    """Î£®Ìä∏ ÏóîÎìúÌè¨Ïù∏Ìä∏"""
    return {"message": "Welcome to Kocruit API"}

# ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ ÏóîÎìúÌè¨Ïù∏Ìä∏
@app.get("/performance")
async def performance_info():
    """ÏÑ±Îä• Ï†ïÎ≥¥ ÏóîÎìúÌè¨Ïù∏Ìä∏"""
    from app.core.database import get_connection_info
    from app.core.cache import get_cache_stats
    from app.utils.llm_cache import get_cache_stats as llm_cache_stats
    
    try:
        db_info = get_connection_info()
        cache_stats = llm_cache_stats()
        
        return {
            "database": db_info,
            "cache": cache_stats,
            "timestamp": time.time()
        }
        cache_info = get_cache_stats()
        
        return {
            "database": db_info,
            "cache": cache_info,
            "timestamp": time.time()
        }
    except Exception as e:
        return {"error": str(e)}

def run_auto_process():
    print("run_auto_process called") 
    """ÏûêÎèô Ï≤òÎ¶¨ Ìï®Ïàò"""
    db = SessionLocal()
    try:
        # Í∏∞Ï°¥ ÏûêÎèô Ï≤òÎ¶¨ (auto_process_applications) Ï†úÍ±∞
        # auto_process_applications(db)
        # AI ÌèâÍ∞Ä Î∞∞Ïπò ÌîÑÎ°úÏÑ∏Ïä§Îßå Ïã§Ìñâ
        auto_evaluate_all_applications(db)
        print("ÏûêÎèô Ï≤òÎ¶¨ ÏôÑÎ£å")
    except Exception as e:
        print(f"ÏûêÎèô Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {e}")
    finally:
        db.close()

# APScheduler Îì±Î°ù (Ïòà: 10Î∂ÑÎßàÎã§ Ïã§Ìñâ)
if BackgroundScheduler:
    scheduler = BackgroundScheduler()
    scheduler.add_job(run_auto_process, 'interval', minutes=10)
    scheduler.start()
    print("‚úÖ APScheduler started successfully")
else:
    print("‚ö†Ô∏è APScheduler not available, skipping scheduled jobs")


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    ) 