#!/usr/bin/env python3
"""
AI ë©´ì ‘ í‰ê°€ ì¬ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from app.core.database import get_db
from app.models.job import JobPost
from app.models.application import Application, DocumentStatus, InterviewStatus
from app.models.user import User
from app.models.interview_evaluation import InterviewEvaluation
from app.services.ai_interview_evaluation_service import AiInterviewEvaluationService

def run_ai_interview_evaluation():
    """AI ë©´ì ‘ í‰ê°€ ì¬ì‹¤í–‰"""
    db = next(get_db())
    
    try:
        print("=== AI ë©´ì ‘ í‰ê°€ ì¬ì‹¤í–‰ ===\n")
        
        # ì ìˆ˜ê°€ ì—†ëŠ” AI ë©´ì ‘ í‰ê°€ ì°¾ê¸°
        evaluations_without_score = db.query(InterviewEvaluation).filter(
            InterviewEvaluation.interview_type == 'AI_INTERVIEW',
            InterviewEvaluation.total_score.is_(None)
        ).all()
        
        print(f"ì ìˆ˜ê°€ ì—†ëŠ” AI ë©´ì ‘ í‰ê°€ ìˆ˜: {len(evaluations_without_score)}")
        
        if len(evaluations_without_score) == 0:
            print("âœ… ëª¨ë“  AI ë©´ì ‘ í‰ê°€ì— ì ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤.")
            return
        
        # í‰ê°€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        evaluation_service = AiInterviewEvaluationService()
        
        success_count = 0
        error_count = 0
        
        for evaluation in evaluations_without_score:
            try:
                print(f"ğŸ”„ í‰ê°€ ì¬ì‹¤í–‰ ì¤‘... Application ID: {evaluation.application_id}")
                
                # ì§€ì›ì ì •ë³´ ì¡°íšŒ
                application = db.query(Application).filter(
                    Application.id == evaluation.application_id
                ).first()
                
                if not application:
                    print(f"âŒ Application {evaluation.application_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    error_count += 1
                    continue
                
                # AI ë©´ì ‘ í‰ê°€ ì¬ì‹¤í–‰
                result = evaluation_service.evaluate_ai_interview(
                    application_id=evaluation.application_id,
                    db=db
                )
                
                if result and result.get('total_score') is not None:
                    # í‰ê°€ ì ìˆ˜ ì—…ë°ì´íŠ¸
                    evaluation.total_score = result['total_score']
                    evaluation.technical_score = result.get('technical_score')
                    evaluation.communication_score = result.get('communication_score')
                    evaluation.problem_solving_score = result.get('problem_solving_score')
                    evaluation.cultural_fit_score = result.get('cultural_fit_score')
                    evaluation.evaluation_details = result.get('evaluation_details')
                    
                    # ë©´ì ‘ ìƒíƒœ ì—…ë°ì´íŠ¸
                    if result['total_score'] >= 70:
                        application.interview_status = InterviewStatus.AI_INTERVIEW_PASSED
                    else:
                        application.interview_status = InterviewStatus.AI_INTERVIEW_FAILED
                    
                    db.commit()
                    print(f"âœ… í‰ê°€ ì™„ë£Œ - ì ìˆ˜: {result['total_score']}")
                    success_count += 1
                else:
                    print(f"âŒ í‰ê°€ ì‹¤íŒ¨ - ê²°ê³¼ ì—†ìŒ")
                    error_count += 1
                    
            except Exception as e:
                print(f"âŒ í‰ê°€ ì˜¤ë¥˜: {str(e)}")
                error_count += 1
                db.rollback()
        
        print(f"\n=== í‰ê°€ ì¬ì‹¤í–‰ ì™„ë£Œ ===")
        print(f"âœ… ì„±ê³µ: {success_count}")
        print(f"âŒ ì‹¤íŒ¨: {error_count}")
        
    finally:
        db.close()

def run_evaluation_for_all_applications():
    """ëª¨ë“  ì§€ì›ìì— ëŒ€í•´ AI ë©´ì ‘ í‰ê°€ ì‹¤í–‰"""
    db = next(get_db())
    
    try:
        print("=== ëª¨ë“  ì§€ì›ì AI ë©´ì ‘ í‰ê°€ ì‹¤í–‰ ===\n")
        
        # AI ë©´ì ‘ ì™„ë£Œëœ ì§€ì›ìë“¤ ì¡°íšŒ
        applications = db.query(Application).filter(
            Application.document_status == DocumentStatus.PASSED,
            Application.interview_status.in_([
                InterviewStatus.AI_INTERVIEW_COMPLETED,
                InterviewStatus.AI_INTERVIEW_PASSED,
                InterviewStatus.AI_INTERVIEW_FAILED
            ])
        ).all()
        
        print(f"AI ë©´ì ‘ ì™„ë£Œëœ ì§€ì›ì ìˆ˜: {len(applications)}")
        
        # í‰ê°€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        evaluation_service = AiInterviewEvaluationService()
        
        success_count = 0
        error_count = 0
        
        for application in applications:
            try:
                print(f"ğŸ”„ í‰ê°€ ì‹¤í–‰ ì¤‘... {application.id}")
                
                # AI ë©´ì ‘ í‰ê°€ ì‹¤í–‰
                result = evaluation_service.evaluate_ai_interview(
                    application_id=application.id,
                    db=db
                )
                
                if result and result.get('total_score') is not None:
                    # ê¸°ì¡´ í‰ê°€ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                    existing_evaluation = db.query(InterviewEvaluation).filter(
                        InterviewEvaluation.application_id == application.id,
                        InterviewEvaluation.interview_type == 'AI_INTERVIEW'
                    ).first()
                    
                    if existing_evaluation:
                        existing_evaluation.total_score = result['total_score']
                        existing_evaluation.technical_score = result.get('technical_score')
                        existing_evaluation.communication_score = result.get('communication_score')
                        existing_evaluation.problem_solving_score = result.get('problem_solving_score')
                        existing_evaluation.cultural_fit_score = result.get('cultural_fit_score')
                        existing_evaluation.evaluation_details = result.get('evaluation_details')
                    else:
                        new_evaluation = InterviewEvaluation(
                            application_id=application.id,
                            interview_type='AI_INTERVIEW',
                            total_score=result['total_score'],
                            technical_score=result.get('technical_score'),
                            communication_score=result.get('communication_score'),
                            problem_solving_score=result.get('problem_solving_score'),
                            cultural_fit_score=result.get('cultural_fit_score'),
                            evaluation_details=result.get('evaluation_details')
                        )
                        db.add(new_evaluation)
                    
                    # ë©´ì ‘ ìƒíƒœ ì—…ë°ì´íŠ¸
                    if result['total_score'] >= 70:
                        application.interview_status = InterviewStatus.AI_INTERVIEW_PASSED
                    else:
                        application.interview_status = InterviewStatus.AI_INTERVIEW_FAILED
                    
                    db.commit()
                    print(f"âœ… í‰ê°€ ì™„ë£Œ - ì ìˆ˜: {result['total_score']}")
                    success_count += 1
                else:
                    print(f"âŒ í‰ê°€ ì‹¤íŒ¨ - ê²°ê³¼ ì—†ìŒ")
                    error_count += 1
                    
            except Exception as e:
                print(f"âŒ í‰ê°€ ì˜¤ë¥˜: {str(e)}")
                error_count += 1
                db.rollback()
        
        print(f"\n=== í‰ê°€ ì‹¤í–‰ ì™„ë£Œ ===")
        print(f"âœ… ì„±ê³µ: {success_count}")
        print(f"âŒ ì‹¤íŒ¨: {error_count}")
        
    finally:
        db.close()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='AI ë©´ì ‘ í‰ê°€ ì‹¤í–‰')
    parser.add_argument('--mode', choices=['fix', 'all'], default='fix',
                       help='fix: ì ìˆ˜ ì—†ëŠ” í‰ê°€ë§Œ ìˆ˜ì •, all: ëª¨ë“  ì§€ì›ì í‰ê°€')
    
    args = parser.parse_args()
    
    if args.mode == 'fix':
        run_ai_interview_evaluation()
    else:
        run_evaluation_for_all_applications() 