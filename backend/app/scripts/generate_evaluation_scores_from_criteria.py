#!/usr/bin/env python3
"""
í‰ê°€ ê¸°ì¤€ì— ë§ëŠ” ì‹¤ì œ í‰ê°€ ë°ì´í„°ë¥¼ ëœë¤ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
import random
import json
from datetime import datetime
from typing import List, Dict, Any

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from app.core.database import get_db
from app.models.evaluation_criteria import EvaluationCriteria
from app.models.interview_evaluation import InterviewEvaluation
from app.models.application import Application
from app.models.company_user import CompanyUser

def get_evaluation_criteria_for_job_post(job_post_id: int) -> List[EvaluationCriteria]:
    """íŠ¹ì • ê³µê³ ì˜ í‰ê°€ ê¸°ì¤€ ì¡°íšŒ"""
    db = next(get_db())
    criteria = db.query(EvaluationCriteria).filter(
        EvaluationCriteria.job_post_id == job_post_id
    ).all()
    return criteria

def get_applications_for_job_post(job_post_id: int) -> List[Application]:
    """íŠ¹ì • ê³µê³ ì˜ ì§€ì›ì ëª©ë¡ ì¡°íšŒ"""
    db = next(get_db())
    applications = db.query(Application).filter(
        Application.job_post_id == job_post_id
    ).all()
    return applications

def get_evaluators_by_type(evaluator_type: str) -> List[int]:
    """í‰ê°€ì íƒ€ì…ë³„ ID ëª©ë¡ ì¡°íšŒ"""
    db = next(get_db())
    
    if evaluator_type == "practical":
        # ì‹¤ë¬´ì§„ í‰ê°€ì (3001-3003)
        evaluator_ids = [3001, 3002, 3003]
    elif evaluator_type == "executive":
        # ì„ì›ì§„ í‰ê°€ì (3004-3006)
        evaluator_ids = [3004, 3005, 3006]
    else:
        evaluator_ids = []
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í‰ê°€ìë§Œ í•„í„°ë§
    existing_evaluators = db.query(CompanyUser.id).filter(
        CompanyUser.id.in_(evaluator_ids)
    ).all()
    
    return [e.id for e in existing_evaluators]

def generate_random_score_for_item(item: Dict[str, Any], evaluator_bias: float = 0.0) -> Dict[str, Any]:
    """í‰ê°€ í•­ëª©ë³„ ëœë¤ ì ìˆ˜ ìƒì„±"""
    max_score = item.get('max_score', 10)
    weight = item.get('weight', 1.0)
    
    # í‰ê°€ìë³„ í¸í–¥ ì ìš© (í‰ê°€ìë§ˆë‹¤ ë‹¤ë¥¸ ê¸°ì¤€)
    base_score = random.uniform(6.0, 9.5)  # ê¸°ë³¸ 6-9.5ì 
    adjusted_score = min(max_score, max(0, base_score + evaluator_bias))
    
    # ì†Œìˆ˜ì  1ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼
    final_score = round(adjusted_score, 1)
    
    return {
        "item_name": item.get('item_name', ''),
        "score": final_score,
        "max_score": max_score,
        "weight": weight,
        "weighted_score": round(final_score * weight, 2),
        "comment": generate_random_comment(final_score, item.get('item_name', ''))
    }

def generate_random_comment(score: float, item_name: str) -> str:
    """ì ìˆ˜ì— ë”°ë¥¸ ëœë¤ ì½”ë©˜íŠ¸ ìƒì„±"""
    if score >= 9.0:
        comments = [
            f"{item_name}ì— ëŒ€í•´ ë§¤ìš° ë›°ì–´ë‚œ ì—­ëŸ‰ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
            f"{item_name} ë¶„ì•¼ì—ì„œ íƒì›”í•œ ì‹¤ë ¥ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.",
            f"{item_name}ì— ëŒ€í•œ ê¹Šì€ ì´í•´ì™€ ì‹¤ë¬´ ê²½í—˜ì´ ì¸ìƒì ì…ë‹ˆë‹¤."
        ]
    elif score >= 7.5:
        comments = [
            f"{item_name}ì— ëŒ€í•´ ì¶©ë¶„í•œ ì—­ëŸ‰ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
            f"{item_name} ë¶„ì•¼ì—ì„œ ì ì ˆí•œ ìˆ˜ì¤€ì˜ ì‹¤ë ¥ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.",
            f"{item_name}ì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì´í•´ê°€ ì˜ ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        ]
    elif score >= 6.0:
        comments = [
            f"{item_name}ì— ëŒ€í•´ ë³´í†µ ìˆ˜ì¤€ì˜ ì—­ëŸ‰ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
            f"{item_name} ë¶„ì•¼ì—ì„œ ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.",
            f"{item_name}ì— ëŒ€í•œ ì´í•´ê°€ ë‹¤ì†Œ ë¶€ì¡±í•©ë‹ˆë‹¤."
        ]
    else:
        comments = [
            f"{item_name}ì— ëŒ€í•´ ë¶€ì¡±í•œ ì—­ëŸ‰ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
            f"{item_name} ë¶„ì•¼ì—ì„œ ë§ì€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            f"{item_name}ì— ëŒ€í•œ ì´í•´ê°€ ë§¤ìš° ë¶€ì¡±í•©ë‹ˆë‹¤."
        ]
    
    return random.choice(comments)

def create_evaluation_data(application: Application, criteria: EvaluationCriteria, evaluator_id: int) -> Dict[str, Any]:
    """í‰ê°€ ë°ì´í„° ìƒì„±"""
    evaluation_items = criteria.evaluation_items or []
    
    if not evaluation_items:
        print(f"âš ï¸ {criteria.evaluation_type} ({criteria.interview_stage}) - í‰ê°€ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # í‰ê°€ìë³„ í¸í–¥ ì„¤ì • (í‰ê°€ìë§ˆë‹¤ ë‹¤ë¥¸ ê¸°ì¤€)
    evaluator_biases = {
        3001: 0.2,   # ì‹¤ë¬´ì§„ 1 - ì•½ê°„ ê´€ëŒ€
        3002: -0.1,  # ì‹¤ë¬´ì§„ 2 - ì•½ê°„ ì—„ê²©
        3003: 0.0,   # ì‹¤ë¬´ì§„ 3 - ì¤‘ê°„
        3004: 0.3,   # ì„ì›ì§„ 1 - ê´€ëŒ€
        3005: -0.2,  # ì„ì›ì§„ 2 - ì—„ê²©
        3006: 0.1    # ì„ì›ì§„ 3 - ì•½ê°„ ê´€ëŒ€
    }
    
    evaluator_bias = evaluator_biases.get(evaluator_id, 0.0)
    
    # ê° í‰ê°€ í•­ëª©ë³„ ì ìˆ˜ ìƒì„±
    item_scores = []
    total_weighted_score = 0.0
    total_weight = 0.0
    
    for item in evaluation_items:
        score_data = generate_random_score_for_item(item, evaluator_bias)
        item_scores.append(score_data)
        total_weighted_score += score_data['weighted_score']
        total_weight += item.get('weight', 1.0)
    
    # ì´ì  ê³„ì‚°
    if total_weight > 0:
        total_score = round(total_weighted_score / total_weight, 2)
    else:
        total_score = round(sum(score['score'] for score in item_scores) / len(item_scores), 2)
    
    # ì¢…í•© í‰ê°€ ìƒì„±
    overall_summary = generate_overall_summary(total_score, criteria.interview_stage)
    
    return {
        "application_id": application.id,
        "evaluator_id": evaluator_id,
        "evaluation_type": criteria.interview_stage.upper(),
        "total_score": total_score,
        "evaluation_items": item_scores,
        "summary": overall_summary,
        "status": "completed"
    }

def generate_overall_summary(total_score: float, interview_stage: str) -> str:
    """ì¢…í•© í‰ê°€ ìš”ì•½ ìƒì„±"""
    stage_name = "ì‹¤ë¬´ì§„" if interview_stage == "practical" else "ì„ì›ì§„"
    
    if total_score >= 9.0:
        return f"{stage_name} ë©´ì ‘ì—ì„œ ë§¤ìš° ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ëª¨ë“  í‰ê°€ í•­ëª©ì—ì„œ ë›°ì–´ë‚œ ì—­ëŸ‰ì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, í•´ë‹¹ ì§ë¬´ì— ë§¤ìš° ì í•©í•œ ì¸ì¬ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."
    elif total_score >= 7.5:
        return f"{stage_name} ë©´ì ‘ì—ì„œ ì–‘í˜¸í•œ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ í‰ê°€ í•­ëª©ì—ì„œ ì¶©ë¶„í•œ ì—­ëŸ‰ì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, í•´ë‹¹ ì§ë¬´ì— ì í•©í•œ ì¸ì¬ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."
    elif total_score >= 6.0:
        return f"{stage_name} ë©´ì ‘ì—ì„œ ë³´í†µ ìˆ˜ì¤€ì˜ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì¼ë¶€ í‰ê°€ í•­ëª©ì—ì„œ ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆìœ¼ë‚˜, ì „ë°˜ì ìœ¼ë¡œ ì ì ˆí•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
    else:
        return f"{stage_name} ë©´ì ‘ì—ì„œ ë¶€ì¡±í•œ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ í‰ê°€ í•­ëª©ì—ì„œ ê°œì„ ì´ í•„ìš”í•˜ë©°, í•´ë‹¹ ì§ë¬´ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ì—­ëŸ‰ ê°œë°œì´ í•„ìš”í•©ë‹ˆë‹¤."

def save_evaluation_to_db(evaluation_data: Dict[str, Any]) -> bool:
    """í‰ê°€ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        db = next(get_db())
        
        # ê¸°ì¡´ í‰ê°€ ë°ì´í„° í™•ì¸
        existing = db.query(InterviewEvaluation).filter(
            InterviewEvaluation.application_id == evaluation_data['application_id'],
            InterviewEvaluation.evaluator_id == evaluation_data['evaluator_id'],
            InterviewEvaluation.evaluation_type == evaluation_data['evaluation_type']
        ).first()
        
        if existing:
            print(f"  â­ï¸ ì´ë¯¸ í‰ê°€ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return False
        
        # ìƒˆë¡œìš´ í‰ê°€ ë°ì´í„° ìƒì„±
        new_evaluation = InterviewEvaluation(
            application_id=evaluation_data['application_id'],
            evaluator_id=evaluation_data['evaluator_id'],
            is_ai=False,
            evaluation_type=evaluation_data['evaluation_type'],
            total_score=evaluation_data['total_score'],
            score=evaluation_data['total_score'],  # í˜¸í™˜ì„±ì„ ìœ„í•´
            summary=evaluation_data['summary'],
            status=evaluation_data['status']
        )
        
        db.add(new_evaluation)
        db.commit()
        
        print(f"  âœ… í‰ê°€ì {evaluation_data['evaluator_id']}: {evaluation_data['total_score']}ì ")
        return True
        
    except Exception as e:
        print(f"  âŒ í‰ê°€ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        db.rollback()
        return False

def generate_evaluation_scores_for_job_post(job_post_id: int):
    """íŠ¹ì • ê³µê³ ì˜ ëª¨ë“  ì§€ì›ìì— ëŒ€í•´ í‰ê°€ ì ìˆ˜ ìƒì„±"""
    print(f"ğŸ¯ Job Post {job_post_id}ì˜ í‰ê°€ ì ìˆ˜ ìƒì„± ì‹œì‘")
    
    # í‰ê°€ ê¸°ì¤€ ì¡°íšŒ
    criteria_list = get_evaluation_criteria_for_job_post(job_post_id)
    if not criteria_list:
        print(f"âŒ Job Post {job_post_id}ì— ëŒ€í•œ í‰ê°€ ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì§€ì›ì ëª©ë¡ ì¡°íšŒ
    applications = get_applications_for_job_post(job_post_id)
    if not applications:
        print(f"âŒ Job Post {job_post_id}ì— ëŒ€í•œ ì§€ì›ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š í‰ê°€ ê¸°ì¤€: {len(criteria_list)}ê°œ, ì§€ì›ì: {len(applications)}ëª…")
    
    # í‰ê°€ ê¸°ì¤€ë³„ë¡œ ì²˜ë¦¬
    for criteria in criteria_list:
        print(f"\nğŸ” {criteria.evaluation_type} ({criteria.interview_stage}) í‰ê°€ ê¸°ì¤€ ì²˜ë¦¬ ì¤‘...")
        
        # í‰ê°€ì ëª©ë¡ ì¡°íšŒ
        evaluators = get_evaluators_by_type(criteria.interview_stage)
        if not evaluators:
            print(f"  âš ï¸ {criteria.interview_stage} í‰ê°€ìê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        print(f"  ğŸ‘¥ í‰ê°€ì: {evaluators}")
        
        # ê° ì§€ì›ìì— ëŒ€í•´ í‰ê°€ ë°ì´í„° ìƒì„±
        for application in applications:
            print(f"\n  ğŸ‘¤ ì§€ì›ì {application.id} ({application.applicant_user.name if application.applicant_user else 'Unknown'})")
            
            # ê° í‰ê°€ìë³„ë¡œ í‰ê°€ ë°ì´í„° ìƒì„±
            for evaluator_id in evaluators:
                evaluation_data = create_evaluation_data(application, criteria, evaluator_id)
                
                if evaluation_data:
                    save_evaluation_to_db(evaluation_data)
    
    print(f"\nâœ… Job Post {job_post_id}ì˜ í‰ê°€ ì ìˆ˜ ìƒì„± ì™„ë£Œ!")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python generate_evaluation_scores_from_criteria.py <job_post_id>")
        print("ì˜ˆì‹œ: python generate_evaluation_scores_from_criteria.py 17")
        return
    
    try:
        job_post_id = int(sys.argv[1])
        generate_evaluation_scores_for_job_post(job_post_id)
        
    except ValueError:
        print("âŒ job_post_idëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main() 