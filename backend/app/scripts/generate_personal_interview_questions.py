#!/usr/bin/env python3
"""
ì‹¤ë¬´ì§„ ë©´ì ‘ìš© ê°œì¸ë³„ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
sys.path.append('/app')

from app.core.database import SessionLocal
from app.models.job import JobPost
from app.models.application import Application
from app.models.interview_question import InterviewQuestion, QuestionType
from app.api.v1.interview_question import parse_job_post_data

def generate_personal_interview_questions():
    """ì‹¤ë¬´ì§„ ë©´ì ‘ìš© ê°œì¸ë³„ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± (application_id, resume ê¸°ë°˜)"""
    db = SessionLocal()
    try:
        # ê³µê³  17 ì¡°íšŒ
        job = db.query(JobPost).filter(JobPost.id == 17).first()
        if not job:
            print("JobPost 17 not found")
            return
        
        print(f"JobPost 17: {job.title}")
        
        # ê³µê³  ì •ë³´ íŒŒì‹±
        company_name = job.company.name if job.company else "KOSAê³µê³µ"
        job_info = parse_job_post_data(job)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° import
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), 'agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ëª¨ë“  ì§€ì›ì ì¡°íšŒ
        applications = db.query(Application).filter(Application.job_post_id == 17).all()
        print(f"ì´ {len(applications)}ëª…ì˜ ì§€ì›ìì— ëŒ€í•œ ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±")
        
        total_questions = 0
        
        # ê° ì§€ì›ìì— ëŒ€í•´ ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±
        for app in applications:
            try:
                print(f"\nğŸ”„ ì§€ì›ì {app.id}ì— ëŒ€í•œ ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì¤‘...")
                
                # ì§€ì›ìì˜ ì´ë ¥ì„œ ì •ë³´ ì¡°íšŒ
                resume_text = ""
                if app.resume_id:
                    from app.models.resume import Resume
                    resume = db.query(Resume).filter(Resume.id == app.resume_id).first()
                    if resume and resume.content:
                        resume_text = resume.content
                        print(f"  ğŸ“„ ì´ë ¥ì„œ ë‚´ìš© ê¸¸ì´: {len(resume_text)}ì")
                    else:
                        print(f"  âš ï¸ ì´ë ¥ì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. (resume_id: {app.resume_id})")
                else:
                    print(f"  âš ï¸ ì´ë ¥ì„œ IDê°€ ì—†ìŠµë‹ˆë‹¤. (application_id: {app.id})")
                
                # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ì‹¤ë¬´ì§„ ë©´ì ‘ìš©)
                workflow_result = generate_comprehensive_interview_questions(
                    resume_text=resume_text,
                    job_info=job_info,
                    company_name=company_name,
                    applicant_name="ì§€ì›ì",
                    interview_type="general"  # ì‹¤ë¬´ì§„ ë©´ì ‘ìš©
                )
                
                # ê²°ê³¼ì—ì„œ ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ì¶”ì¶œ
                question_bundle = workflow_result.get("question_bundle", {})
                print(f"  ğŸ” LangGraph ê²°ê³¼: {list(question_bundle.keys())}")
                
                # ì§ˆë¬¸ ê°œìˆ˜ ê³„ì‚° ë° ì €ì¥
                questions_count = 0
                
                # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (ë°±ì—…ìš©)
                import json
                import os
                from datetime import datetime
                
                backup_data = {
                    "application_id": app.id,
                    "resume_id": app.resume_id,
                    "job_post_id": job.id,
                    "company_name": company_name,
                    "resume_text_length": len(resume_text),
                    "generated_at": datetime.now().isoformat(),
                    "question_bundle": question_bundle,
                    "resume_summary": workflow_result.get("resume_summary", ""),
                    "analysis_data": workflow_result.get("analysis_data", {})
                }
                
                # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
                backup_dir = "/app/backup_interview_questions"
                os.makedirs(backup_dir, exist_ok=True)
                
                # JSON íŒŒì¼ë¡œ ì €ì¥
                backup_filename = f"{backup_dir}/personal_questions_app_{app.id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                with open(backup_filename, 'w', encoding='utf-8') as f:
                    json.dump(backup_data, f, ensure_ascii=False, indent=2)
                print(f"  ğŸ’¾ ë°±ì—… íŒŒì¼ ì €ì¥: {backup_filename}")
                
                # ê°œì¸ë³„ ë§ì¶¤ ì§ˆë¬¸ (application_id ê¸°ë°˜)
                personal_questions = question_bundle.get("personal", [])
                for question_text in personal_questions:
                    interview_question = InterviewQuestion(
                        application_id=app.id,
                        job_post_id=None,
                        company_id=None,
                        type=QuestionType.PERSONAL,  # ì‹¤ë¬´ì§„ ë©´ì ‘ (ê°œì¸ë³„ ë§ì¶¤)
                        question_text=question_text,
                        category="personal_custom",
                        difficulty="medium"
                    )
                    db.add(interview_question)
                    questions_count += 1
                
                # ì§ë¬´ ë§ì¶¤ ì§ˆë¬¸ (application_id + job_post_id ê¸°ë°˜)
                job_questions = question_bundle.get("job", [])
                for question_text in job_questions:
                    interview_question = InterviewQuestion(
                        application_id=app.id,
                        job_post_id=job.id,
                        company_id=None,
                        type=QuestionType.JOB,  # ì‹¤ë¬´ì§„ ë©´ì ‘ (ì§ë¬´ ë§ì¶¤)
                        question_text=question_text,
                        category="job_custom",
                        difficulty="medium"
                    )
                    db.add(interview_question)
                    questions_count += 1
                
                # ê³µí†µ ì§ˆë¬¸ (application_id ê¸°ë°˜)
                common_questions = question_bundle.get("common", [])
                for question_text in common_questions:
                    interview_question = InterviewQuestion(
                        application_id=app.id,
                        job_post_id=None,
                        company_id=None,
                        type=QuestionType.COMMON,  # ì‹¤ë¬´ì§„ ë©´ì ‘ (ê³µí†µ)
                        question_text=question_text,
                        category="common",
                        difficulty="medium"
                    )
                    db.add(interview_question)
                    questions_count += 1
                
                total_questions += questions_count
                print(f"  âœ… {questions_count}ê°œ ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ")
                print(f"  ğŸ“ ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬: ê°œì¸ë³„ ë§ì¶¤ {len(personal_questions)}ê°œ, ì§ë¬´ ë§ì¶¤ {len(job_questions)}ê°œ, ê³µí†µ {len(common_questions)}ê°œ")
                    
            except Exception as e:
                print(f"  âŒ ì§€ì›ì {app.id} ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                import traceback
                print(f"  ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        
        db.commit()
        print(f"\nğŸ‰ ì‹¤ë¬´ì§„ ë©´ì ‘ ê°œì¸ë³„ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")
        print(f"ê³µê³  {job.id}: {total_questions}ê°œ ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±")
        print(f"ì§€ì›ì {len(applications)}ëª…: ê°œì¸ë³„ ë§ì¶¤ ì§ˆë¬¸ ìƒì„±")
        
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    print("ğŸ¯ ì‹¤ë¬´ì§„ ë©´ì ‘ ê°œì¸ë³„ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± ì‹œì‘!")
    generate_personal_interview_questions() 