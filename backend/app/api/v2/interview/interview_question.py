from fastapi import APIRouter, Depends, HTTPException, Query, UploadFile, File, BackgroundTasks
from sqlalchemy.orm import Session
from sqlalchemy import func
from typing import List, Optional, Dict, Any
import redis
from pydantic import BaseModel
from app.utils.llm_cache import redis_cache
import datetime
from app.core.database import get_db
from app.api.v2.auth.auth import get_current_user
from app.models.v2.auth.user import User
from app.models.v2.document.application import Application, ApplicationStage, OverallStatus, StageStatus, StageName
from app.models.v2.recruitment.job import JobPost
from app.models.v2.document.resume import Resume, Spec
from app.models.v2.interview.personal_question_result import PersonalQuestionResult
from app.services.v2.interview.interview_question_service import InterviewQuestionService
from app.schemas.interview_question import InterviewQuestionCreate, InterviewQuestionBulkCreate,InterviewQuestionResponse, InterviewQuestionBulkCreate
from app.models.v2.interview.interview_question import InterviewQuestion, QuestionType
from app.api.v2.interview.company_question_rag import generate_questions, CompanyQuestionRagResponse
from app.services.v2.interview.evaluation_criteria_service import EvaluationCriteriaService
from app.models.v2.interview.evaluation_criteria import EvaluationCriteria
from app.schemas.evaluation_criteria import EvaluationCriteriaCreate
from app.models.v2.interview.interview_question_log import InterviewQuestionLog, InterviewType

import tempfile
import os

redis_client = redis.Redis(host='redis', port=6379, db=0)

router = APIRouter()

# í†µí•© APIìš© ìŠ¤í‚¤ë§ˆ
class IntegratedQuestionRequest(BaseModel):
    resume_id: Optional[int] = None
    application_id: Optional[int] = None
    company_name: str = ""
    name: str = ""

class IntegratedQuestionResponse(BaseModel):
    questions: list[str]
    question_bundle: dict
    summary_info: dict

# ê¸°ì¡´ APIìš© ìŠ¤í‚¤ë§ˆ (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
class CompanyQuestionRequest(BaseModel):
    company_name: str

class ProjectQuestionRequest(BaseModel):
    resume_id: int
    company_name: str = ""
    name: str = ""

class JobQuestionRequest(BaseModel):
    application_id: int
    company_name: str = ""
    resume_data: Optional[Dict[str, Any]] = None

class CompanyQuestionResponse(BaseModel):
    questions: list[str]

class ProjectQuestionResponse(BaseModel):
    questions: list[str]
    question_bundle: dict
    portfolio_info: str

class JobQuestionResponse(BaseModel):
    questions: list[str]
    question_bundle: dict
    job_matching_info: str

# ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆ ì¶”ê°€
class ResumeAnalysisRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class ResumeAnalysisResponse(BaseModel):
    resume_summary: str
    key_projects: List[str]
    technical_skills: List[str]
    soft_skills: List[str]
    experience_highlights: List[str]
    potential_concerns: List[str]
    interview_focus_areas: List[str]
    portfolio_analysis: Optional[str] = None
    job_matching_score: Optional[float] = None
    job_matching_details: Optional[str] = None

class InterviewChecklistRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class InterviewChecklistResponse(BaseModel):
    pre_interview_checklist: List[str]
    during_interview_checklist: List[str]
    post_interview_checklist: List[str]
    red_flags_to_watch: List[str]
    green_flags_to_confirm: List[str]

# ìƒˆë¡œìš´ ë¶„ì„ íˆ´ë“¤ì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ ì¶”ê°€
class ResumeOrchestratorRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_id: Optional[int] = None
    jobpost_id: Optional[int] = None
    enable_tools: Optional[List[str]] = None  # ['highlight', 'comprehensive', 'detailed', 'competitiveness', 'keyword_matching']

class ResumeOrchestratorResponse(BaseModel):
    metadata: Dict[str, Any]
    results: Dict[str, Any]
    errors: Dict[str, Any]
    summary: Dict[str, Any]

class DetailedAnalysisRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None

class DetailedAnalysisResponse(BaseModel):
    core_competencies: Dict[str, Any]
    experience_analysis: Dict[str, Any]
    growth_potential: Dict[str, Any]
    problem_solving: Dict[str, Any]
    leadership_collaboration: Dict[str, Any]
    specialization: Dict[str, Any]
    improvement_areas: Dict[str, Any]
    overall_assessment: Dict[str, Any]

class CompetitivenessComparisonRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None

class CompetitivenessComparisonResponse(BaseModel):
    market_competitiveness: Dict[str, Any]
    strength_areas: Dict[str, Any]
    weakness_areas: Dict[str, Any]
    differentiation_factors: Dict[str, Any]
    competitive_analysis: Dict[str, Any]
    sustainability: Dict[str, Any]
    improvement_strategy: Dict[str, Any]
    hiring_recommendation: Dict[str, Any]

class KeywordMatchingRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None

class KeywordMatchingResponse(BaseModel):
    technical_skills_matching: Dict[str, Any]
    experience_matching: Dict[str, Any]
    qualification_matching: Dict[str, Any]
    soft_skills_matching: Dict[str, Any]
    keyword_gaps: Dict[str, Any]
    unexpected_strengths: Dict[str, Any]
    matching_summary: Dict[str, Any]
    improvement_roadmap: Dict[str, Any]

class StrengthsWeaknessesRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class StrengthsWeaknessesResponse(BaseModel):
    strengths: List[dict]
    weaknesses: List[dict]
    development_areas: List[str]
    competitive_advantages: List[str]

class InterviewGuidelineRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class InterviewGuidelineResponse(BaseModel):
    interview_approach: str
    key_questions_by_category: dict
    evaluation_criteria: List[dict]
    time_allocation: dict
    follow_up_questions: List[str]

class EvaluationCriteriaRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None
    interview_stage: Optional[str] = None
    save_to_db: bool = False  # DB ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)

class EvaluationCriteriaResponse(BaseModel):
    suggested_criteria: List[dict]
    weight_recommendations: List[dict]
    evaluation_questions: List[str]
    scoring_guidelines: dict

# --- ê³µê³  ê¸°ë°˜ Request/Response ëª¨ë¸ ---
class JobBasedChecklistRequest(BaseModel):
    job_post_id: int
    company_name: str

class JobBasedChecklistResponse(BaseModel):
    pre_interview_checklist: List[str]
    during_interview_checklist: List[str]
    post_interview_checklist: List[str]
    red_flags_to_watch: List[str]
    green_flags_to_confirm: List[str]

class JobBasedGuidelineRequest(BaseModel):
    job_post_id: int
    company_name: str

class JobBasedGuidelineResponse(BaseModel):
    interview_approach: str
    key_questions_by_category: Dict
    evaluation_criteria: List[Dict]
    time_allocation: Dict
    follow_up_questions: List[str]

class JobBasedCriteriaRequest(BaseModel):
    job_post_id: int
    company_name: str

class JobBasedCriteriaResponse(BaseModel):
    suggested_criteria: List[Dict]
    weight_recommendations: List[Dict]
    evaluation_questions: List[str]
    scoring_guidelines: Dict

class JobBasedStrengthsRequest(BaseModel):
    job_post_id: int
    company_name: str

class JobBasedStrengthsResponse(BaseModel):
    strengths: List[Dict]
    weaknesses: List[Dict]
    development_areas: List[str]
    competitive_advantages: List[str]

def combine_resume_and_specs(resume: Resume, specs: List[Spec]) -> str:
    """Resumeì™€ Specì„ ì¡°í•©í•˜ì—¬ í¬ê´„ì ì¸ resume_text ìƒì„±"""
    
    # ê¸°ë³¸ ì´ë ¥ì„œ ì •ë³´
    resume_text = f"""
ì´ë ¥ì„œ ì œëª©: {resume.title}

ê¸°ë³¸ ë‚´ìš©:
{resume.content or "ë‚´ìš© ì—†ìŒ"}
"""
    
    # Spec íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
    spec_categories = {}
    for spec in specs:
        spec_type = spec.spec_type
        if spec_type not in spec_categories:
            spec_categories[spec_type] = []
        spec_categories[spec_type].append(spec)
    
    # í”„ë¡œì íŠ¸ ì •ë³´ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
    if "project" in spec_categories or "í”„ë¡œì íŠ¸" in spec_categories:
        projects = spec_categories.get("project", []) + spec_categories.get("í”„ë¡œì íŠ¸", [])
        resume_text += "\n\nì£¼ìš” í”„ë¡œì íŠ¸ ê²½í—˜:\n"
        for i, project in enumerate(projects, 1):
            resume_text += f"{i}. {project.spec_title}\n"
            if project.spec_description:
                resume_text += f"   {project.spec_description}\n"
    
    # êµìœ¡ì‚¬í•­
    if "education" in spec_categories or "êµìœ¡" in spec_categories:
        educations = spec_categories.get("education", []) + spec_categories.get("êµìœ¡", [])
        resume_text += "\n\nêµìœ¡ì‚¬í•­:\n"
        for education in educations:
            resume_text += f"- {education.spec_title}\n"
            if education.spec_description:
                resume_text += f"  {education.spec_description}\n"
    
    # ìê²©ì¦
    if "certificate" in spec_categories or "ìê²©ì¦" in spec_categories:
        certificates = spec_categories.get("certificate", []) + spec_categories.get("ìê²©ì¦", [])
        resume_text += "\n\nìê²©ì¦:\n"
        for cert in certificates:
            resume_text += f"- {cert.spec_title}\n"
            if cert.spec_description:
                resume_text += f"  {cert.spec_description}\n"
    
    # ê¸°ìˆ ìŠ¤íƒ
    if "skill" in spec_categories or "ê¸°ìˆ " in spec_categories:
        skills = spec_categories.get("skill", []) + spec_categories.get("ê¸°ìˆ ", [])
        resume_text += "\n\nê¸°ìˆ  ìŠ¤íƒ:\n"
        for skill in skills:
            resume_text += f"- {skill.spec_title}\n"
            if skill.spec_description:
                resume_text += f"  {skill.spec_description}\n"
    
    # ê¸°íƒ€ ìŠ¤í™ë“¤
    other_specs = []
    for spec_type, specs_list in spec_categories.items():
        if spec_type not in ["project", "í”„ë¡œì íŠ¸", "education", "êµìœ¡", "certificate", "ìê²©ì¦", "skill", "ê¸°ìˆ "]:
            other_specs.extend(specs_list)
    
    if other_specs:
        resume_text += "\n\nê¸°íƒ€ ê²½í—˜:\n"
        for spec in other_specs:
            resume_text += f"- {spec.spec_title} ({spec.spec_type})\n"
            if spec.spec_description:
                resume_text += f"  {spec.spec_description}\n"
    
    return resume_text.strip()

def parse_job_post_data(job_post: JobPost) -> str:
    """JobPost ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ì§ë¬´ ì •ë³´ í…ìŠ¤íŠ¸ ìƒì„±"""
    
    job_info = f"""
ê³µê³  ì œëª©: {job_post.title}
ë¶€ì„œ: {job_post.department or "ë¯¸ì§€ì •"}

ìê²©ìš”ê±´:
{job_post.qualifications or "ìê²©ìš”ê±´ ì •ë³´ ì—†ìŒ"}

ì§ë¬´ ë‚´ìš©:
{job_post.job_details or "ì§ë¬´ ë‚´ìš© ì •ë³´ ì—†ìŒ"}

ê·¼ë¬´ ì¡°ê±´:
{job_post.conditions or "ê·¼ë¬´ ì¡°ê±´ ì •ë³´ ì—†ìŒ"}

ì±„ìš© ì ˆì°¨:
{job_post.procedures or "ì±„ìš© ì ˆì°¨ ì •ë³´ ì—†ìŒ"}

ê·¼ë¬´ì§€: {job_post.location or "ë¯¸ì§€ì •"}
ê³ ìš©í˜•íƒœ: {job_post.employment_type or "ë¯¸ì§€ì •"}
ëª¨ì§‘ì¸ì›: {job_post.headcount or "ë¯¸ì§€ì •"}ëª…
"""
    
    return job_info.strip()

def analyze_job_matching(resume_text: str, job_info: str) -> str:
    """ì´ë ¥ì„œì™€ ê³µê³  ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë§¤ì¹­ ì •ë³´ ìƒì„±"""
    
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ë¶„ì„
    matching_keywords = []
    
    # ê³µê³µê¸°ê´€ ê´€ë ¨ í‚¤ì›Œë“œ
    if "ê³µê³µ" in job_info or "ê¸°ê´€" in job_info:
        if "ê³µê³µ" in resume_text or "ê¸°ê´€" in resume_text or "ì •ë¶€" in resume_text:
            matching_keywords.append("ê³µê³µê¸°ê´€ ê²½í—˜")
    
    # PM/PL ê´€ë ¨ í‚¤ì›Œë“œ
    if "PM" in job_info or "PL" in job_info or "í”„ë¡œì íŠ¸ê´€ë¦¬" in job_info:
        if "PM" in resume_text or "PL" in resume_text or "í”„ë¡œì íŠ¸" in resume_text or "ê´€ë¦¬" in resume_text:
            matching_keywords.append("í”„ë¡œì íŠ¸ ê´€ë¦¬ ê²½í—˜")
    
    # IT/SI ê´€ë ¨ í‚¤ì›Œë“œ
    if "IT" in job_info or "SI" in job_info or "ê°œë°œ" in job_info:
        if "IT" in resume_text or "SI" in resume_text or "ê°œë°œ" in resume_text or "í”„ë¡œê·¸ë˜ë°" in resume_text:
            matching_keywords.append("IT/ê°œë°œ ê²½í—˜")
    
    # ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ê´€ë ¨
    if "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬" in job_info:
        if "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬" in resume_text or "ê¸°ì‚¬" in resume_text:
            matching_keywords.append("ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ìê²©ì¦")
    
    if matching_keywords:
        return f"ë§¤ì¹­ëœ í‚¤ì›Œë“œ: {', '.join(matching_keywords)}"
    else:
        return "ì§ì ‘ì ì¸ ë§¤ì¹­ í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

@router.post("/", response_model=InterviewQuestionResponse)
def create_question(question: InterviewQuestionCreate, db: Session = Depends(get_db)):
    db_question = InterviewQuestion(**question.dict())
    db.add(db_question)
    db.commit()
    db.refresh(db_question)
    return db_question

@router.post("/bulk-create", response_model=List[InterviewQuestionResponse])
def create_questions_bulk(bulk_data: InterviewQuestionBulkCreate, db: Session = Depends(get_db)):
    """ëŒ€ëŸ‰ ì§ˆë¬¸ ìƒì„±"""
    return InterviewQuestionService.create_questions_bulk(db, bulk_data)


@router.post("/integrated-questions", response_model=IntegratedQuestionResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_integrated_questions(request: IntegratedQuestionRequest, db: Session = Depends(get_db)):
    """í†µí•© ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©, DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        job_matching_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
                    job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì¢…í•© ì§ˆë¬¸ ìƒì„± (DB ì €ì¥ ì—†ìŒ)
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name,
            applicant_name=request.name,
            interview_type="general",
            job_matching_info=job_matching_info
        )
        
        # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
        questions = workflow_result.get("questions", [])
        question_bundle = workflow_result.get("question_bundle", {})
        evaluation_tools = workflow_result.get("evaluation_tools", {})
        resume_analysis = workflow_result.get("resume_analysis", {})
        
        # ìš”ì•½ ì •ë³´ êµ¬ì„±
        summary_info = {
            "total_questions": len(questions),
            "question_categories": list(question_bundle.keys()) if question_bundle else [],
            "evaluation_tools_available": list(evaluation_tools.keys()) if evaluation_tools else [],
            "resume_analysis_available": bool(resume_analysis),
            "workflow_execution_time": workflow_result.get("execution_time", 0),
            "generated_at": workflow_result.get("generated_at", "")
        }
        
        return IntegratedQuestionResponse(
            questions=questions,
            question_bundle=question_bundle,
            summary_info=summary_info
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/resume-analysis", response_model=ResumeAnalysisResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_resume_analysis(request: ResumeAnalysisRequest, db: Session = Depends(get_db)):
    """ì´ë ¥ì„œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©, DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        job_matching_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
                    job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì´ë ¥ì„œ ë¶„ì„ (DB ì €ì¥ ì—†ìŒ)
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ì´ë ¥ì„œ ë¶„ì„ë§Œ)
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "",
            applicant_name=request.name or "",
            interview_type="general",
            job_matching_info=job_matching_info
        )
        
        # ì´ë ¥ì„œ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
        resume_analysis = workflow_result.get("resume_analysis", {})
        
        return ResumeAnalysisResponse(**resume_analysis)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/interview-checklist", response_model=InterviewChecklistResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_interview_checklist(request: InterviewChecklistRequest, db: Session = Depends(get_db)):
    """ë©´ì ‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± API"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ê¸°ë°˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
        from agent.agents.interview_question_node import generate_interview_checklist
        checklist_result = generate_interview_checklist(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬"
        )
        
        return checklist_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/strengths-weaknesses", response_model=StrengthsWeaknessesResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def analyze_strengths_weaknesses(request: StrengthsWeaknessesRequest, db: Session = Depends(get_db)):
    """ì§€ì›ì ê°•ì /ì•½ì  ë¶„ì„ API"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ê¸°ë°˜ ê°•ì /ì•½ì  ë¶„ì„
        from agent.agents.interview_question_node import analyze_candidate_strengths_weaknesses
        analysis_result = analyze_candidate_strengths_weaknesses(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬"
        )
        
        return analysis_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/interview-guideline", response_model=InterviewGuidelineResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_interview_guideline(request: InterviewGuidelineRequest, db: Session = Depends(get_db)):
    """ë©´ì ‘ ê°€ì´ë“œë¼ì¸ ìƒì„± API"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ê¸°ë°˜ ë©´ì ‘ ê°€ì´ë“œë¼ì¸ ìƒì„±
        from agent.agents.interview_question_node import generate_interview_guideline
        guideline_result = generate_interview_guideline(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬"
        )
        
        return guideline_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/evaluation-criteria", response_model=EvaluationCriteriaResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def suggest_evaluation_criteria(request: EvaluationCriteriaRequest, db: Session = Depends(get_db)):
    """í‰ê°€ ê¸°ì¤€ ìë™ ì œì•ˆ API (ì´ë ¥ì„œ ê¸°ë°˜)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # ë©´ì ‘ ë‹¨ê³„ë³„ í‰ê°€ ê¸°ì¤€ ìƒì„±
        from agent.agents.interview_question_node import suggest_evaluation_criteria
        
        # ë©´ì ‘ ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        interview_stage = getattr(request, 'interview_stage', 'practical')  # ê¸°ë³¸ê°’: ì‹¤ë¬´ì§„
        
        if interview_stage == 'practical':
            # ì‹¤ë¬´ì§„ ë©´ì ‘: ê¸°ìˆ ì  ì—­ëŸ‰ ì¤‘ì‹¬
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                focus_area="technical_skills"  # ê¸°ìˆ ì  ì—­ëŸ‰ ì¤‘ì‹¬
            )
        elif interview_stage == 'executive':
            # ì„ì›ì§„ ë©´ì ‘: ì¸ì„±/ë¦¬ë”ì‹­ ì¤‘ì‹¬
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                focus_area="leadership_potential"  # ë¦¬ë”ì‹­/ì¸ì„± ì¤‘ì‹¬
            )
        else:
            # ê¸°ë³¸: ì¢…í•©ì  í‰ê°€
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬"
            )
        
        # DB ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš° ì €ì¥
        if request.save_to_db:
            try:

                
                criteria_service = EvaluationCriteriaService(db)
                
                # LangGraph ê²°ê³¼ë¥¼ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
                suggested_criteria = []
                for item in criteria_result.get("suggested_criteria", []):
                    if isinstance(item, dict):
                        suggested_criteria.append({
                            "criterion": item.get("criterion", ""),
                            "description": item.get("description", ""),
                            "max_score": item.get("max_score", 10)
                        })
                
                weight_recommendations = []
                for item in criteria_result.get("weight_recommendations", []):
                    if isinstance(item, dict):
                        weight_recommendations.append({
                            "criterion": item.get("criterion", ""),
                            "weight": float(item.get("weight", 0.0)),
                            "reason": item.get("reason", "")
                        })
                
                evaluation_questions = criteria_result.get("evaluation_questions", [])
                if not isinstance(evaluation_questions, list):
                    evaluation_questions = []
                
                scoring_guidelines = criteria_result.get("scoring_guidelines", {})
                if not isinstance(scoring_guidelines, dict):
                    scoring_guidelines = {}

                criteria_data = EvaluationCriteriaCreate(
                    job_post_id=None,
                    resume_id=request.resume_id,
                    application_id=request.application_id,
                    evaluation_type="resume_based",
                    company_name=request.company_name,
                    suggested_criteria=suggested_criteria,
                    weight_recommendations=weight_recommendations,
                    evaluation_questions=evaluation_questions,
                    scoring_guidelines=scoring_guidelines
                )
                
                # ê¸°ì¡´ ë°ì´í„° í™•ì¸ ë° ì €ì¥/ì—…ë°ì´íŠ¸
                existing_criteria = criteria_service.get_evaluation_criteria_by_resume(
                    request.resume_id, 
                    request.application_id,
                    interview_stage
                )
                
                if existing_criteria:
                    criteria_service.update_evaluation_criteria_by_resume(
                        request.resume_id, 
                        criteria_data,
                        request.application_id,
                        interview_stage
                    )
                else:
                    criteria_service.create_evaluation_criteria(criteria_data)
                    
            except Exception as db_error:
                print(f"âš ï¸ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {db_error}")
                # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ LangGraph ê²°ê³¼ëŠ” ë°˜í™˜
                pass
        
        return criteria_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/company-questions", response_model=CompanyQuestionResponse)
@redis_cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ (íšŒì‚¬ ì •ë³´ ê¸°ë°˜)
async def generate_company_questions(request: CompanyQuestionRequest):
    """íšŒì‚¬ëª… ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (ì¸ì¬ìƒ + ë‰´ìŠ¤ ê¸°ë°˜)"""
    # Content-Type: application/json
    # {    "company_name": "ì‚¼ì„±ì „ì"     }
    # TODO: ì‚°ì—… íŠ¸ë Œë“œ/ê²½ìŸì‚¬ ë¹„êµ
    # TODO: ê¸°ìˆ  í˜ì‹ /ì‹ ì‚¬ì—…
    # TODO: íšŒì‚¬ ê¸°ë³¸ ì •ë³´ ì´í•´

    try:
        # LangGraph ê¸°ë°˜ í†µí•© ì§ˆë¬¸ ìƒì„±
        result = generate_questions(request.company_name)
        questions = result.get("text", [])
        
        if isinstance(questions, str):
            questions = questions.strip().split("\n")
        
        return {"questions": questions}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/project-questions", response_model=ProjectQuestionResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_project_questions(request: ProjectQuestionRequest, db: Session = Depends(get_db)):
    """ìê¸°ì†Œê°œì„œ/ì´ë ¥ì„œ ê¸°ë°˜ í”„ë¡œì íŠ¸ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©)"""
    # POST /api/v2/interview-questions/project-questions
    # Content-Type: application/json
    # {
    #   "resume_id": 1,
    #   "company_name": "ë„¤ì´ë²„",
    #   "name": "í™ê¸¸ë™"
    # }

    try:
        # Resumeì™€ Spec ë°ì´í„° ì¡°íšŒ
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        
        # Resume + Spec í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
        resume_text = combine_resume_and_specs(resume, specs)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì¢…í•© ì§ˆë¬¸ ìƒì„±
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            company_name=request.company_name,
            applicant_name=request.name,
            interview_type="general"
        )
        
        # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
        questions = workflow_result.get("questions", [])
        question_bundle = workflow_result.get("question_bundle", {})
        portfolio_info = ""
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ ì¶”ì¶œ
        if "personal" in question_bundle and "ìê¸°ì†Œê°œì„œ ìš”ì•½" in question_bundle["personal"]:
            portfolio_info = question_bundle["personal"].get("ìê¸°ì†Œê°œì„œ ìš”ì•½", "")
        
        result = {
            "resume_id": request.resume_id,
            "company_name": request.company_name,
            "questions": questions,
            "question_bundle": question_bundle,
            "portfolio_info": portfolio_info
        }
        
        return ProjectQuestionResponse(**result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/common-questions", response_model=Dict[str, Any])
@redis_cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ (ê³µí†µ ì§ˆë¬¸)
async def generate_common_questions_endpoint(
    company_name: str = "",
    job_post_id: Optional[int] = None,
    db: Session = Depends(get_db)
):
    """ëª¨ë“  ì§€ì›ìì—ê²Œ ê³µí†µìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ ìƒì„± API"""
    try:
        job_info = ""
        if job_post_id:
            job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
            if job_post:
                job_info = parse_job_post_data(job_post)
        
        # ê³µí†µ ì§ˆë¬¸ ìƒì„±
        from agent.agents.interview_question_node import generate_common_questions
        common_questions = generate_common_questions(
            company_name=company_name,
            job_info=job_info
        )
        
        # ëª¨ë“  ì§ˆë¬¸ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©
        all_questions = []
        all_questions.extend(common_questions.get("ì¸ì„±/ë™ê¸°", []))
        all_questions.extend(common_questions.get("íšŒì‚¬ ê´€ë ¨", []))
        all_questions.extend(common_questions.get("ì§ë¬´ ì´í•´", []))
        all_questions.extend(common_questions.get("ìƒí™© ëŒ€ì²˜", []))
        
        result = {
            "questions": all_questions,
            "question_bundle": common_questions,
            "company_name": company_name,
            "job_post_id": job_post_id
        }
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/job-questions", response_model=JobQuestionResponse)
async def generate_job_questions(request: JobQuestionRequest, db: Session = Depends(get_db)):
    """ì§€ì›ì„œ ê¸°ë°˜ ì§ë¬´ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©)"""
    # POST /api/v2/interview-questions/job-questions
    # Content-Type: application/json
    # {
    #   "application_id": 41,
    #   "company_name": "KOSAê³µê³µ"
    # }

    try:
        # Application ë°ì´í„° ì¡°íšŒ
        application = db.query(Application).filter(Application.id == request.application_id).first()
        if not application:
            raise HTTPException(status_code=404, detail="Application not found")
        
        # JobPost ë°ì´í„° ì¡°íšŒ
        job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
        
        # Resume ë°ì´í„° ì¡°íšŒ
        resume = db.query(Resume).filter(Resume.id == application.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        # Spec ë°ì´í„° ì¡°íšŒ
        specs = db.query(Spec).filter(Spec.resume_id == application.resume_id).all()
        
        # Resume + Spec í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
        resume_text = combine_resume_and_specs(resume, specs)
        
        # JobPost ì •ë³´ íŒŒì‹±
        job_info = parse_job_post_data(job_post)
        
        # ì‹¤ì œ íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
        actual_company_name = job_post.company.name if job_post.company else request.company_name
        
        # ì§ë¬´ ë§¤ì¹­ ë¶„ì„
        job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì¢…í•© ì§ˆë¬¸ ìƒì„±
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        try:
            workflow_result = generate_comprehensive_interview_questions(
                resume_text=resume_text,
                job_info=job_info,
                company_name=actual_company_name,
                applicant_name='',  # getattr(request, 'name', '') or '',
                interview_type="general",
                job_matching_info=job_matching_info
            )
            
            # ê²°ê³¼ ê²€ì¦
            if not workflow_result or not isinstance(workflow_result, dict):
                raise Exception("ì›Œí¬í”Œë¡œìš°ì—ì„œ ìœ íš¨í•œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
            questions = workflow_result.get("questions", [])
            question_bundle = workflow_result.get("question_bundle", {})
            
            # ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„±ì´ ìš”ì²­ëœ ê²½ìš° ì¶”ê°€ ì²˜ë¦¬
            if request.resume_data:
                try:
                    print(f"ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì‹œì‘ - application_id: {request.application_id}")
                    print(f"resume_data í‚¤: {list(request.resume_data.keys()) if request.resume_data else 'None'}")
                    print(f"job_info ê¸¸ì´: {len(job_info) if job_info else 0}")
                    print(f"company_name: {actual_company_name}")
                    
                    from agent.tools.personal_question_tool import generate_personal_interview_questions
                    
                    # ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± - tool í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ
                    personal_result = generate_personal_interview_questions(
                        resume_data=request.resume_data,
                        job_posting=job_info,
                        company_name=actual_company_name
                    )
                    
                    print(f"ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ - ê²°ê³¼ íƒ€ì…: {type(personal_result)}")
                    print(f"ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ - ê²°ê³¼ í‚¤: {list(personal_result.keys()) if personal_result else 'None'}")
                    
                    # ê°œì¸ë³„ ì§ˆë¬¸ì„ question_bundleì— ì¶”ê°€
                    if personal_result and personal_result.get("questions"):
                        personal_questions = personal_result["questions"]
                        print(f"ê°œì¸ë³„ ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬: {list(personal_questions.keys())}")
                        
                        # ê¸°ì¡´ question_bundleì„ ê°œì¸ë³„ ì§ˆë¬¸ìœ¼ë¡œ ì™„ì „íˆ êµì²´
                        question_bundle = personal_questions
                        
                        # ì „ì²´ ì§ˆë¬¸ ëª©ë¡ë„ ê°œì¸ë³„ ì§ˆë¬¸ìœ¼ë¡œ êµì²´
                        questions = []
                        for questions_list in personal_questions.values():
                            if isinstance(questions_list, list):
                                questions.extend(questions_list)
                            elif isinstance(questions_list, str):
                                questions.append(questions_list)
                            
                        print(f"ê°œì¸ë³„ ì§ˆë¬¸ìœ¼ë¡œ êµì²´ ì™„ë£Œ - ì´ ì§ˆë¬¸ ìˆ˜: {len(questions)}")
                        print(f"ê°œì¸ë³„ ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(question_bundle)}")
                    else:
                        print("âš ï¸ ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                        # ê¸°ë³¸ ì§ˆë¬¸ ìœ ì§€
                            
                except Exception as e:
                    print(f"ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    # ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì§ˆë¬¸ë§Œ ì‚¬ìš©
                    # ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ê¸°ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ê³„ì† ì§„í–‰
                    print("ê¸°ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            
            # ìµœì¢… ê²°ê³¼ ê²€ì¦
            if not question_bundle or (isinstance(question_bundle, dict) and len(question_bundle) == 0):
                print("âš ï¸ ì§ˆë¬¸ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                raise HTTPException(
                    status_code=500, 
                    detail="AI ê°œì¸ ì§ˆë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                )
            
            # 4. DBì— ê²°ê³¼ ì €ì¥
            try:
                print(f"ğŸ’¾ DB ì €ì¥ ì‹œì‘: application_id={request.application_id}")
                
                # ê¸°ì¡´ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                existing_result = db.query(PersonalQuestionResult).filter(
                    PersonalQuestionResult.application_id == request.application_id
                ).first()
                
                print(f"ğŸ” ê¸°ì¡´ ê²°ê³¼ ì¡°íšŒ: {'ìˆìŒ' if existing_result else 'ì—†ìŒ'}")
                
                if existing_result:
                    # ê¸°ì¡´ ê²°ê³¼ ì—…ë°ì´íŠ¸
                    print(f"ğŸ”„ ê¸°ì¡´ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹œì‘: ID {existing_result.id}")
                    existing_result.questions = questions
                    existing_result.question_bundle = question_bundle
                    existing_result.job_matching_info = job_matching_info
                    existing_result.updated_at = func.now()
                    personal_result = existing_result
                    print(f"ğŸ”„ ê¸°ì¡´ ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ ì—…ë°ì´íŠ¸: ID {existing_result.id}")
                else:
                    # ìƒˆë¡œìš´ ê²°ê³¼ ìƒì„±
                    print(f"ğŸ†• ìƒˆë¡œìš´ ê²°ê³¼ ìƒì„± ì‹œì‘")
                    personal_result = PersonalQuestionResult(
                        application_id=request.application_id,
                        jobpost_id=application.job_post_id,
                        company_id=application.job_post.company_id if application.job_post else None,
                        questions=questions,
                        question_bundle=question_bundle,
                        job_matching_info=job_matching_info
                    )
                    print(f"ğŸ†• PersonalQuestionResult ê°ì²´ ìƒì„± ì™„ë£Œ")
                    db.add(personal_result)
                    print(f"ğŸ’¾ ìƒˆë¡œìš´ ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ ì €ì¥")
                
                print(f"ğŸ’¾ DB commit ì‹œì‘")
                db.commit()
                print(f"âœ… ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ: ID {personal_result.id}")
                
            except Exception as db_error:
                print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨ (ë¶„ì„ ê²°ê³¼ëŠ” ë°˜í™˜): {db_error}")
                print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨ ìƒì„¸: {type(db_error).__name__}: {str(db_error)}")
                import traceback
                print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨ ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
                db.rollback()
                # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ ë¶„ì„ ê²°ê³¼ëŠ” ë°˜í™˜
            
            return JobQuestionResponse(
                questions=questions,
                question_bundle=question_bundle,
                job_matching_info=job_matching_info
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/passed-applicants-questions", response_model=Dict[str, Any])
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_passed_applicants_questions(
    request: dict,
    db: Session = Depends(get_db)
):
    job_post_id = request.get("job_post_id")
    company_name = request.get("company_name", "íšŒì‚¬")
    """ì„œë¥˜ í•©ê²©ìë“¤ì— ëŒ€í•œ ê°œì¸ë³„ ë©´ì ‘ ì§ˆë¬¸ ì¼ê´„ ìƒì„±"""
    # POST /api/v2/interview-questions/passed-applicants-questions
    # Content-Type: application/json
    # {
    #   "job_post_id": 17,
    #   "company_name": "KOSAê³µê³µ"
    # }

    try:
        # ì„œë¥˜ í•©ê²©ì ì¡°íšŒ - applications.pyì˜ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ
        from app.api.v2.document.applications import get_passed_applicants
        passed_applicants_response = get_passed_applicants(job_post_id, db)
        passed_applicants = passed_applicants_response.get("passed_applicants", [])
        
        if not passed_applicants:
            return {
                "message": "ì„œë¥˜ í•©ê²©ìê°€ ì—†ìŠµë‹ˆë‹¤.",
                "total_applicants": 0,
                "personal_questions": {}
            }
        
        # JobPost ë°ì´í„° ì¡°íšŒ
        job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
        
        # ì±„ìš©ê³µê³  ì •ë³´ íŒŒì‹±
        job_posting = parse_job_post_data(job_post)
        
        # ì‹¤ì œ íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
        actual_company_name = job_post.company.name if job_post.company else company_name
        
        # ê° í•©ê²©ìì— ëŒ€í•œ ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„±
        applicants_data = []
        
        for applicant in passed_applicants:
            # Resume ë°ì´í„° ì¡°íšŒ
            resume = db.query(Resume).filter(Resume.id == applicant["resume_id"]).first()
            if not resume:
                continue
            
            # Spec ë°ì´í„° ì¡°íšŒ
            specs = db.query(Spec).filter(Spec.resume_id == applicant["resume_id"]).all()
            
            # Resume + Spec í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
            resume_text = combine_resume_and_specs(resume, specs)
            
            # ì´ë ¥ì„œ ë°ì´í„° êµ¬ì„±
            resume_data = {
                "personal_info": {
                    "name": applicant["name"],
                    "email": applicant["email"],
                    "phone": applicant.get("phone", ""),
                    "address": applicant.get("address", "")
                },
                "education": {
                    "university": applicant.get("education", ""),
                    "major": applicant.get("major", ""),
                    "degree": applicant.get("degree_type", ""),
                    "gpa": ""
                },
                "experience": {
                    "companies": [],
                    "position": "",
                    "duration": ""
                },
                "skills": {
                    "programming_languages": [],
                    "frameworks": [],
                    "databases": [],
                    "tools": []
                },
                "projects": [],
                "activities": [],
                "certificates": applicant.get("certificates", [])
            }
            
            # Spec ë°ì´í„°ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            for spec in specs:
                if str(spec.spec_type) == "experience" and str(spec.spec_title) == "company":
                    resume_data["experience"]["companies"].append(spec.spec_description or "")
                elif str(spec.spec_type) == "experience" and str(spec.spec_title) == "position":
                    resume_data["experience"]["position"] = spec.spec_description or ""
                elif str(spec.spec_type) == "experience" and str(spec.spec_title) == "duration":
                    resume_data["experience"]["duration"] = spec.spec_description or ""
                elif str(spec.spec_type) == "skills" and str(spec.spec_title) == "name":
                    if "Java" in (spec.spec_description or ""):
                        resume_data["skills"]["programming_languages"].append("Java")
                    if "Python" in (spec.spec_description or ""):
                        resume_data["skills"]["programming_languages"].append("Python")
                    if "Spring" in (spec.spec_description or ""):
                        resume_data["skills"]["frameworks"].append("Spring")
                    if "React" in (spec.spec_description or ""):
                        resume_data["skills"]["frameworks"].append("React")
                elif str(spec.spec_type) == "projects" and str(spec.spec_title) == "name":
                    resume_data["projects"].append({
                        "name": spec.spec_description or "",
                        "description": ""
                    })
                elif str(spec.spec_type) == "activities" and str(spec.spec_title) == "name":
                    resume_data["activities"].append({
                        "name": spec.spec_description or "",
                        "description": ""
                    })
            
            applicants_data.append({
                "name": applicant["name"],
                "resume_data": resume_data,
                "resume_text": resume_text
            })
        
        # AI Agentë¥¼ í†µí•œ ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„±
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.tools.personal_question_tool import generate_batch_personal_questions
        
        # ì¼ê´„ ì§ˆë¬¸ ìƒì„±
        batch_questions = generate_batch_personal_questions(
            applicants_data=applicants_data,
            job_posting=job_posting,
            company_name=actual_company_name
        )
        
        result = {
            "message": "ì„œë¥˜ í•©ê²©ì ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ",
            "job_post_id": job_post_id,
            "company_name": actual_company_name,
            "total_applicants": len(passed_applicants),
            "personal_questions": batch_questions.get("personal_questions", {})
        }
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/analysis-questions", response_model=Dict[str, Any])
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_analysis_questions(request: IntegratedQuestionRequest, db: Session = Depends(get_db)):
    """
    ë‹¤ì–‘í•œ ì§ë¬´ ì—­ëŸ‰(ì‹¤ë¬´, ë¬¸ì œí•´ê²°, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ì„±ì¥ ê°€ëŠ¥ì„± ë“±) í‰ê°€ ì§ˆë¬¸ í†µí•© API
    """
    try:
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)

        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)

        from agent.agents.interview_question_node import generate_advanced_competency_questions

        competency_questions = generate_advanced_competency_questions(resume_text=resume_text, job_info=job_info)

        result = {"competency_questions": competency_questions}
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ê³µê³ /ì§ë¬´/íšŒì‚¬ ê¸°ì¤€ì˜ ì‹¤ë¬´ì§„ ê³µí†µ ì§ˆë¬¸ ìƒì„± API
@router.post("/job-common-questions", response_model=Dict[str, Any])
@redis_cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ (ê³µí†µ ì§ˆë¬¸)
async def generate_job_common_questions(
    job_post_id: int,
    company_name: str = "",
    db: Session = Depends(get_db)
):
    """
    ê³µê³ /ì§ë¬´/íšŒì‚¬ ê¸°ì¤€ì˜ ì‹¤ë¬´ì§„ ê³µí†µ ì§ˆë¬¸ ìƒì„± API
    (ì§€ì›ìë³„ì´ ì•„ë‹Œ, ëª¨ë“  ì§€ì›ìì—ê²Œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì§ë¬´ ì¤‘ì‹¬ ì§ˆë¬¸)
    """
    job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
    if not job_post:
        raise HTTPException(status_code=404, detail="Job post not found")
    job_info = parse_job_post_data(job_post)
    from agent.agents.interview_question_node import generate_job_question_bundle
    # resume_text ì—†ì´(ê³µí†µ ì§ˆë¬¸)
    question_bundle = await generate_job_question_bundle(
        resume_text="",
        job_info=job_info,
        company_name=company_name,
        job_matching_info=""
    )
    result = {"question_bundle": question_bundle}
    return result

import json
import re

def parse_json_from_llm(content):
    """LLM ì‘ë‹µì—ì„œ ë§ˆí¬ë‹¤ìš´ íœìŠ¤ë¥¼ ì œê±°í•˜ê³  JSONìœ¼ë¡œ ë³€í™˜"""
    if isinstance(content, dict): return content
    try:
        # ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì œê±°
        clean_content = re.sub(r'```(?:json)?\s*([\s\S]*?)\s*```', r'\1', content)
        return json.loads(clean_content.strip())
    except Exception as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return content

# --- ê³µê³  ê¸°ë°˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ---
@router.post("/interview-checklist/job-based")
@redis_cache(expire=3600)
async def generate_job_based_checklist(
    request: JobBasedChecklistRequest, 
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """ê³µê³  ê¸°ë°˜ ë©´ì ‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± (DB ì²´í¬ í›„ ì—†ìœ¼ë©´ Background Task)"""
    try:
        from app.models.v2.analysis.analysis_result import AnalysisResult
        
        # 1. ë¨¼ì € DBì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        existing = db.query(AnalysisResult).filter(
            AnalysisResult.jobpost_id == request.job_post_id,
            AnalysisResult.analysis_type == 'job_based_checklist'
        ).first()
        
        if existing:
            return existing.analysis_data

        job_post = db.query(JobPost).filter(JobPost.id == request.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¶”ê°€
        background_tasks.add_task(
            process_job_based_checklist,
            request.job_post_id,
            request.company_name or "",
            job_post.company_id
        )
        
        return {"message": "generating"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def process_job_based_checklist(job_post_id: int, company_name: str, company_id: int):
    """ì‹¤ì œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ë° DB ì €ì¥ (Background)"""
    db = next(get_db())
    try:
        from app.models.v2.analysis.analysis_result import AnalysisResult
        from agent.agents.interview_question_node import generate_interview_checklist
        
        job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
        job_info = parse_job_post_data(job_post)
        
        print(f"ğŸš€ [Background] ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì‹œì‘: JobPost {job_post_id}")
        
        raw_result = generate_interview_checklist(
            resume_text="",
            job_info=job_info,
            company_name=company_name
        )
        checklist_result = parse_json_from_llm(raw_result)
        
        # DB ì €ì¥ (AnalysisResult)
        existing = db.query(AnalysisResult).filter(
            AnalysisResult.jobpost_id == job_post_id,
            AnalysisResult.analysis_type == 'job_based_checklist'
        ).first()
        
        if existing:
            existing.analysis_data = checklist_result
            existing.updated_at = datetime.datetime.now()
        else:
            new_result = AnalysisResult(
                application_id=None,
                resume_id=None,
                jobpost_id=job_post_id,
                company_id=company_id,
                analysis_type='job_based_checklist',
                analysis_data=checklist_result
            )
            db.add(new_result)
        db.commit()
        print(f"âœ… [Background] ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ë° ì €ì¥ ì™„ë£Œ: JobPost {job_post_id}")
    except Exception as e:
        print(f"âŒ [Background] ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        db.rollback()
    finally:
        db.close()

# --- ê³µê³  ê¸°ë°˜ ê°•ì /ì•½ì  ---
@router.post("/strengths-weaknesses/job-based")
@redis_cache(expire=3600)
async def analyze_job_based_strengths_weaknesses(
    request: JobBasedStrengthsRequest, 
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """ê³µê³  ê¸°ë°˜ ê°•ì /ì•½ì  ë¶„ì„ (DB ì²´í¬ í›„ ì—†ìœ¼ë©´ Background Task)"""
    try:
        from app.models.v2.analysis.analysis_result import AnalysisResult
        
        # 1. ë¨¼ì € DBì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        existing = db.query(AnalysisResult).filter(
            AnalysisResult.jobpost_id == request.job_post_id,
            AnalysisResult.analysis_type == 'job_based_strengths'
        ).first()
        
        if existing:
            return {"message": "ê¸°ì¡´ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.", "data": existing.analysis_data, "job_post_id": request.job_post_id}

        job_post = db.query(JobPost).filter(JobPost.id == request.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
            
        background_tasks.add_task(
            process_job_based_strengths,
            request.job_post_id,
            request.company_name or "",
            job_post.company_id
        )
        
        return {"message": "ê°•ì /ì•½ì  ë¶„ì„ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.", "job_post_id": request.job_post_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def process_job_based_strengths(job_post_id: int, company_name: str, company_id: int):
    """ì‹¤ì œ ê°•ì /ì•½ì  ë¶„ì„ ë° ì €ì¥ (Background)"""
    db = next(get_db())
    try:
        from app.models.v2.analysis.analysis_result import AnalysisResult
        from agent.agents.interview_question_node import analyze_candidate_strengths_weaknesses
        
        job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
        job_info = parse_job_post_data(job_post)
        
        print(f"ğŸš€ [Background] ê°•ì /ì•½ì  ë¶„ì„ ì‹œì‘: JobPost {job_post_id}")
        
        analysis_result = analyze_candidate_strengths_weaknesses(
            resume_text="",
            job_info=job_info,
            company_name=company_name
        )
        
        existing = db.query(AnalysisResult).filter(
            AnalysisResult.jobpost_id == job_post_id,
            AnalysisResult.analysis_type == 'job_based_strengths'
        ).first()
        
        if existing:
            existing.analysis_data = analysis_result
            existing.updated_at = datetime.datetime.now()
        else:
            new_res = AnalysisResult(
                application_id=None,
                resume_id=None,
                jobpost_id=job_post_id,
                company_id=company_id,
                analysis_type='job_based_strengths',
                analysis_data=analysis_result
            )
            db.add(new_res)
        db.commit()
        print(f"âœ… [Background] ê°•ì /ì•½ì  ë¶„ì„ ë° ì €ì¥ ì™„ë£Œ: JobPost {job_post_id}")
    except Exception as e:
        print(f"âŒ [Background] ê°•ì /ì•½ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
        db.rollback()
    finally:
        db.close()

# --- ê³µê³  ê¸°ë°˜ ê°€ì´ë“œë¼ì¸ ---
@router.post("/interview-guideline/job-based")
@redis_cache(expire=3600)
async def generate_job_based_guideline(
    request: JobBasedGuidelineRequest, 
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """ê³µê³  ê¸°ë°˜ ê°€ì´ë“œë¼ì¸ ìƒì„± (DB ì²´í¬ í›„ ì—†ìœ¼ë©´ Background Task)"""
    try:
        from app.models.v2.analysis.analysis_result import AnalysisResult
        
        # 1. ë¨¼ì € DBì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        existing = db.query(AnalysisResult).filter(
            AnalysisResult.jobpost_id == request.job_post_id,
            AnalysisResult.analysis_type == 'job_based_guideline'
        ).first()
        
        if existing:
            return existing.analysis_data

        job_post = db.query(JobPost).filter(JobPost.id == request.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
            
        background_tasks.add_task(
            process_job_based_guideline,
            request.job_post_id,
            request.company_name or "",
            job_post.company_id
        )
        
        return {"message": "generating"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def process_job_based_guideline(job_post_id: int, company_name: str, company_id: int):
    """ì‹¤ì œ ê°€ì´ë“œë¼ì¸ ìƒì„± ë° ì €ì¥ (Background)"""
    db = next(get_db())
    try:
        from app.models.v2.analysis.analysis_result import AnalysisResult
        from agent.agents.interview_question_node import generate_interview_guideline
        
        job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
        job_info = parse_job_post_data(job_post)
        
        print(f"ğŸš€ [Background] ê°€ì´ë“œë¼ì¸ ìƒì„± ì‹œì‘: JobPost {job_post_id}")
        
        raw_result = generate_interview_guideline(
            resume_text="",
            job_info=job_info,
            company_name=company_name
        )
        guideline_result = parse_json_from_llm(raw_result)
        
        existing = db.query(AnalysisResult).filter(
            AnalysisResult.jobpost_id == job_post_id,
            AnalysisResult.analysis_type == 'job_based_guideline'
        ).first()
        
        if existing:
            existing.analysis_data = guideline_result
            existing.updated_at = datetime.datetime.now()
        else:
            new_res = AnalysisResult(
                application_id=None,
                resume_id=None,
                jobpost_id=job_post_id,
                company_id=company_id,
                analysis_type='job_based_guideline',
                analysis_data=guideline_result
            )
            db.add(new_res)
        db.commit()
        print(f"âœ… [Background] ê°€ì´ë“œë¼ì¸ ìƒì„± ë° ì €ì¥ ì™„ë£Œ: JobPost {job_post_id}")
    except Exception as e:
        print(f"âŒ [Background] ê°€ì´ë“œë¼ì¸ ìƒì„± ì‹¤íŒ¨: {e}")
        db.rollback()
    finally:
        db.close()

# --- ê³µê³  ê¸°ë°˜ í‰ê°€ ê¸°ì¤€ (ì¤‘ë³µ ì œê±°) ---

# === ì„ì›ë©´ì ‘ ì§ˆë¬¸ ìƒì„± API ===
class ExecutiveInterviewRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class ExecutiveInterviewResponse(BaseModel):
    questions: str
    interview_type: str = "executive"

# === AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± API ===
class AiInterviewRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class AiInterviewResponse(BaseModel):
    questions: str
    interview_type: str = "ai"

class AiInterviewSaveRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None
    save_to_db: bool = True  # DBì— ì €ì¥í• ì§€ ì—¬ë¶€

class AiInterviewSaveResponse(BaseModel):
    questions: str
    interview_type: str = "ai"
    saved_questions_count: int
    message: str

@router.post("/ai-interview", response_model=AiInterviewResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_ai_interview_questions(request: AiInterviewRequest, db: Session = Depends(get_db)):
    """AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©, DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (DB ì €ì¥ ì—†ìŒ)
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬",
            applicant_name=request.name or "",
            interview_type="ai"
        )
        
        # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
        questions = workflow_result.get("questions", [])
        question_text = "\n".join(questions) if questions else "ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return {
            "questions": question_text,
            "interview_type": "ai",
            "workflow_result": {
                "total_questions": len(questions),
                "execution_time": workflow_result.get("execution_time", 0),
                "generated_at": workflow_result.get("generated_at", "")
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/ai-interview-save", response_model=AiInterviewSaveResponse)
async def generate_and_save_ai_interview_questions(request: AiInterviewSaveRequest, db: Session = Depends(get_db)):
    """AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ë° DB ì €ì¥"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (fallback ì‚¬ìš©)
        try:
            # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„±
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
            from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
            
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            workflow_result = generate_comprehensive_interview_questions(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                applicant_name=request.name or "",
                interview_type="ai"
            )
            
            # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
            generated_questions = workflow_result.get("generated_questions", {})
            ai_questions = generated_questions.get("ai", {})
            
            # ì§ˆë¬¸ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            all_questions = []
            for category, questions in ai_questions.items():
                if isinstance(questions, list):
                    all_questions.extend(questions)
                elif isinstance(questions, dict) and "questions" in questions:
                    all_questions.extend(questions["questions"])
            
        except Exception as e:
            print(f"AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
            # Fallback: ëœë¤ ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©
            from app.data.general_interview_questions import get_random_general_questions
            
            # 7ê°œì˜ ëœë¤ ì¼ë°˜ ì§ˆë¬¸ ì„ íƒ
            random_questions = get_random_general_questions(7)
            all_questions = [q["question"] for q in random_questions]
            
            # ì¶”ê°€ë¡œ 3ê°œì˜ ê¸°ë³¸ ì§ˆë¬¸ ì¶”ê°€ (ì´ 10ê°œ)
            additional_questions = [
                "ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.",
                "ì´ ì§ë¬´ì— ì§€ì›í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "ë³¸ì¸ì˜ ê°•ì ê³¼ ì•½ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            ]
            all_questions.extend(additional_questions)
        
        question_text = "\n".join(all_questions) if all_questions else "ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # DBì— ì €ì¥
        saved_count = 0
        if request.save_to_db and all_questions:
            now = datetime.datetime.now()
            # job_post_id ì°¾ê¸°
            job_post_id = None
            if request.application_id:
                application = db.query(Application).filter(Application.id == request.application_id).first()
                if application:
                    job_post_id = application.job_post_id
            
            if job_post_id:
                # ê¸°ì¡´ AI ë©´ì ‘ ì§ˆë¬¸ ì‚­ì œ (job_post_id ê¸°ë°˜, ì¤‘ë³µ ë°©ì§€)
                db.query(InterviewQuestion).filter(
                    InterviewQuestion.job_post_id == job_post_id,
                    InterviewQuestion.type == QuestionType.AI_INTERVIEW
                ).delete()
                
                # ìƒˆë¡œìš´ ì§ˆë¬¸ë“¤ ì €ì¥ (job_post_id ê¸°ë°˜, application_idëŠ” NULL)
                for i, question in enumerate(all_questions):
                    # ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ê²°ì •
                    category = "common"
                    if i < 3:
                        category = "common"
                    elif i < 6:
                        category = "personal"
                    elif i < 8:
                        category = "company"
                    else:
                        category = "job"
                    
                    # DBì— ì €ì¥ (AI ë©´ì ‘ì€ job_post_id ê¸°ë°˜, application_idëŠ” NULL)
                    interview_question = InterviewQuestion(
                        application_id=None,  # AI ë©´ì ‘ì€ ê³µê³ ë³„ ê³µìœ 
                        job_post_id=job_post_id,
                        type=QuestionType.AI_INTERVIEW,
                        question_text=question,
                        category=category,
                        difficulty="medium"  # AI ë©´ì ‘ì€ ê¸°ë³¸ì ìœ¼ë¡œ medium
                    )
                    db.add(interview_question)
                    saved_count += 1
                
                db.commit()
            
            # ìºì‹œ ë¬´íš¨í™”
            try:
                from app.core.cache import invalidate_cache
                # ê´€ë ¨ ìºì‹œ í‚¤ë“¤ ë¬´íš¨í™”
                cache_patterns_to_clear = [
                    f"cache:applications:job:{request.application_id}:*",
                    f"cache:interview-questions:application:{request.application_id}:*",
                    f"cache:interview-questions:job:{request.application_id}:*"
                ]
                
                for cache_pattern in cache_patterns_to_clear:
                    try:
                        invalidate_cache(cache_pattern)
                        print(f"ìºì‹œ ë¬´íš¨í™” ì™„ë£Œ: {cache_pattern}")
                    except Exception as cache_error:
                        print(f"ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {cache_pattern} - {cache_error}")
            except Exception as cache_error:
                print(f"ìºì‹œ ë¬´íš¨í™” ì¤‘ ì˜¤ë¥˜: {cache_error}")
        
        return {
            "questions": question_text,
            "interview_type": "ai",
            "saved_questions_count": saved_count,
            "message": f"AI ë©´ì ‘ ì§ˆë¬¸ {saved_count}ê°œê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤." if saved_count > 0 else "ì§ˆë¬¸ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# AI ë„êµ¬ í†µí•© API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
class AiToolsRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None
    interview_stage: Optional[str] = None
    evaluator_type: Optional[str] = None

class AiToolsResponse(BaseModel):
    evaluation_tools: dict
    questions: Optional[str] = None

@router.post("/ai-tools", response_model=AiToolsResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_ai_tools(request: AiToolsRequest, db: Session = Depends(get_db)):
    """AI ë©´ì ‘ì„ ìœ„í•œ í†µí•© ë„êµ¬ ìƒì„± (ì²´í¬ë¦¬ìŠ¤íŠ¸, ê°•ì /ì•½ì , ê°€ì´ë“œë¼ì¸, í‰ê°€ ê¸°ì¤€)"""
    # ì´ë ¥ì„œ ì •ë³´ ì¡°íšŒ
    resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
    if not resume:
        raise HTTPException(status_code=404, detail="ì´ë ¥ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Spec ì •ë³´ ì¡°íšŒ
    specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
    
    # í†µí•© ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ìƒì„±
    resume_text = combine_resume_and_specs(resume, specs)
    
    # Agent í˜¸ì¶œ ì¤€ë¹„
    import httpx
    from app.core.config import settings
    agent_url = settings.AGENT_URL or "http://agent:8001"
    url = f"{agent_url}/api/v2/agent/tools/interview-prep"
    
    # Agent ìš”ì²­ì„ ìœ„í•œ ë°ì´í„° êµ¬ì„±
    job_post_dict = {
        "title": request.interview_stage or "AI ë©´ì ‘",
        "qualifications": "", # ê³µê³  ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
        "conditions": "",
        "job_details": f"íšŒì‚¬: {request.company_name}"
    }
    
    resume_dict = {
        "name": request.name or "ì§€ì›ì",
        "career_summary": resume_text[:1000], # ìš”ì•½ í•„ìš” ì‹œ
        "skills": "", # íŒŒì‹± í•„ìš” ì‹œ
        "introduction": resume_text
    }
    
    payload = {
        "job_post": job_post_dict,
        "resume_data": resume_dict,
        "interview_type": "AI_INTERVIEW"
    }
    
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.post(url, json=payload, timeout=60.0)
            if resp.status_code == 200:
                tools_data = resp.json()
                # ì‘ë‹µ êµ¬ì¡°ê°€ {"evaluation_tools": ...} í˜•íƒœë¼ê³  ê°€ì •
                return AiToolsResponse(
                    evaluation_tools=tools_data.get("evaluation_tools", {}),
                    questions=None
                )
            else:
                print(f"Agent API í˜¸ì¶œ ì‹¤íŒ¨: {resp.status_code} {resp.text}")
                raise Exception("Agent API Error")

    except Exception as e:
        print(f"AI ë„êµ¬ ìƒì„± ì˜¤ë¥˜ (Agent í˜¸ì¶œ): {e}")
        # Fallback ë¡œì§ (ê¸°ì¡´ ì˜ˆì™¸ ì²˜ë¦¬ì™€ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ê±°ë‚˜ ê°„ì†Œí™”)
        # ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ì˜ ê¸°ë³¸ê°’ ë°˜í™˜ ë¡œì§ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        return AiToolsResponse(
            evaluation_tools={
                "checklist": {
                    "pre_interview_checklist": ["ì´ë ¥ì„œ ê²€í† ", "ê¸°ìˆ  ìŠ¤íƒ í™•ì¸"],
                    "during_interview_checklist": ["ê¸°ìˆ  ì§ˆë¬¸", "ê²½í—˜ í™•ì¸"],
                    "post_interview_checklist": ["í‰ê°€ ê¸°ë¡", "ê²°ê³¼ ì •ë¦¬"],
                    "red_flags_to_watch": ["ê¸°ìˆ  ë¶€ì¡±", "ê²½í—˜ ë¶€ì¡±"],
                    "green_flags_to_confirm": ["ê¸°ìˆ  ìš°ìˆ˜", "ê²½í—˜ í’ë¶€"]
                },
                "strengths_weaknesses": {
                    "strengths": [{"area": "ê¸°ìˆ ì—­ëŸ‰", "description": "ê¸°ìˆ  ìŠ¤íƒì´ ë‹¤ì–‘í•¨", "evidence": "ì´ë ¥ì„œ ê¸°ë°˜"}],
                    "weaknesses": [{"area": "ê²½í—˜ë¶€ì¡±", "description": "ì‹¤ë¬´ ê²½í—˜ ë¶€ì¡±", "suggestion": "í”„ë¡œì íŠ¸ ê²½í—˜ í™•ëŒ€"}],
                    "development_areas": ["ì‹¤ë¬´ ê²½í—˜", "íŒ€ì›Œí¬"],
                    "competitive_advantages": ["ê¸°ìˆ  ë‹¤ì–‘ì„±", "í•™ìŠµ ëŠ¥ë ¥"]
                },
                "guideline": {
                    "interview_approach": "ê¸°ìˆ  ì¤‘ì‹¬ ë©´ì ‘",
                    "key_questions_by_category": {
                        "ê¸°ìˆ ì—­ëŸ‰": ["ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€?", "í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–»ê²Œ í™œìš©í–ˆë‚˜?"],
                        "í”„ë¡œì íŠ¸ê²½í—˜": ["ê°€ì¥ ì–´ë ¤ì› ë˜ í”„ë¡œì íŠ¸ëŠ”?", "íŒ€ì—ì„œì˜ ì—­í• ì€?"]
                    },
                    "evaluation_criteria": [{"criterion": "ê¸°ìˆ ì—­ëŸ‰", "description": "ê¸°ìˆ  ìŠ¤íƒ ìˆ™ë ¨ë„", "weight": 0.4}],
                    "time_allocation": {"ê¸°ìˆ ì§ˆë¬¸": 0.5, "ê²½í—˜ì§ˆë¬¸": 0.3, "ì†Œí”„íŠ¸ìŠ¤í‚¬": 0.2},
                    "follow_up_questions": ["êµ¬ì²´ì ì¸ ê¸°ìˆ  í™œìš© ì‚¬ë¡€ëŠ”?", "ë¬¸ì œ í•´ê²° ê³¼ì •ì€?"]
                },
                "evaluation_criteria": {
                    "suggested_criteria": [{"criterion": "ê¸°ìˆ ì—­ëŸ‰", "description": "ê¸°ìˆ  ìŠ¤íƒ ìˆ™ë ¨ë„", "weight": 0.4}],
                    "weight_recommendations": [{"category": "ê¸°ìˆ ì—­ëŸ‰", "weight": 0.4, "reason": "í•µì‹¬ ì—­ëŸ‰"}],
                    "evaluation_questions": ["ê¸°ìˆ  ìŠ¤íƒ ìˆ™ë ¨ë„ëŠ”?", "í”„ë¡œì íŠ¸ ê²½í—˜ì€?"],
                    "scoring_guidelines": {"A": "90-100ì ", "B": "80-89ì ", "C": "70-79ì ", "D": "60-69ì ", "F": "60ì  ë¯¸ë§Œ"}
                }
            }
        )

@router.post("/application/{application_id}/evaluate-audio")
async def evaluate_audio(
    application_id: int,
    question_id: int,  # ì§ˆë¬¸ IDë„ í”„ë¡ íŠ¸ì—ì„œ ê°™ì´ ë³´ë‚´ì•¼ DB ì €ì¥ ê°€ëŠ¥
    question_text: str,
    audio_file: UploadFile = File(...)
):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ agent ì»¨í…Œì´ë„ˆì— ì „ë‹¬í•˜ì—¬ ì‹¤ì‹œê°„ ë¶„ì„ í›„ ê²°ê³¼ ë°˜í™˜
    """
    import httpx
    
    # 1. ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(await audio_file.read())
        tmp_path = tmp.name

    try:
        # 2. agent ì»¨í…Œì´ë„ˆì— HTTP ìš”ì²­ìœ¼ë¡œ ë¶„ì„ ìš”ì²­
        async with httpx.AsyncClient() as client:
            with open(tmp_path, "rb") as f:
                files = {"audio_file": f}
                data = {
                    "application_id": application_id,
                    "question_id": question_id,
                    "question_text": question_text
                }
                response = await client.post(
                    "http://agent:8001/evaluate-audio",
                    files=files,
                    data=data
                )
                result = response.json()
        
        # 3. DB ì €ì¥
        db = next(get_db())  # Depends ì‚¬ìš© ë¶ˆê°€ ì‹œ ì§ì ‘ í˜¸ì¶œ
        log = db.query(InterviewQuestionLog).filter(
            InterviewQuestionLog.application_id == application_id,
            InterviewQuestionLog.question_id == question_id
        ).first()
        if log:
            log.answer_text_transcribed = result.get("answer_text_transcribed")
            log.emotion = result.get("emotion")
            log.attitude = result.get("attitude")
            log.answer_score = result.get("answer_score")
            log.answer_feedback = result.get("answer_feedback")
            db.commit()
        
        return result
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(tmp_path):
            os.remove(tmp_path)

# --- ê³µê³  ê¸°ë°˜ í‰ê°€ ê¸°ì¤€ ---
@router.post("/evaluation-criteria/job-based")
@redis_cache(expire=3600)
async def create_job_based_evaluation_criteria(
    request: JobBasedCriteriaRequest, 
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """ê³µê³  ê¸°ë°˜ í‰ê°€í•­ëª© ìƒì„± (DB ì²´í¬ í›„ ì—†ìœ¼ë©´ Background Task)"""
    try:
        from app.services.v2.interview.evaluation_criteria_service import EvaluationCriteriaService
        
        # 1. ë¨¼ì € DBì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        criteria_service = EvaluationCriteriaService(db)
        existing = criteria_service.get_evaluation_criteria_by_job_post(request.job_post_id)
        
        if existing:
            return existing

        job_post = db.query(JobPost).filter(JobPost.id == request.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
            
        background_tasks.add_task(
            process_job_based_evaluation_criteria,
            request.job_post_id,
            request.company_name or ""
        )
        
        return {"message": "generating"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def process_job_based_evaluation_criteria(job_post_id: int, company_name: str):
    """ì‹¤ì œ í‰ê°€í•­ëª© ìƒì„± ë° ì €ì¥ (Background)"""
    db = next(get_db())
    try:
        from app.services.v2.interview.evaluation_criteria_service import EvaluationCriteriaService
        from app.schemas.evaluation_criteria import EvaluationCriteriaCreate
        from agent.agents.interview_question_node import suggest_evaluation_criteria
        
        job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
        job_info = parse_job_post_data(job_post)
        
        print(f"ğŸš€ [Background] í‰ê°€í•­ëª© ìƒì„± ì‹œì‘: JobPost {job_post_id}")
        
        raw_result = suggest_evaluation_criteria(
            resume_text="",
            job_info=job_info,
            company_name=company_name
        )
        criteria_result = parse_json_from_llm(raw_result)
        
        criteria_service = EvaluationCriteriaService(db)
        existing_criteria = criteria_service.get_evaluation_criteria_by_job_post(job_post_id)
        
        # ë°ì´í„° ë³€í™˜ ë¡œì§
        suggested_criteria_dict = []
        for item in criteria_result.get("suggested_criteria", []):
            if isinstance(item, dict):
                suggested_criteria_dict.append({
                    "criterion": item.get("criterion", ""),
                    "description": item.get("description", ""),
                    "max_score": item.get("max_score", 10)
                })
        
        weight_recommendations_dict = []
        for item in criteria_result.get("weight_recommendations", []):
            if isinstance(item, dict):
                weight_recommendations_dict.append({
                    "criterion": item.get("criterion", ""),
                    "weight": float(item.get("weight", 0.0)),
                    "reason": item.get("reason", "")
                })
        
        criteria_data = EvaluationCriteriaCreate(
            job_post_id=job_post_id,
            company_name=company_name,
            suggested_criteria=suggested_criteria_dict,
            weight_recommendations=weight_recommendations_dict,
            evaluation_questions=criteria_result.get("evaluation_questions", []),
            scoring_guidelines=criteria_result.get("scoring_guidelines", {}),
            evaluation_items=criteria_result.get("evaluation_items", [])
        )
        
        if existing_criteria:
            criteria_service.update_evaluation_criteria(job_post_id, criteria_data)
        else:
            criteria_service.create_evaluation_criteria(criteria_data)
            
        print(f"âœ… [Background] í‰ê°€í•­ëª© ìƒì„± ë° ì €ì¥ ì™„ë£Œ: JobPost {job_post_id}")
    except Exception as e:
        print(f"âŒ [Background] í‰ê°€í•­ëª© ìƒì„± ì‹¤íŒ¨: {e}")
    finally:
        db.close()

@router.delete("/evaluation-criteria/job/{job_post_id}")
async def delete_job_based_evaluation_criteria(job_post_id: int, db: Session = Depends(get_db)):
    """ê³µê³ ë³„ í‰ê°€í•­ëª© ì‚­ì œ"""
    try:
        criteria_service = EvaluationCriteriaService(db)
        success = criteria_service.delete_evaluation_criteria(job_post_id)
        
        if not success:
            raise HTTPException(status_code=404, detail="Evaluation criteria not found for this job post")
        
        return {"message": "Evaluation criteria deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/evaluation-criteria/resume-based", response_model=EvaluationCriteriaResponse)
async def create_resume_based_evaluation_criteria(request: EvaluationCriteriaRequest, db: Session = Depends(get_db)):
    """ì´ë ¥ì„œ ê¸°ë°˜ í‰ê°€ ê¸°ì¤€ ìƒì„± ë° DB ì €ì¥"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # ë©´ì ‘ ë‹¨ê³„ë³„ í‰ê°€ ê¸°ì¤€ ìƒì„±
        from agent.agents.interview_question_node import suggest_evaluation_criteria
        
        # ë©´ì ‘ ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        interview_stage = getattr(request, 'interview_stage', 'practical')  # ê¸°ë³¸ê°’: ì‹¤ë¬´ì§„
        
        if interview_stage == 'practical':
            # ì‹¤ë¬´ì§„ ë©´ì ‘: ê¸°ìˆ ì  ì—­ëŸ‰ ì¤‘ì‹¬
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                focus_area="technical_skills"  # ê¸°ìˆ ì  ì—­ëŸ‰ ì¤‘ì‹¬
            )
        elif interview_stage == 'executive':
            # ì„ì›ì§„ ë©´ì ‘: ì¸ì„±/ë¦¬ë”ì‹­ ì¤‘ì‹¬
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                focus_area="leadership_potential"  # ë¦¬ë”ì‹­/ì¸ì„± ì¤‘ì‹¬
            )
        else:
            # ê¸°ë³¸: ì¢…í•©ì  í‰ê°€
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬"
            )
        
        # DBì— ì €ì¥
        print(f"ğŸ” LangGraph ê²°ê³¼: {criteria_result}")
        try:           
            print("ğŸ” EvaluationCriteriaService import ì„±ê³µ")
            criteria_service = EvaluationCriteriaService(db)
            print("ğŸ” EvaluationCriteriaService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
            
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            existing_criteria = criteria_service.get_evaluation_criteria_by_resume(
                request.resume_id, 
                request.application_id,
                interview_stage
            )
            print(f"ğŸ” ê¸°ì¡´ ë°ì´í„° í™•ì¸: {existing_criteria}")
            
            # LangGraph ê²°ê³¼ë¥¼ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
            suggested_criteria = []
            for item in criteria_result.get("suggested_criteria", []):
                if isinstance(item, dict):
                    suggested_criteria.append({
                        "criterion": item.get("criterion", ""),
                        "description": item.get("description", ""),
                        "max_score": item.get("max_score", 10)
                    })
            
            weight_recommendations = []
            for item in criteria_result.get("weight_recommendations", []):
                if isinstance(item, dict):
                    weight_recommendations.append({
                        "criterion": item.get("criterion", ""),
                        "weight": float(item.get("weight", 0.0)),
                        "reason": item.get("reason", "")
                    })
            
            evaluation_questions = criteria_result.get("evaluation_questions", [])
            if not isinstance(evaluation_questions, list):
                evaluation_questions = []
            
            scoring_guidelines = criteria_result.get("scoring_guidelines", {})
            if not isinstance(scoring_guidelines, dict):
                scoring_guidelines = {}
            
            # evaluation_items ì²˜ë¦¬ (ìƒˆë¡œìš´ êµ¬ì²´ì  í‰ê°€ í•­ëª©)
            evaluation_items = criteria_result.get("evaluation_items", [])
            if not isinstance(evaluation_items, list):
                evaluation_items = []
            
            print(f"ğŸ” ë³€í™˜ëœ ë°ì´í„°:")
            print(f"  - suggested_criteria: {suggested_criteria}")
            print(f"  - weight_recommendations: {weight_recommendations}")
            print(f"  - evaluation_questions: {evaluation_questions}")
            print(f"  - scoring_guidelines: {scoring_guidelines}")
            print(f"  - evaluation_items: {evaluation_items}")

            criteria_data = EvaluationCriteriaCreate(
                job_post_id=None,  # ì´ë ¥ì„œ ê¸°ë°˜ì´ë¯€ë¡œ None
                resume_id=request.resume_id,
                application_id=request.application_id,
                evaluation_type="resume_based",
                company_name=request.company_name,
                suggested_criteria=suggested_criteria,
                weight_recommendations=weight_recommendations,
                evaluation_questions=evaluation_questions,
                scoring_guidelines=scoring_guidelines,
                evaluation_items=evaluation_items  # ìƒˆë¡œìš´ êµ¬ì²´ì  í‰ê°€ í•­ëª© ì¶”ê°€
            )
            print(f"ğŸ” criteria_data ìƒì„± ì„±ê³µ: {criteria_data}")
            
            if existing_criteria:
                # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
                criteria_service.update_evaluation_criteria_by_resume(
                    request.resume_id, 
                    criteria_data,
                    request.application_id,
                    interview_stage
                )
                print(f"âœ… í‰ê°€í•­ëª© ì—…ë°ì´íŠ¸ ì™„ë£Œ: resume_id={request.resume_id}")
            else:
                # ìƒˆë¡œ ìƒì„±
                criteria_service.create_evaluation_criteria(criteria_data)
                print(f"âœ… í‰ê°€í•­ëª© ìƒì„± ì™„ë£Œ: resume_id={request.resume_id}")
                
        except Exception as db_error:
            print(f"âš ï¸ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {db_error}")
            print(f"âš ï¸ ì˜¤ë¥˜ íƒ€ì…: {type(db_error)}")
            import traceback
            print(f"âš ï¸ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ LangGraph ê²°ê³¼ëŠ” ë°˜í™˜
            pass
        
        return criteria_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ìƒˆë¡œìš´ API: ë©´ì ‘ ë‹¨ê³„ë³„ í‰ê°€ í•­ëª© ì¡°íšŒ (Frontendìš©)
class InterviewEvaluationItemsRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    interview_stage: str  # "practical" ë˜ëŠ” "executive"

class InterviewEvaluationItemsResponse(BaseModel):
    interview_stage: str
    evaluation_items: List[Dict[str, Any]]
    total_weight: float
    max_total_score: int
    message: str = "í‰ê°€ í•­ëª©ì„ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤."

@router.post("/evaluation-items/interview", response_model=InterviewEvaluationItemsResponse)
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ
async def get_interview_evaluation_items(
    request: InterviewEvaluationItemsRequest,
    db: Session = Depends(get_db)
):
    """ë©´ì ‘ ë‹¨ê³„ë³„ í‰ê°€ í•­ëª© ì¡°íšŒ (ë‹¨ìˆœí™”ëœ ê¸°ë³¸ ê¸°ì¤€)"""
    try:
        # ë‹¨ìˆœí™”ëœ ê¸°ë³¸ í‰ê°€ ê¸°ì¤€ ë°˜í™˜ (DB ì˜ì¡´ì„± ì œê±°)
        if request.interview_stage == "practical":
            evaluation_items = [
                {
                    "item_name": "ê¸°ìˆ  ì—­ëŸ‰",
                    "description": "ì§€ì›ìì˜ ê¸°ìˆ ì  ëŠ¥ë ¥ê³¼ ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - í•´ë‹¹ ë¶„ì•¼ ì „ë¬¸ê°€ ìˆ˜ì¤€",
                        "4ì ": "ì–‘í˜¸ - ì‹¤ë¬´ ê°€ëŠ¥í•œ ìˆ˜ì¤€",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ ìˆ˜ì¤€",
                        "2ì ": "ë¯¸í¡ - ê°œì„  í•„ìš”",
                        "1ì ": "ë¶€ì¡± - í•™ìŠµ í•„ìš”"
                    },
                    "evaluation_questions": [
                        "ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì— ëŒ€í•œ ì´í•´ë„ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì‹¤ë¬´ì—ì„œ í•´ë‹¹ ê¸°ìˆ ì„ ì–´ë–»ê²Œ í™œìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
                    ],
                    "weight": 0.30
                },
                {
                    "item_name": "ê²½í—˜ ë° ì„±ê³¼",
                    "description": "ì§€ì›ìì˜ í”„ë¡œì íŠ¸ ê²½í—˜ê³¼ ì„±ê³¼",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ì„±ê³¼ì™€ ê²½í—˜",
                        "4ì ": "ì–‘í˜¸ - ì¶©ë¶„í•œ ê²½í—˜ê³¼ ì„±ê³¼",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ ê²½í—˜",
                        "2ì ": "ë¯¸í¡ - ê²½í—˜ ë¶€ì¡±",
                        "1ì ": "ë¶€ì¡± - ê²½í—˜ ì—†ìŒ"
                    },
                    "evaluation_questions": [
                        "ê°€ì¥ ì„±ê³µì ì´ì—ˆë˜ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ë³¸ì¸ì˜ ê¸°ì—¬ë„ì™€ ì„±ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.25
                },
                {
                    "item_name": "ë¬¸ì œí•´ê²° ëŠ¥ë ¥",
                    "description": "ì§€ì›ìì˜ ë¬¸ì œ ì¸ì‹ ë° í•´ê²° ëŠ¥ë ¥",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ì°½ì˜ì ì´ê³  íš¨ê³¼ì ì¸ í•´ê²°",
                        "4ì ": "ì–‘í˜¸ - ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ í•´ê²°",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ í•´ê²° ëŠ¥ë ¥",
                        "2ì ": "ë¯¸í¡ - í•´ê²° ëŠ¥ë ¥ ë¶€ì¡±",
                        "1ì ": "ë¶€ì¡± - ë¬¸ì œ ì¸ì‹ ì–´ë ¤ì›€"
                    },
                    "evaluation_questions": [
                        "ì–´ë ¤ìš´ ë¬¸ì œë¥¼ í•´ê²°í•œ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì˜ˆìƒì¹˜ ëª»í•œ ìƒí™©ì— ì–´ë–»ê²Œ ëŒ€ì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
                    ],
                    "weight": 0.20
                },
                {
                    "item_name": "ì˜ì‚¬ì†Œí†µ ë° í˜‘ì—…",
                    "description": "ì§€ì›ìì˜ íŒ€ì›Œí¬ì™€ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ì†Œí†µê³¼ ë¦¬ë”ì‹­",
                        "4ì ": "ì–‘í˜¸ - ì›í™œí•œ ì†Œí†µê³¼ í˜‘ì—…",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ ì†Œí†µ ëŠ¥ë ¥",
                        "2ì ": "ë¯¸í¡ - ì†Œí†µ ëŠ¥ë ¥ ë¶€ì¡±",
                        "1ì ": "ë¶€ì¡± - ì†Œí†µ ì–´ë ¤ì›€"
                    },
                    "evaluation_questions": [
                        "íŒ€ í”„ë¡œì íŠ¸ì—ì„œì˜ ì—­í• ê³¼ ê¸°ì—¬ë„ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ê°ˆë“± ìƒí™©ì„ ì–´ë–»ê²Œ í•´ê²°í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
                    ],
                    "weight": 0.15
                },
                {
                    "item_name": "ì„±ì¥ ì˜ì§€",
                    "description": "ì§€ì›ìì˜ í•™ìŠµ ì˜ì§€ì™€ ì„±ì¥ ê°€ëŠ¥ì„±",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ í•™ìŠµ ì˜ì§€ì™€ ê³„íš",
                        "4ì ": "ì–‘í˜¸ - ì ê·¹ì ì¸ í•™ìŠµ ì˜ì§€",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ í•™ìŠµ ì˜ì§€",
                        "2ì ": "ë¯¸í¡ - í•™ìŠµ ì˜ì§€ ë¶€ì¡±",
                        "1ì ": "ë¶€ì¡± - í•™ìŠµ ì˜ì§€ ì—†ìŒ"
                    },
                    "evaluation_questions": [
                        "ìƒˆë¡œìš´ ê¸°ìˆ ì„ í•™ìŠµí•œ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì•ìœ¼ë¡œì˜ ì„±ì¥ ê³„íšì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.10
                }
            ]
        else:  # executive
            evaluation_items = [
                {
                    "item_name": "ë¦¬ë”ì‹­",
                    "description": "íŒ€ ë¦¬ë”©ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                        "4ì ": "ì–‘í˜¸ - ì–‘í˜¸í•œ ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                        "3ì ": "ë³´í†µ - ì¼ë°˜ì ì¸ ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                        "2ì ": "ë¯¸í¡ - ì œí•œì ì¸ ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                        "1ì ": "ë¶€ì¡± - ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥ ë¶€ì¡±"
                    },
                    "evaluation_questions": [
                        "íŒ€ì„ ì´ëŒì–´ë³¸ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì–´ë ¤ìš´ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦° ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.30
                },
                {
                    "item_name": "ì „ëµì  ì‚¬ê³ ",
                    "description": "ë¹„ì „ ì œì‹œì™€ ì „ëµ ìˆ˜ë¦½ ëŠ¥ë ¥",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥",
                        "4ì ": "ì–‘í˜¸ - ì–‘í˜¸í•œ ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥",
                        "3ì ": "ë³´í†µ - ì¼ë°˜ì ì¸ ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥",
                        "2ì ": "ë¯¸í¡ - ì œí•œì ì¸ ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥",
                        "1ì ": "ë¶€ì¡± - ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥ ë¶€ì¡±"
                    },
                    "evaluation_questions": [
                        "ì¡°ì§ì˜ ë¯¸ë˜ ë¹„ì „ì„ ì–´ë–»ê²Œ ì„¤ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                        "ì‹œì¥ ë³€í™”ì— ëŒ€ì‘í•˜ëŠ” ì „ëµì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.25
                },
                {
                    "item_name": "ì¸ì„±ê³¼ ê°€ì¹˜ê´€",
                    "description": "ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                        "4ì ": "ì–‘í˜¸ - ì–‘í˜¸í•œ ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                        "3ì ": "ë³´í†µ - ì¼ë°˜ì ì¸ ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                        "2ì ": "ë¯¸í¡ - ì œí•œì ì¸ ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                        "1ì ": "ë¶€ì¡± - ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„± ë¶€ì¡±"
                    },
                    "evaluation_questions": [
                        "ìœ¤ë¦¬ì  ë”œë ˆë§ˆ ìƒí™©ì„ ì–´ë–»ê²Œ í•´ê²°í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                        "ì¡°ì§ì˜ ê°€ì¹˜ê´€ê³¼ ë³¸ì¸ì˜ ê°€ì¹˜ê´€ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.25
                },
                {
                    "item_name": "ì„±ì¥ ì ì¬ë ¥",
                    "description": "ë¯¸ë˜ ì„±ì¥ ê°€ëŠ¥ì„±ê³¼ ë™ê¸°ë¶€ì—¬",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ì„±ì¥ ì ì¬ë ¥ê³¼ ê°•í•œ ë™ê¸°ë¶€ì—¬",
                        "4ì ": "ì–‘í˜¸ - ì–‘í˜¸í•œ ì„±ì¥ ì ì¬ë ¥ê³¼ ë™ê¸°ë¶€ì—¬",
                        "3ì ": "ë³´í†µ - ì¼ë°˜ì ì¸ ì„±ì¥ ì ì¬ë ¥ê³¼ ë™ê¸°ë¶€ì—¬",
                        "2ì ": "ë¯¸í¡ - ì œí•œì ì¸ ì„±ì¥ ì ì¬ë ¥ê³¼ ë™ê¸°ë¶€ì—¬",
                        "1ì ": "ë¶€ì¡± - ì„±ì¥ ì ì¬ë ¥ê³¼ ë™ê¸°ë¶€ì—¬ ë¶€ì¡±"
                    },
                    "evaluation_questions": [
                        "ì•ìœ¼ë¡œì˜ ì„±ì¥ ê³„íšì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì´ ì§ë¬´ì— ì§€ì›í•œ ë™ê¸°ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.20
                }
            ]
        
        # ì´ ê°€ì¤‘ì¹˜ì™€ ìµœëŒ€ ì ìˆ˜ ê³„ì‚°
        total_weight = sum(item.get("weight", 0) for item in evaluation_items)
        max_total_score = sum(item.get("max_score", 5) for item in evaluation_items)
        
        return InterviewEvaluationItemsResponse(
            interview_stage=request.interview_stage,
            evaluation_items=evaluation_items,
            total_weight=total_weight,
            max_total_score=max_total_score
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ì¤‘ì‹¬ APIë“¤ (DB ì €ì¥ ì—†ìŒ)
@router.post("/langgraph/interview-questions", response_model=Dict[str, Any])
async def generate_interview_questions_with_langgraph(request: IntegratedQuestionRequest, db: Session = Depends(get_db)):
    """ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        job_matching_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
                    job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name,
            applicant_name=request.name,
            interview_type="general",
            job_matching_info=job_matching_info
        )
        
        return {
            "success": True,
            "workflow_type": "interview_question_generation",
            "result": workflow_result,
            "executed_at": workflow_result.get("generated_at", "")
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "workflow_type": "interview_question_generation"
        }

@router.post("/langgraph/resume-analysis", response_model=Dict[str, Any])
async def generate_resume_analysis_with_langgraph(request: ResumeAnalysisRequest, db: Session = Depends(get_db)):
    """ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì´ë ¥ì„œ ë¶„ì„ (DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        job_matching_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
                    job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "",
            applicant_name=request.name or "",
            interview_type="general",
            job_matching_info=job_matching_info
        )
        
        return {
            "success": True,
            "workflow_type": "resume_analysis",
            "result": {
                "resume_analysis": workflow_result.get("resume_analysis", {}),
                "evaluation_tools": workflow_result.get("evaluation_tools", {})
            },
            "executed_at": workflow_result.get("generated_at", "")
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "workflow_type": "resume_analysis"
        }

@router.post("/langgraph/ai-interview", response_model=Dict[str, Any])
async def generate_ai_interview_with_langgraph(request: AiInterviewRequest, db: Session = Depends(get_db)):
    """ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬",
            applicant_name=request.name or "",
            interview_type="ai"
        )
        
        return {
            "success": True,
            "workflow_type": "ai_interview_question_generation",
            "result": workflow_result,
            "executed_at": workflow_result.get("generated_at", "")
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "workflow_type": "ai_interview_question_generation"
        }

@router.post("/langgraph/evaluation-tools", response_model=Dict[str, Any])
async def generate_evaluation_tools_with_langgraph(request: AiToolsRequest, db: Session = Depends(get_db)):
    """ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ í‰ê°€ ë„êµ¬ ìƒì„± (DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬",
            applicant_name=request.name or "",
            interview_type=request.interview_stage or "general"
        )
        
        return {
            "success": True,
            "workflow_type": "evaluation_tools_generation",
            "result": {
                "evaluation_tools": workflow_result.get("evaluation_tools", {}),
                "resume_analysis": workflow_result.get("resume_analysis", {})
            },
            "executed_at": workflow_result.get("generated_at", "")
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "workflow_type": "evaluation_tools_generation"
        }

# ë°±ê·¸ë¼ìš´ë“œ ì—ì´ì „íŠ¸ ì‹¤í–‰ APIë“¤
@router.post("/background/generate-interview-questions")
async def trigger_background_interview_questions_generation(request: IntegratedQuestionRequest, db: Session = Depends(get_db)):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± íŠ¸ë¦¬ê±°"""
    try:
        if not request.application_id:
            raise HTTPException(status_code=400, detail="application_idê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íŠ¸ë¦¬ê±°
        import asyncio
        from app.scheduler.langgraph_background_scheduler import generate_interview_questions_for_application_async
        
        # ë¹„ë™ê¸°ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰
        asyncio.create_task(generate_interview_questions_for_application_async(request.application_id))
        
        return {
            "success": True,
            "message": f"ì§€ì› {request.application_id}ì— ëŒ€í•œ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "task_type": "interview_questions_generation",
            "application_id": request.application_id
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "task_type": "interview_questions_generation"
        }

@router.post("/background/generate-resume-analysis")
async def trigger_background_resume_analysis_generation(request: ResumeAnalysisRequest, db: Session = Depends(get_db)):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì´ë ¥ì„œ ë¶„ì„ ìƒì„± íŠ¸ë¦¬ê±°"""
    try:
        if not request.application_id:
            raise HTTPException(status_code=400, detail="application_idê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íŠ¸ë¦¬ê±°
        import asyncio
        from app.scheduler.langgraph_background_scheduler import generate_resume_analysis_for_application_async
        
        # ë¹„ë™ê¸°ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰
        asyncio.create_task(generate_resume_analysis_for_application_async(request.application_id))
        
        return {
            "success": True,
            "message": f"ì§€ì› {request.application_id}ì— ëŒ€í•œ ì´ë ¥ì„œ ë¶„ì„ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "task_type": "resume_analysis_generation",
            "application_id": request.application_id
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "task_type": "resume_analysis_generation"
        }

@router.post("/background/generate-evaluation-tools")
async def trigger_background_evaluation_tools_generation(request: AiToolsRequest, db: Session = Depends(get_db)):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ í‰ê°€ ë„êµ¬ ìƒì„± íŠ¸ë¦¬ê±°"""
    try:
        if not request.application_id:
            raise HTTPException(status_code=400, detail="application_idê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íŠ¸ë¦¬ê±°
        import asyncio
        from app.scheduler.langgraph_background_scheduler import generate_evaluation_tools_for_application_async
        
        # ë¹„ë™ê¸°ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰
        asyncio.create_task(generate_evaluation_tools_for_application_async(request.application_id))
        
        return {
            "success": True,
            "message": f"ì§€ì› {request.application_id}ì— ëŒ€í•œ í‰ê°€ ë„êµ¬ ìƒì„±ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "task_type": "evaluation_tools_generation",
            "application_id": request.application_id
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "task_type": "evaluation_tools_generation"
        }
