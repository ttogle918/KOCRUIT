from fastapi import APIRouter, Depends, HTTPException, Query, UploadFile, File
from sqlalchemy.orm import Session
from sqlalchemy import func
from typing import List, Optional, Dict, Any
from app.core.database import get_db
from app.api.v1.auth import get_current_user
from app.models.user import User
from app.models.application import Application, DocumentStatus, InterviewStatus
from app.models.evaluation_criteria import EvaluationCriteria
from app.models.interview_question import InterviewQuestion, QuestionType
from app.models.job import JobPost
from app.models.resume import Resume, Spec
from app.models.personal_question_result import PersonalQuestionResult
from app.services.interview_question_service import InterviewQuestionService
from app.schemas.interview_question import (
    InterviewQuestionCreate, 
    InterviewQuestionResponse, 
    InterviewQuestionBulkCreate
)
from pydantic import BaseModel

from app.api.v1.company_question_rag import generate_questions
from app.utils.llm_cache import redis_cache

import redis
import json

from app.schemas.interview_question import InterviewQuestionBulkCreate, InterviewQuestionCreate, InterviewQuestionResponse
from app.models.interview_question_log import InterviewQuestionLog, InterviewType
import tempfile
import os

redis_client = redis.Redis(host='redis', port=6379, db=0)

router = APIRouter()

# í†µí•© APIìš© ìŠ¤í‚¤ë§ˆ
class IntegratedQuestionRequest(BaseModel):
    resume_id: Optional[int] = None
    application_id: Optional[int] = None
    company_name: str = ""
    name: str = ""

class IntegratedQuestionResponse(BaseModel):
    questions: list[str]
    question_bundle: dict
    summary_info: dict

# ê¸°ì¡´ APIìš© ìŠ¤í‚¤ë§ˆ (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
class CompanyQuestionRequest(BaseModel):
    company_name: str

class ProjectQuestionRequest(BaseModel):
    resume_id: int
    company_name: str = ""
    name: str = ""

class JobQuestionRequest(BaseModel):
    application_id: int
    company_name: str = ""
    resume_data: Optional[Dict[str, Any]] = None

class CompanyQuestionResponse(BaseModel):
    questions: list[str]

class ProjectQuestionResponse(BaseModel):
    questions: list[str]
    question_bundle: dict
    portfolio_info: str

class JobQuestionResponse(BaseModel):
    questions: list[str]
    question_bundle: dict
    job_matching_info: str

# ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆ ì¶”ê°€
class ResumeAnalysisRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class ResumeAnalysisResponse(BaseModel):
    resume_summary: str
    key_projects: List[str]
    technical_skills: List[str]
    soft_skills: List[str]
    experience_highlights: List[str]
    potential_concerns: List[str]
    interview_focus_areas: List[str]
    portfolio_analysis: Optional[str] = None
    job_matching_score: Optional[float] = None
    job_matching_details: Optional[str] = None

class InterviewChecklistRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class InterviewChecklistResponse(BaseModel):
    pre_interview_checklist: List[str]
    during_interview_checklist: List[str]
    post_interview_checklist: List[str]
    red_flags_to_watch: List[str]
    green_flags_to_confirm: List[str]

# ìƒˆë¡œìš´ ë¶„ì„ íˆ´ë“¤ì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ ì¶”ê°€
class ResumeOrchestratorRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_id: Optional[int] = None
    jobpost_id: Optional[int] = None
    enable_tools: Optional[List[str]] = None  # ['highlight', 'comprehensive', 'detailed', 'competitiveness', 'keyword_matching']

class ResumeOrchestratorResponse(BaseModel):
    metadata: Dict[str, Any]
    results: Dict[str, Any]
    errors: Dict[str, Any]
    summary: Dict[str, Any]

class DetailedAnalysisRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None

class DetailedAnalysisResponse(BaseModel):
    core_competencies: Dict[str, Any]
    experience_analysis: Dict[str, Any]
    growth_potential: Dict[str, Any]
    problem_solving: Dict[str, Any]
    leadership_collaboration: Dict[str, Any]
    specialization: Dict[str, Any]
    improvement_areas: Dict[str, Any]
    overall_assessment: Dict[str, Any]

class CompetitivenessComparisonRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None

class CompetitivenessComparisonResponse(BaseModel):
    market_competitiveness: Dict[str, Any]
    strength_areas: Dict[str, Any]
    weakness_areas: Dict[str, Any]
    differentiation_factors: Dict[str, Any]
    competitive_analysis: Dict[str, Any]
    sustainability: Dict[str, Any]
    improvement_strategy: Dict[str, Any]
    hiring_recommendation: Dict[str, Any]

class KeywordMatchingRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None

class KeywordMatchingResponse(BaseModel):
    technical_skills_matching: Dict[str, Any]
    experience_matching: Dict[str, Any]
    qualification_matching: Dict[str, Any]
    soft_skills_matching: Dict[str, Any]
    keyword_gaps: Dict[str, Any]
    unexpected_strengths: Dict[str, Any]
    matching_summary: Dict[str, Any]
    improvement_roadmap: Dict[str, Any]

class StrengthsWeaknessesRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class StrengthsWeaknessesResponse(BaseModel):
    strengths: List[dict]
    weaknesses: List[dict]
    development_areas: List[str]
    competitive_advantages: List[str]

class InterviewGuidelineRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class InterviewGuidelineResponse(BaseModel):
    interview_approach: str
    key_questions_by_category: dict
    evaluation_criteria: List[dict]
    time_allocation: dict
    follow_up_questions: List[str]

class EvaluationCriteriaRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None
    interview_stage: Optional[str] = None
    save_to_db: bool = False  # DB ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)

class EvaluationCriteriaResponse(BaseModel):
    suggested_criteria: List[dict]
    weight_recommendations: List[dict]
    evaluation_questions: List[str]
    scoring_guidelines: dict

# --- ê³µê³  ê¸°ë°˜ Request/Response ëª¨ë¸ ---
class JobBasedChecklistRequest(BaseModel):
    job_post_id: int
    company_name: str

class JobBasedChecklistResponse(BaseModel):
    pre_interview_checklist: List[str]
    during_interview_checklist: List[str]
    post_interview_checklist: List[str]
    red_flags_to_watch: List[str]
    green_flags_to_confirm: List[str]

class JobBasedGuidelineRequest(BaseModel):
    job_post_id: int
    company_name: str

class JobBasedGuidelineResponse(BaseModel):
    interview_approach: str
    key_questions_by_category: Dict
    evaluation_criteria: List[Dict]
    time_allocation: Dict
    follow_up_questions: List[str]

class JobBasedCriteriaRequest(BaseModel):
    job_post_id: int
    company_name: str

class JobBasedCriteriaResponse(BaseModel):
    suggested_criteria: List[Dict]
    weight_recommendations: List[Dict]
    evaluation_questions: List[str]
    scoring_guidelines: Dict

class JobBasedStrengthsRequest(BaseModel):
    job_post_id: int
    company_name: str

class JobBasedStrengthsResponse(BaseModel):
    strengths: List[Dict]
    weaknesses: List[Dict]
    development_areas: List[str]
    competitive_advantages: List[str]

def combine_resume_and_specs(resume: Resume, specs: List[Spec]) -> str:
    """Resumeì™€ Specì„ ì¡°í•©í•˜ì—¬ í¬ê´„ì ì¸ resume_text ìƒì„±"""
    
    # ê¸°ë³¸ ì´ë ¥ì„œ ì •ë³´
    resume_text = f"""
ì´ë ¥ì„œ ì œëª©: {resume.title}

ê¸°ë³¸ ë‚´ìš©:
{resume.content or "ë‚´ìš© ì—†ìŒ"}
"""
    
    # Spec íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
    spec_categories = {}
    for spec in specs:
        spec_type = spec.spec_type
        if spec_type not in spec_categories:
            spec_categories[spec_type] = []
        spec_categories[spec_type].append(spec)
    
    # í”„ë¡œì íŠ¸ ì •ë³´ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
    if "project" in spec_categories or "í”„ë¡œì íŠ¸" in spec_categories:
        projects = spec_categories.get("project", []) + spec_categories.get("í”„ë¡œì íŠ¸", [])
        resume_text += "\n\nì£¼ìš” í”„ë¡œì íŠ¸ ê²½í—˜:\n"
        for i, project in enumerate(projects, 1):
            resume_text += f"{i}. {project.spec_title}\n"
            if project.spec_description:
                resume_text += f"   {project.spec_description}\n"
    
    # êµìœ¡ì‚¬í•­
    if "education" in spec_categories or "êµìœ¡" in spec_categories:
        educations = spec_categories.get("education", []) + spec_categories.get("êµìœ¡", [])
        resume_text += "\n\nêµìœ¡ì‚¬í•­:\n"
        for education in educations:
            resume_text += f"- {education.spec_title}\n"
            if education.spec_description:
                resume_text += f"  {education.spec_description}\n"
    
    # ìê²©ì¦
    if "certificate" in spec_categories or "ìê²©ì¦" in spec_categories:
        certificates = spec_categories.get("certificate", []) + spec_categories.get("ìê²©ì¦", [])
        resume_text += "\n\nìê²©ì¦:\n"
        for cert in certificates:
            resume_text += f"- {cert.spec_title}\n"
            if cert.spec_description:
                resume_text += f"  {cert.spec_description}\n"
    
    # ê¸°ìˆ ìŠ¤íƒ
    if "skill" in spec_categories or "ê¸°ìˆ " in spec_categories:
        skills = spec_categories.get("skill", []) + spec_categories.get("ê¸°ìˆ ", [])
        resume_text += "\n\nê¸°ìˆ  ìŠ¤íƒ:\n"
        for skill in skills:
            resume_text += f"- {skill.spec_title}\n"
            if skill.spec_description:
                resume_text += f"  {skill.spec_description}\n"
    
    # ê¸°íƒ€ ìŠ¤í™ë“¤
    other_specs = []
    for spec_type, specs_list in spec_categories.items():
        if spec_type not in ["project", "í”„ë¡œì íŠ¸", "education", "êµìœ¡", "certificate", "ìê²©ì¦", "skill", "ê¸°ìˆ "]:
            other_specs.extend(specs_list)
    
    if other_specs:
        resume_text += "\n\nê¸°íƒ€ ê²½í—˜:\n"
        for spec in other_specs:
            resume_text += f"- {spec.spec_title} ({spec.spec_type})\n"
            if spec.spec_description:
                resume_text += f"  {spec.spec_description}\n"
    
    return resume_text.strip()

def parse_job_post_data(job_post: JobPost) -> str:
    """JobPost ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ì§ë¬´ ì •ë³´ í…ìŠ¤íŠ¸ ìƒì„±"""
    
    job_info = f"""
ê³µê³  ì œëª©: {job_post.title}
ë¶€ì„œ: {job_post.department or "ë¯¸ì§€ì •"}

ìê²©ìš”ê±´:
{job_post.qualifications or "ìê²©ìš”ê±´ ì •ë³´ ì—†ìŒ"}

ì§ë¬´ ë‚´ìš©:
{job_post.job_details or "ì§ë¬´ ë‚´ìš© ì •ë³´ ì—†ìŒ"}

ê·¼ë¬´ ì¡°ê±´:
{job_post.conditions or "ê·¼ë¬´ ì¡°ê±´ ì •ë³´ ì—†ìŒ"}

ì±„ìš© ì ˆì°¨:
{job_post.procedures or "ì±„ìš© ì ˆì°¨ ì •ë³´ ì—†ìŒ"}

ê·¼ë¬´ì§€: {job_post.location or "ë¯¸ì§€ì •"}
ê³ ìš©í˜•íƒœ: {job_post.employment_type or "ë¯¸ì§€ì •"}
ëª¨ì§‘ì¸ì›: {job_post.headcount or "ë¯¸ì§€ì •"}ëª…
"""
    
    return job_info.strip()

def analyze_job_matching(resume_text: str, job_info: str) -> str:
    """ì´ë ¥ì„œì™€ ê³µê³  ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë§¤ì¹­ ì •ë³´ ìƒì„±"""
    
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ë¶„ì„
    matching_keywords = []
    
    # ê³µê³µê¸°ê´€ ê´€ë ¨ í‚¤ì›Œë“œ
    if "ê³µê³µ" in job_info or "ê¸°ê´€" in job_info:
        if "ê³µê³µ" in resume_text or "ê¸°ê´€" in resume_text or "ì •ë¶€" in resume_text:
            matching_keywords.append("ê³µê³µê¸°ê´€ ê²½í—˜")
    
    # PM/PL ê´€ë ¨ í‚¤ì›Œë“œ
    if "PM" in job_info or "PL" in job_info or "í”„ë¡œì íŠ¸ê´€ë¦¬" in job_info:
        if "PM" in resume_text or "PL" in resume_text or "í”„ë¡œì íŠ¸" in resume_text or "ê´€ë¦¬" in resume_text:
            matching_keywords.append("í”„ë¡œì íŠ¸ ê´€ë¦¬ ê²½í—˜")
    
    # IT/SI ê´€ë ¨ í‚¤ì›Œë“œ
    if "IT" in job_info or "SI" in job_info or "ê°œë°œ" in job_info:
        if "IT" in resume_text or "SI" in resume_text or "ê°œë°œ" in resume_text or "í”„ë¡œê·¸ë˜ë°" in resume_text:
            matching_keywords.append("IT/ê°œë°œ ê²½í—˜")
    
    # ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ê´€ë ¨
    if "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬" in job_info:
        if "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬" in resume_text or "ê¸°ì‚¬" in resume_text:
            matching_keywords.append("ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ìê²©ì¦")
    
    if matching_keywords:
        return f"ë§¤ì¹­ëœ í‚¤ì›Œë“œ: {', '.join(matching_keywords)}"
    else:
        return "ì§ì ‘ì ì¸ ë§¤ì¹­ í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

@router.post("/", response_model=InterviewQuestionResponse)
def create_question(question: InterviewQuestionCreate, db: Session = Depends(get_db)):
    db_question = InterviewQuestion(**question.dict())
    db.add(db_question)
    db.commit()
    db.refresh(db_question)
    return db_question

@router.get("/application/{application_id}", response_model=List[InterviewQuestionResponse])
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (ì§ˆë¬¸ ì¡°íšŒ)
def get_questions_by_application(application_id: int, db: Session = Depends(get_db)):
    from app.models.interview_question import InterviewQuestion
    return db.query(InterviewQuestion).filter(InterviewQuestion.application_id == application_id).all()

@router.get("/application/{application_id}/by-type", response_model=InterviewQuestionResponse)
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (ì§ˆë¬¸ íƒ€ì…ë³„ ì¡°íšŒ)
def get_questions_by_type(application_id: int, db: Session = Depends(get_db)):
    """ì§€ì›ì„œë³„ ì§ˆë¬¸ì„ ìœ í˜•ë³„ë¡œ ë¶„ë¥˜í•˜ì—¬ ì¡°íšŒ"""
    return InterviewQuestionService.get_questions_by_type(db, application_id)

@router.post("/bulk-create", response_model=List[InterviewQuestionResponse])
def create_questions_bulk(bulk_data: InterviewQuestionBulkCreate, db: Session = Depends(get_db)):
    """ëŒ€ëŸ‰ ì§ˆë¬¸ ìƒì„±"""
    return InterviewQuestionService.create_questions_bulk(db, bulk_data)


@router.post("/integrated-questions", response_model=IntegratedQuestionResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_integrated_questions(request: IntegratedQuestionRequest, db: Session = Depends(get_db)):
    """í†µí•© ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©, DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        job_matching_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
                    job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì¢…í•© ì§ˆë¬¸ ìƒì„± (DB ì €ì¥ ì—†ìŒ)
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name,
            applicant_name=request.name,
            interview_type="general",
            job_matching_info=job_matching_info
        )
        
        # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
        questions = workflow_result.get("questions", [])
        question_bundle = workflow_result.get("question_bundle", {})
        evaluation_tools = workflow_result.get("evaluation_tools", {})
        resume_analysis = workflow_result.get("resume_analysis", {})
        
        # ìš”ì•½ ì •ë³´ êµ¬ì„±
        summary_info = {
            "total_questions": len(questions),
            "question_categories": list(question_bundle.keys()) if question_bundle else [],
            "evaluation_tools_available": list(evaluation_tools.keys()) if evaluation_tools else [],
            "resume_analysis_available": bool(resume_analysis),
            "workflow_execution_time": workflow_result.get("execution_time", 0),
            "generated_at": workflow_result.get("generated_at", "")
        }
        
        return IntegratedQuestionResponse(
            questions=questions,
            question_bundle=question_bundle,
            summary_info=summary_info
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/resume-analysis", response_model=ResumeAnalysisResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_resume_analysis(request: ResumeAnalysisRequest, db: Session = Depends(get_db)):
    """ì´ë ¥ì„œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©, DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        job_matching_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
                    job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì´ë ¥ì„œ ë¶„ì„ (DB ì €ì¥ ì—†ìŒ)
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ì´ë ¥ì„œ ë¶„ì„ë§Œ)
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "",
            applicant_name=request.name or "",
            interview_type="general",
            job_matching_info=job_matching_info
        )
        
        # ì´ë ¥ì„œ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
        resume_analysis = workflow_result.get("resume_analysis", {})
        
        return ResumeAnalysisResponse(**resume_analysis)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/interview-checklist", response_model=InterviewChecklistResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_interview_checklist(request: InterviewChecklistRequest, db: Session = Depends(get_db)):
    """ë©´ì ‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± API"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ê¸°ë°˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
        from agent.agents.interview_question_node import generate_interview_checklist
        checklist_result = generate_interview_checklist(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬"
        )
        
        return checklist_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/strengths-weaknesses", response_model=StrengthsWeaknessesResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def analyze_strengths_weaknesses(request: StrengthsWeaknessesRequest, db: Session = Depends(get_db)):
    """ì§€ì›ì ê°•ì /ì•½ì  ë¶„ì„ API"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ê¸°ë°˜ ê°•ì /ì•½ì  ë¶„ì„
        from agent.agents.interview_question_node import analyze_candidate_strengths_weaknesses
        analysis_result = analyze_candidate_strengths_weaknesses(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬"
        )
        
        return analysis_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/interview-guideline", response_model=InterviewGuidelineResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_interview_guideline(request: InterviewGuidelineRequest, db: Session = Depends(get_db)):
    """ë©´ì ‘ ê°€ì´ë“œë¼ì¸ ìƒì„± API"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ê¸°ë°˜ ë©´ì ‘ ê°€ì´ë“œë¼ì¸ ìƒì„±
        from agent.agents.interview_question_node import generate_interview_guideline
        guideline_result = generate_interview_guideline(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬"
        )
        
        return guideline_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/evaluation-criteria", response_model=EvaluationCriteriaResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def suggest_evaluation_criteria(request: EvaluationCriteriaRequest, db: Session = Depends(get_db)):
    """í‰ê°€ ê¸°ì¤€ ìë™ ì œì•ˆ API (ì´ë ¥ì„œ ê¸°ë°˜)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # ë©´ì ‘ ë‹¨ê³„ë³„ í‰ê°€ ê¸°ì¤€ ìƒì„±
        from agent.agents.interview_question_node import suggest_evaluation_criteria
        
        # ë©´ì ‘ ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        interview_stage = getattr(request, 'interview_stage', 'practical')  # ê¸°ë³¸ê°’: ì‹¤ë¬´ì§„
        
        if interview_stage == 'practical':
            # ì‹¤ë¬´ì§„ ë©´ì ‘: ê¸°ìˆ ì  ì—­ëŸ‰ ì¤‘ì‹¬
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                focus_area="technical_skills"  # ê¸°ìˆ ì  ì—­ëŸ‰ ì¤‘ì‹¬
            )
        elif interview_stage == 'executive':
            # ì„ì›ì§„ ë©´ì ‘: ì¸ì„±/ë¦¬ë”ì‹­ ì¤‘ì‹¬
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                focus_area="leadership_potential"  # ë¦¬ë”ì‹­/ì¸ì„± ì¤‘ì‹¬
            )
        else:
            # ê¸°ë³¸: ì¢…í•©ì  í‰ê°€
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬"
            )
        
        # DB ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš° ì €ì¥
        if request.save_to_db:
            try:
                from app.services.evaluation_criteria_service import EvaluationCriteriaService
                from app.schemas.evaluation_criteria import EvaluationCriteriaCreate
                
                criteria_service = EvaluationCriteriaService(db)
                
                # LangGraph ê²°ê³¼ë¥¼ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
                suggested_criteria = []
                for item in criteria_result.get("suggested_criteria", []):
                    if isinstance(item, dict):
                        suggested_criteria.append({
                            "criterion": item.get("criterion", ""),
                            "description": item.get("description", ""),
                            "max_score": item.get("max_score", 10)
                        })
                
                weight_recommendations = []
                for item in criteria_result.get("weight_recommendations", []):
                    if isinstance(item, dict):
                        weight_recommendations.append({
                            "criterion": item.get("criterion", ""),
                            "weight": float(item.get("weight", 0.0)),
                            "reason": item.get("reason", "")
                        })
                
                evaluation_questions = criteria_result.get("evaluation_questions", [])
                if not isinstance(evaluation_questions, list):
                    evaluation_questions = []
                
                scoring_guidelines = criteria_result.get("scoring_guidelines", {})
                if not isinstance(scoring_guidelines, dict):
                    scoring_guidelines = {}

                criteria_data = EvaluationCriteriaCreate(
                    job_post_id=None,
                    resume_id=request.resume_id,
                    application_id=request.application_id,
                    evaluation_type="resume_based",
                    company_name=request.company_name,
                    suggested_criteria=suggested_criteria,
                    weight_recommendations=weight_recommendations,
                    evaluation_questions=evaluation_questions,
                    scoring_guidelines=scoring_guidelines
                )
                
                # ê¸°ì¡´ ë°ì´í„° í™•ì¸ ë° ì €ì¥/ì—…ë°ì´íŠ¸
                existing_criteria = criteria_service.get_evaluation_criteria_by_resume(
                    request.resume_id, 
                    request.application_id,
                    interview_stage
                )
                
                if existing_criteria:
                    criteria_service.update_evaluation_criteria_by_resume(
                        request.resume_id, 
                        criteria_data,
                        request.application_id,
                        interview_stage
                    )
                else:
                    criteria_service.create_evaluation_criteria(criteria_data)
                    
            except Exception as db_error:
                print(f"âš ï¸ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {db_error}")
                # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ LangGraph ê²°ê³¼ëŠ” ë°˜í™˜
                pass
        
        return criteria_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/company-questions", response_model=CompanyQuestionResponse)
@redis_cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ (íšŒì‚¬ ì •ë³´ ê¸°ë°˜)
async def generate_company_questions(request: CompanyQuestionRequest):
    """íšŒì‚¬ëª… ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (ì¸ì¬ìƒ + ë‰´ìŠ¤ ê¸°ë°˜)"""
    # POST /api/v1/interview-questions/company-questions
    # Content-Type: application/json
    # {    "company_name": "ì‚¼ì„±ì „ì"     }
    # TODO: ì‚°ì—… íŠ¸ë Œë“œ/ê²½ìŸì‚¬ ë¹„êµ
    # TODO: ê¸°ìˆ  í˜ì‹ /ì‹ ì‚¬ì—…
    # TODO: íšŒì‚¬ ê¸°ë³¸ ì •ë³´ ì´í•´

    try:
        # LangGraph ê¸°ë°˜ í†µí•© ì§ˆë¬¸ ìƒì„±
        result = generate_questions(request.company_name)
        questions = result.get("text", [])
        
        if isinstance(questions, str):
            questions = questions.strip().split("\n")
        
        return {"questions": questions}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/application/{application_id}/practical-questions")
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (ì‹¤ë¬´ì§„ ì§ˆë¬¸ ì¡°íšŒ)
async def get_practical_interview_questions(application_id: int, db: Session = Depends(get_db)):
    """ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ (interview_question í…Œì´ë¸”ì—ì„œ COMMON, JOB, PERSONAL íƒ€ì… ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°)"""
    try:
        # application_idë¡œ ì§€ì›ì ì •ë³´ ì¡°íšŒ
        application = db.query(Application).filter(Application.id == application_id).first()
        if not application:
            raise HTTPException(status_code=404, detail="Application not found")
        
        # interview_question í…Œì´ë¸”ì—ì„œ ì‹¤ë¬´ì§„ ë©´ì ‘ìš© ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
        # COMMON, JOB, PERSONAL(applicant_id í•„í„°ë§) íƒ€ì…ë§Œ
        questions = []
        
        # 1. COMMON íƒ€ì… ì§ˆë¬¸ (ëª¨ë“  ì§€ì›ìì—ê²Œ ê³µí†µ)
        common_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.type == "COMMON"
        ).all()
        questions.extend([{"question_text": q.question_text, "type": q.type, "category": q.category, "difficulty": q.difficulty} for q in common_questions])
        
        # 2. JOB íƒ€ì… ì§ˆë¬¸ (ì§ë¬´ ê´€ë ¨) - application_idê°€ NULLì¸ ê²ƒë§Œ
        job_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.type == "JOB",
            InterviewQuestion.application_id.is_(None)
        ).all()
        questions.extend([{"question_text": q.question_text, "type": q.type, "category": q.category, "difficulty": q.difficulty} for q in job_questions])
        
        # 3. PERSONAL íƒ€ì… ì§ˆë¬¸ (íŠ¹ì • ì§€ì›ì ì „ìš©) - application_id ì‚¬ìš©
        personal_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.type == "PERSONAL",
            InterviewQuestion.application_id == application_id
        ).all()
        questions.extend([{"question_text": q.question_text, "type": q.type, "category": q.category, "difficulty": q.difficulty} for q in personal_questions])
        
        # ì§ˆë¬¸ ì¤‘ë³µ ì œê±° ë° ì •ë ¬ (question_text ê¸°ì¤€)
        seen_questions = set()
        unique_questions = []
        for q in questions:
            if q["question_text"] not in seen_questions:
                seen_questions.add(q["question_text"])
                unique_questions.append(q)
        
        questions = sorted(unique_questions, key=lambda x: x["question_text"])
        
        # ì§ˆë¬¸ íƒ€ì…ë³„ ë¶„ë¥˜ ì •ë³´ ìƒì„±
        question_details = {
            "common": [q.question_text for q in common_questions],
            "job": [q.question_text for q in job_questions],
            "personal": [q.question_text for q in personal_questions]
        }
        
        # ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜ (ê¸°ë³¸ ì§ˆë¬¸ ì œê±°)
        return {
            "application_id": application_id,
            "user_id": application.user_id,
            "resume_id": application.resume_id,
            "questions": questions,
            "question_count": len(questions),
            "types": ["COMMON", "JOB", "PERSONAL"],
            "question_details": question_details,
            "source": "database"
        }
    except Exception as e:
        print(f"âŒ ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        print(f"application_id: {application_id}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì‹¤ë¬´ì§„ ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@router.get("/application/{application_id}/executive-questions")
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (ì„ì›ì§„ ì§ˆë¬¸ ì¡°íšŒ)
async def get_executive_interview_questions(application_id: int, db: Session = Depends(get_db)):
    """ì„ì›ì§„ ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ (interview_question í…Œì´ë¸”ì—ì„œ COMMON, EXECUTIVE, PERSONAL íƒ€ì… ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°)"""
    try:
        # application_idë¡œ ì§€ì›ì ì •ë³´ ì¡°íšŒ
        application = db.query(Application).filter(Application.id == application_id).first()
        if not application:
            raise HTTPException(status_code=404, detail="Application not found")

        # interview_question í…Œì´ë¸”ì—ì„œ ì„ì›ì§„ ë©´ì ‘ìš© ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
        # COMMON, EXECUTIVE, PERSONAL(applicant_id í•„í„°ë§) íƒ€ì…ë§Œ
        questions = []
        
        # 1. COMMON íƒ€ì… ì§ˆë¬¸ (ëª¨ë“  ì§€ì›ìì—ê²Œ ê³µí†µ)
        common_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.type == "COMMON"
        ).all()
        questions.extend([{"question_text": q.question_text, "type": q.type, "category": q.category, "difficulty": q.difficulty} for q in common_questions])
        
        # 2. EXECUTIVE íƒ€ì… ì§ˆë¬¸ (ì„ì›ì§„ ì „ìš©)
        executive_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.type == "EXECUTIVE"
        ).all()
        questions.extend([{"question_text": q.question_text, "type": q.type, "category": q.category, "difficulty": q.difficulty} for q in executive_questions])
        
        # 3. PERSONAL íƒ€ì… ì§ˆë¬¸ (íŠ¹ì • ì§€ì›ì ì „ìš©) - application_id ì‚¬ìš©
        personal_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.type == "PERSONAL",
            InterviewQuestion.application_id == application_id
        ).all()
        questions.extend([{"question_text": q.question_text, "type": q.type, "category": q.category, "difficulty": q.difficulty} for q in personal_questions])
        
        # ì§ˆë¬¸ ì¤‘ë³µ ì œê±° ë° ì •ë ¬ (question_text ê¸°ì¤€)
        seen_questions = set()
        unique_questions = []
        for q in questions:
            if q["question_text"] not in seen_questions:
                seen_questions.add(q["question_text"])
                unique_questions.append(q)
        
        questions = sorted(unique_questions, key=lambda x: x["question_text"])
        
        # ì§ˆë¬¸ íƒ€ì…ë³„ ë¶„ë¥˜ ì •ë³´ ìƒì„±
        question_details = {
            "common": [q.question_text for q in common_questions],
            "executive": [q.question_text for q in executive_questions],
            "personal": [q.question_text for q in personal_questions]
        }
        
        # ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜ (ê¸°ë³¸ ì§ˆë¬¸ ì œê±°)
        return {
            "application_id": application_id,
            "user_id": application.user_id,
            "resume_id": application.resume_id,
            "questions": questions,
            "question_count": len(questions),
            "types": ["COMMON", "EXECUTIVE", "PERSONAL"],
            "question_details": question_details,
            "source": "database"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/project-questions", response_model=ProjectQuestionResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_project_questions(request: ProjectQuestionRequest, db: Session = Depends(get_db)):
    """ìê¸°ì†Œê°œì„œ/ì´ë ¥ì„œ ê¸°ë°˜ í”„ë¡œì íŠ¸ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©)"""
    # POST /api/v1/interview-questions/project-questions
    # Content-Type: application/json
    # {
    #   "resume_id": 1,
    #   "company_name": "ë„¤ì´ë²„",
    #   "name": "í™ê¸¸ë™"
    # }

    try:
        # Resumeì™€ Spec ë°ì´í„° ì¡°íšŒ
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        
        # Resume + Spec í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
        resume_text = combine_resume_and_specs(resume, specs)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì¢…í•© ì§ˆë¬¸ ìƒì„±
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            company_name=request.company_name,
            applicant_name=request.name,
            interview_type="general"
        )
        
        # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
        questions = workflow_result.get("questions", [])
        question_bundle = workflow_result.get("question_bundle", {})
        portfolio_info = ""
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ ì¶”ì¶œ
        if "personal" in question_bundle and "ìê¸°ì†Œê°œì„œ ìš”ì•½" in question_bundle["personal"]:
            portfolio_info = question_bundle["personal"].get("ìê¸°ì†Œê°œì„œ ìš”ì•½", "")
        
        result = {
            "resume_id": request.resume_id,
            "company_name": request.company_name,
            "questions": questions,
            "question_bundle": question_bundle,
            "portfolio_info": portfolio_info
        }
        
        return ProjectQuestionResponse(**result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/common-questions", response_model=Dict[str, Any])
@redis_cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ (ê³µí†µ ì§ˆë¬¸)
async def generate_common_questions_endpoint(
    company_name: str = "",
    job_post_id: Optional[int] = None,
    db: Session = Depends(get_db)
):
    """ëª¨ë“  ì§€ì›ìì—ê²Œ ê³µí†µìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ ìƒì„± API"""
    try:
        job_info = ""
        if job_post_id:
            job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
            if job_post:
                job_info = parse_job_post_data(job_post)
        
        # ê³µí†µ ì§ˆë¬¸ ìƒì„±
        from agent.agents.interview_question_node import generate_common_questions
        common_questions = generate_common_questions(
            company_name=company_name,
            job_info=job_info
        )
        
        # ëª¨ë“  ì§ˆë¬¸ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©
        all_questions = []
        all_questions.extend(common_questions.get("ì¸ì„±/ë™ê¸°", []))
        all_questions.extend(common_questions.get("íšŒì‚¬ ê´€ë ¨", []))
        all_questions.extend(common_questions.get("ì§ë¬´ ì´í•´", []))
        all_questions.extend(common_questions.get("ìƒí™© ëŒ€ì²˜", []))
        
        result = {
            "questions": all_questions,
            "question_bundle": common_questions,
            "company_name": company_name,
            "job_post_id": job_post_id
        }
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/job-questions", response_model=JobQuestionResponse)
async def generate_job_questions(request: JobQuestionRequest, db: Session = Depends(get_db)):
    """ì§€ì›ì„œ ê¸°ë°˜ ì§ë¬´ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©)"""
    # POST /api/v1/interview-questions/job-questions
    # Content-Type: application/json
    # {
    #   "application_id": 41,
    #   "company_name": "KOSAê³µê³µ"
    # }

    try:
        # Application ë°ì´í„° ì¡°íšŒ
        application = db.query(Application).filter(Application.id == request.application_id).first()
        if not application:
            raise HTTPException(status_code=404, detail="Application not found")
        
        # JobPost ë°ì´í„° ì¡°íšŒ
        job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
        
        # Resume ë°ì´í„° ì¡°íšŒ
        resume = db.query(Resume).filter(Resume.id == application.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        # Spec ë°ì´í„° ì¡°íšŒ
        specs = db.query(Spec).filter(Spec.resume_id == application.resume_id).all()
        
        # Resume + Spec í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
        resume_text = combine_resume_and_specs(resume, specs)
        
        # JobPost ì •ë³´ íŒŒì‹±
        job_info = parse_job_post_data(job_post)
        
        # ì‹¤ì œ íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
        actual_company_name = job_post.company.name if job_post.company else request.company_name
        
        # ì§ë¬´ ë§¤ì¹­ ë¶„ì„
        job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì¢…í•© ì§ˆë¬¸ ìƒì„±
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        try:
            workflow_result = generate_comprehensive_interview_questions(
                resume_text=resume_text,
                job_info=job_info,
                company_name=actual_company_name,
                applicant_name='',  # getattr(request, 'name', '') or '',
                interview_type="general",
                job_matching_info=job_matching_info
            )
            
            # ê²°ê³¼ ê²€ì¦
            if not workflow_result or not isinstance(workflow_result, dict):
                raise Exception("ì›Œí¬í”Œë¡œìš°ì—ì„œ ìœ íš¨í•œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
            questions = workflow_result.get("questions", [])
            question_bundle = workflow_result.get("question_bundle", {})
            
            # ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„±ì´ ìš”ì²­ëœ ê²½ìš° ì¶”ê°€ ì²˜ë¦¬
            if request.resume_data:
                try:
                    print(f"ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì‹œì‘ - application_id: {request.application_id}")
                    print(f"resume_data í‚¤: {list(request.resume_data.keys()) if request.resume_data else 'None'}")
                    print(f"job_info ê¸¸ì´: {len(job_info) if job_info else 0}")
                    print(f"company_name: {actual_company_name}")
                    
                    from agent.tools.personal_question_tool import generate_personal_interview_questions
                    
                    # ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± - tool í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ
                    personal_result = generate_personal_interview_questions(
                        resume_data=request.resume_data,
                        job_posting=job_info,
                        company_name=actual_company_name
                    )
                    
                    print(f"ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ - ê²°ê³¼ íƒ€ì…: {type(personal_result)}")
                    print(f"ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ - ê²°ê³¼ í‚¤: {list(personal_result.keys()) if personal_result else 'None'}")
                    
                    # ê°œì¸ë³„ ì§ˆë¬¸ì„ question_bundleì— ì¶”ê°€
                    if personal_result and personal_result.get("questions"):
                        personal_questions = personal_result["questions"]
                        print(f"ê°œì¸ë³„ ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬: {list(personal_questions.keys())}")
                        
                        # ê¸°ì¡´ question_bundleì„ ê°œì¸ë³„ ì§ˆë¬¸ìœ¼ë¡œ ì™„ì „íˆ êµì²´
                        question_bundle = personal_questions
                        
                        # ì „ì²´ ì§ˆë¬¸ ëª©ë¡ë„ ê°œì¸ë³„ ì§ˆë¬¸ìœ¼ë¡œ êµì²´
                        questions = []
                        for questions_list in personal_questions.values():
                            if isinstance(questions_list, list):
                                questions.extend(questions_list)
                            elif isinstance(questions_list, str):
                                questions.append(questions_list)
                            
                        print(f"ê°œì¸ë³„ ì§ˆë¬¸ìœ¼ë¡œ êµì²´ ì™„ë£Œ - ì´ ì§ˆë¬¸ ìˆ˜: {len(questions)}")
                        print(f"ê°œì¸ë³„ ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(question_bundle)}")
                    else:
                        print("âš ï¸ ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                        # ê¸°ë³¸ ì§ˆë¬¸ ìœ ì§€
                            
                except Exception as e:
                    print(f"ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    # ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì§ˆë¬¸ë§Œ ì‚¬ìš©
                    # ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ê¸°ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ê³„ì† ì§„í–‰
                    print("ê¸°ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            
            # ìµœì¢… ê²°ê³¼ ê²€ì¦
            if not question_bundle or (isinstance(question_bundle, dict) and len(question_bundle) == 0):
                print("âš ï¸ ì§ˆë¬¸ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                raise HTTPException(
                    status_code=500, 
                    detail="AI ê°œì¸ ì§ˆë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                )
            
            # 4. DBì— ê²°ê³¼ ì €ì¥
            try:
                print(f"ğŸ’¾ DB ì €ì¥ ì‹œì‘: application_id={request.application_id}")
                
                # ê¸°ì¡´ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                existing_result = db.query(PersonalQuestionResult).filter(
                    PersonalQuestionResult.application_id == request.application_id
                ).first()
                
                print(f"ğŸ” ê¸°ì¡´ ê²°ê³¼ ì¡°íšŒ: {'ìˆìŒ' if existing_result else 'ì—†ìŒ'}")
                
                if existing_result:
                    # ê¸°ì¡´ ê²°ê³¼ ì—…ë°ì´íŠ¸
                    print(f"ğŸ”„ ê¸°ì¡´ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹œì‘: ID {existing_result.id}")
                    existing_result.questions = questions
                    existing_result.question_bundle = question_bundle
                    existing_result.job_matching_info = job_matching_info
                    existing_result.updated_at = func.now()
                    personal_result = existing_result
                    print(f"ğŸ”„ ê¸°ì¡´ ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ ì—…ë°ì´íŠ¸: ID {existing_result.id}")
                else:
                    # ìƒˆë¡œìš´ ê²°ê³¼ ìƒì„±
                    print(f"ğŸ†• ìƒˆë¡œìš´ ê²°ê³¼ ìƒì„± ì‹œì‘")
                    personal_result = PersonalQuestionResult(
                        application_id=request.application_id,
                        jobpost_id=application.job_post_id,
                        company_id=application.job_post.company_id if application.job_post else None,
                        questions=questions,
                        question_bundle=question_bundle,
                        job_matching_info=job_matching_info
                    )
                    print(f"ğŸ†• PersonalQuestionResult ê°ì²´ ìƒì„± ì™„ë£Œ")
                    db.add(personal_result)
                    print(f"ğŸ’¾ ìƒˆë¡œìš´ ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ ì €ì¥")
                
                print(f"ğŸ’¾ DB commit ì‹œì‘")
                db.commit()
                print(f"âœ… ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ: ID {personal_result.id}")
                
            except Exception as db_error:
                print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨ (ë¶„ì„ ê²°ê³¼ëŠ” ë°˜í™˜): {db_error}")
                print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨ ìƒì„¸: {type(db_error).__name__}: {str(db_error)}")
                import traceback
                print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨ ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
                db.rollback()
                # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ ë¶„ì„ ê²°ê³¼ëŠ” ë°˜í™˜
            
            return JobQuestionResponse(
                questions=questions,
                question_bundle=question_bundle,
                job_matching_info=job_matching_info
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/passed-applicants-questions", response_model=Dict[str, Any])
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_passed_applicants_questions(
    request: dict,
    db: Session = Depends(get_db)
):
    job_post_id = request.get("job_post_id")
    company_name = request.get("company_name", "íšŒì‚¬")
    """ì„œë¥˜ í•©ê²©ìë“¤ì— ëŒ€í•œ ê°œì¸ë³„ ë©´ì ‘ ì§ˆë¬¸ ì¼ê´„ ìƒì„±"""
    # POST /api/v1/interview-questions/passed-applicants-questions
    # Content-Type: application/json
    # {
    #   "job_post_id": 17,
    #   "company_name": "KOSAê³µê³µ"
    # }

    try:
        # ì„œë¥˜ í•©ê²©ì ì¡°íšŒ - applications.pyì˜ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ
        from app.api.v1.applications import get_passed_applicants
        passed_applicants_response = get_passed_applicants(job_post_id, db)
        passed_applicants = passed_applicants_response.get("passed_applicants", [])
        
        if not passed_applicants:
            return {
                "message": "ì„œë¥˜ í•©ê²©ìê°€ ì—†ìŠµë‹ˆë‹¤.",
                "total_applicants": 0,
                "personal_questions": {}
            }
        
        # JobPost ë°ì´í„° ì¡°íšŒ
        job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
        
        # ì±„ìš©ê³µê³  ì •ë³´ íŒŒì‹±
        job_posting = parse_job_post_data(job_post)
        
        # ì‹¤ì œ íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
        actual_company_name = job_post.company.name if job_post.company else company_name
        
        # ê° í•©ê²©ìì— ëŒ€í•œ ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„±
        applicants_data = []
        
        for applicant in passed_applicants:
            # Resume ë°ì´í„° ì¡°íšŒ
            resume = db.query(Resume).filter(Resume.id == applicant["resume_id"]).first()
            if not resume:
                continue
            
            # Spec ë°ì´í„° ì¡°íšŒ
            specs = db.query(Spec).filter(Spec.resume_id == applicant["resume_id"]).all()
            
            # Resume + Spec í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
            resume_text = combine_resume_and_specs(resume, specs)
            
            # ì´ë ¥ì„œ ë°ì´í„° êµ¬ì„±
            resume_data = {
                "personal_info": {
                    "name": applicant["name"],
                    "email": applicant["email"],
                    "phone": applicant.get("phone", ""),
                    "address": applicant.get("address", "")
                },
                "education": {
                    "university": applicant.get("education", ""),
                    "major": applicant.get("major", ""),
                    "degree": applicant.get("degree_type", ""),
                    "gpa": ""
                },
                "experience": {
                    "companies": [],
                    "position": "",
                    "duration": ""
                },
                "skills": {
                    "programming_languages": [],
                    "frameworks": [],
                    "databases": [],
                    "tools": []
                },
                "projects": [],
                "activities": [],
                "certificates": applicant.get("certificates", [])
            }
            
            # Spec ë°ì´í„°ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            for spec in specs:
                if str(spec.spec_type) == "experience" and str(spec.spec_title) == "company":
                    resume_data["experience"]["companies"].append(spec.spec_description or "")
                elif str(spec.spec_type) == "experience" and str(spec.spec_title) == "position":
                    resume_data["experience"]["position"] = spec.spec_description or ""
                elif str(spec.spec_type) == "experience" and str(spec.spec_title) == "duration":
                    resume_data["experience"]["duration"] = spec.spec_description or ""
                elif str(spec.spec_type) == "skills" and str(spec.spec_title) == "name":
                    if "Java" in (spec.spec_description or ""):
                        resume_data["skills"]["programming_languages"].append("Java")
                    if "Python" in (spec.spec_description or ""):
                        resume_data["skills"]["programming_languages"].append("Python")
                    if "Spring" in (spec.spec_description or ""):
                        resume_data["skills"]["frameworks"].append("Spring")
                    if "React" in (spec.spec_description or ""):
                        resume_data["skills"]["frameworks"].append("React")
                elif str(spec.spec_type) == "projects" and str(spec.spec_title) == "name":
                    resume_data["projects"].append({
                        "name": spec.spec_description or "",
                        "description": ""
                    })
                elif str(spec.spec_type) == "activities" and str(spec.spec_title) == "name":
                    resume_data["activities"].append({
                        "name": spec.spec_description or "",
                        "description": ""
                    })
            
            applicants_data.append({
                "name": applicant["name"],
                "resume_data": resume_data,
                "resume_text": resume_text
            })
        
        # AI Agentë¥¼ í†µí•œ ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„±
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.tools.personal_question_tool import generate_batch_personal_questions
        
        # ì¼ê´„ ì§ˆë¬¸ ìƒì„±
        batch_questions = generate_batch_personal_questions(
            applicants_data=applicants_data,
            job_posting=job_posting,
            company_name=actual_company_name
        )
        
        result = {
            "message": "ì„œë¥˜ í•©ê²©ì ê°œì¸ë³„ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ",
            "job_post_id": job_post_id,
            "company_name": actual_company_name,
            "total_applicants": len(passed_applicants),
            "personal_questions": batch_questions.get("personal_questions", {})
        }
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/analysis-questions", response_model=Dict[str, Any])
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_analysis_questions(request: IntegratedQuestionRequest, db: Session = Depends(get_db)):
    """
    ë‹¤ì–‘í•œ ì§ë¬´ ì—­ëŸ‰(ì‹¤ë¬´, ë¬¸ì œí•´ê²°, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ì„±ì¥ ê°€ëŠ¥ì„± ë“±) í‰ê°€ ì§ˆë¬¸ í†µí•© API
    """
    try:
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)

        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)

        from agent.agents.interview_question_node import generate_advanced_competency_questions

        competency_questions = generate_advanced_competency_questions(resume_text=resume_text, job_info=job_info)

        result = {"competency_questions": competency_questions}
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ê³µê³ /ì§ë¬´/íšŒì‚¬ ê¸°ì¤€ì˜ ì‹¤ë¬´ì§„ ê³µí†µ ì§ˆë¬¸ ìƒì„± API
@router.post("/job-common-questions", response_model=Dict[str, Any])
@redis_cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ (ê³µí†µ ì§ˆë¬¸)
async def generate_job_common_questions(
    job_post_id: int,
    company_name: str = "",
    db: Session = Depends(get_db)
):
    """
    ê³µê³ /ì§ë¬´/íšŒì‚¬ ê¸°ì¤€ì˜ ì‹¤ë¬´ì§„ ê³µí†µ ì§ˆë¬¸ ìƒì„± API
    (ì§€ì›ìë³„ì´ ì•„ë‹Œ, ëª¨ë“  ì§€ì›ìì—ê²Œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì§ë¬´ ì¤‘ì‹¬ ì§ˆë¬¸)
    """
    job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
    if not job_post:
        raise HTTPException(status_code=404, detail="Job post not found")
    job_info = parse_job_post_data(job_post)
    from agent.agents.interview_question_node import generate_job_question_bundle
    # resume_text ì—†ì´(ê³µí†µ ì§ˆë¬¸)
    question_bundle = await generate_job_question_bundle(
        resume_text="",
        job_info=job_info,
        company_name=company_name,
        job_matching_info=""
    )
    result = {"question_bundle": question_bundle}
    return result

# --- ê³µê³  ê¸°ë°˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ---
@router.post("/interview-checklist/job-based", response_model=JobBasedChecklistResponse)
@redis_cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ (ê³µê³  ê¸°ë°˜)
async def generate_job_based_checklist(request: JobBasedChecklistRequest, db: Session = Depends(get_db)):
    try:
        job_post = db.query(JobPost).filter(JobPost.id == request.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
        job_info = parse_job_post_data(job_post)
        from agent.agents.interview_question_node import generate_interview_checklist
        checklist_result = await generate_interview_checklist(
            resume_text="",
            job_info=job_info,
            company_name=request.company_name or ""
        )
        return checklist_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# --- ê³µê³  ê¸°ë°˜ ê°•ì /ì•½ì  ---
@router.post("/strengths-weaknesses/job-based", response_model=JobBasedStrengthsResponse)
@redis_cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ (ê³µê³  ê¸°ë°˜)
async def analyze_job_based_strengths_weaknesses(request: JobBasedStrengthsRequest, db: Session = Depends(get_db)):
    try:
        job_post = db.query(JobPost).filter(JobPost.id == request.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
        job_info = parse_job_post_data(job_post)
        from agent.agents.interview_question_node import analyze_candidate_strengths_weaknesses
        analysis_result = await analyze_candidate_strengths_weaknesses(
            resume_text="",
            job_info=job_info,
            company_name=request.company_name or ""
        )
        return analysis_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# --- ê³µê³  ê¸°ë°˜ ê°€ì´ë“œë¼ì¸ ---
@router.post("/interview-guideline/job-based", response_model=JobBasedGuidelineResponse)
@redis_cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ (ê³µê³  ê¸°ë°˜)
async def generate_job_based_guideline(request: JobBasedGuidelineRequest, db: Session = Depends(get_db)):
    try:
        job_post = db.query(JobPost).filter(JobPost.id == request.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
        job_info = parse_job_post_data(job_post)
        from agent.agents.interview_question_node import generate_interview_guideline
        guideline_result = generate_interview_guideline(
            resume_text="",
            job_info=job_info,
            company_name=request.company_name or ""
        )
        return guideline_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# --- ê³µê³  ê¸°ë°˜ í‰ê°€ ê¸°ì¤€ (ì¤‘ë³µ ì œê±°) ---

# === ì„ì›ë©´ì ‘ ì§ˆë¬¸ ìƒì„± API ===
class ExecutiveInterviewRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class ExecutiveInterviewResponse(BaseModel):
    questions: str
    interview_type: str = "executive"

# === AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± API ===
class AiInterviewRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None

class AiInterviewResponse(BaseModel):
    questions: str
    interview_type: str = "ai"

class AiInterviewSaveRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None
    save_to_db: bool = True  # DBì— ì €ì¥í• ì§€ ì—¬ë¶€

class AiInterviewSaveResponse(BaseModel):
    questions: str
    interview_type: str = "ai"
    saved_questions_count: int
    message: str

@router.post("/ai-interview", response_model=AiInterviewResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_ai_interview_questions(request: AiInterviewRequest, db: Session = Depends(get_db)):
    """AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©, DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (DB ì €ì¥ ì—†ìŒ)
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬",
            applicant_name=request.name or "",
            interview_type="ai"
        )
        
        # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
        questions = workflow_result.get("questions", [])
        question_text = "\n".join(questions) if questions else "ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return {
            "questions": question_text,
            "interview_type": "ai",
            "workflow_result": {
                "total_questions": len(questions),
                "execution_time": workflow_result.get("execution_time", 0),
                "generated_at": workflow_result.get("generated_at", "")
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/ai-interview-save", response_model=AiInterviewSaveResponse)
async def generate_and_save_ai_interview_questions(request: AiInterviewSaveRequest, db: Session = Depends(get_db)):
    """AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ë° DB ì €ì¥"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (fallback ì‚¬ìš©)
        try:
            # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„±
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
            from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
            
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            workflow_result = generate_comprehensive_interview_questions(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                applicant_name=request.name or "",
                interview_type="ai"
            )
            
            # ê²°ê³¼ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
            generated_questions = workflow_result.get("generated_questions", {})
            ai_questions = generated_questions.get("ai", {})
            
            # ì§ˆë¬¸ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            all_questions = []
            for category, questions in ai_questions.items():
                if isinstance(questions, list):
                    all_questions.extend(questions)
                elif isinstance(questions, dict) and "questions" in questions:
                    all_questions.extend(questions["questions"])
            
        except Exception as e:
            print(f"AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
            # Fallback: ëœë¤ ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©
            from app.data.general_interview_questions import get_random_general_questions
            
            # 7ê°œì˜ ëœë¤ ì¼ë°˜ ì§ˆë¬¸ ì„ íƒ
            random_questions = get_random_general_questions(7)
            all_questions = [q["question"] for q in random_questions]
            
            # ì¶”ê°€ë¡œ 3ê°œì˜ ê¸°ë³¸ ì§ˆë¬¸ ì¶”ê°€ (ì´ 10ê°œ)
            additional_questions = [
                "ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.",
                "ì´ ì§ë¬´ì— ì§€ì›í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "ë³¸ì¸ì˜ ê°•ì ê³¼ ì•½ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            ]
            all_questions.extend(additional_questions)
        
        question_text = "\n".join(all_questions) if all_questions else "ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # DBì— ì €ì¥
        saved_count = 0
        if request.save_to_db and all_questions:
            from app.models.interview_question import InterviewQuestion, QuestionType
            
            # job_post_id ì°¾ê¸°
            job_post_id = None
            if request.application_id:
                application = db.query(Application).filter(Application.id == request.application_id).first()
                if application:
                    job_post_id = application.job_post_id
            
            if job_post_id:
                # ê¸°ì¡´ AI ë©´ì ‘ ì§ˆë¬¸ ì‚­ì œ (job_post_id ê¸°ë°˜, ì¤‘ë³µ ë°©ì§€)
                db.query(InterviewQuestion).filter(
                    InterviewQuestion.job_post_id == job_post_id,
                    InterviewQuestion.type == QuestionType.AI_INTERVIEW
                ).delete()
                
                # ìƒˆë¡œìš´ ì§ˆë¬¸ë“¤ ì €ì¥ (job_post_id ê¸°ë°˜, application_idëŠ” NULL)
                for i, question in enumerate(all_questions):
                    # ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ê²°ì •
                    category = "common"
                    if i < 3:
                        category = "common"
                    elif i < 6:
                        category = "personal"
                    elif i < 8:
                        category = "company"
                    else:
                        category = "job"
                    
                    # DBì— ì €ì¥ (AI ë©´ì ‘ì€ job_post_id ê¸°ë°˜, application_idëŠ” NULL)
                    interview_question = InterviewQuestion(
                        application_id=None,  # AI ë©´ì ‘ì€ ê³µê³ ë³„ ê³µìœ 
                        job_post_id=job_post_id,
                        type=QuestionType.AI_INTERVIEW,
                        question_text=question,
                        category=category,
                        difficulty="medium"  # AI ë©´ì ‘ì€ ê¸°ë³¸ì ìœ¼ë¡œ medium
                    )
                    db.add(interview_question)
                    saved_count += 1
                
                db.commit()
            
            # ìºì‹œ ë¬´íš¨í™”
            try:
                from app.core.cache import invalidate_cache
                # ê´€ë ¨ ìºì‹œ í‚¤ë“¤ ë¬´íš¨í™”
                cache_patterns_to_clear = [
                    f"cache:applications:job:{request.application_id}:*",
                    f"cache:interview-questions:application:{request.application_id}:*",
                    f"cache:interview-questions:job:{request.application_id}:*"
                ]
                
                for cache_pattern in cache_patterns_to_clear:
                    try:
                        invalidate_cache(cache_pattern)
                        print(f"ìºì‹œ ë¬´íš¨í™” ì™„ë£Œ: {cache_pattern}")
                    except Exception as cache_error:
                        print(f"ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {cache_pattern} - {cache_error}")
            except Exception as cache_error:
                print(f"ìºì‹œ ë¬´íš¨í™” ì¤‘ ì˜¤ë¥˜: {cache_error}")
        
        return {
            "questions": question_text,
            "interview_type": "ai",
            "saved_questions_count": saved_count,
            "message": f"AI ë©´ì ‘ ì§ˆë¬¸ {saved_count}ê°œê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤." if saved_count > 0 else "ì§ˆë¬¸ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/application/{application_id}/ai-questions")
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (AI ì§ˆë¬¸ ì¡°íšŒ)
def get_ai_interview_questions(application_id: int, db: Session = Depends(get_db)):
    """íŠ¹ì • ì§€ì›ìì˜ AI ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ (job_post_id ê¸°ë°˜)"""
    try:
        from app.models.interview_question import InterviewQuestion, QuestionType
        
        # ì§€ì›ìì˜ job_post_id ì°¾ê¸°
        application = db.query(Application).filter(Application.id == application_id).first()
        if not application:
            raise HTTPException(status_code=404, detail="Application not found")
        
        # job_post_id ê¸°ë°˜ìœ¼ë¡œ AI ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ
        questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.job_post_id == application.job_post_id,
            InterviewQuestion.type == QuestionType.AI_INTERVIEW
        ).order_by(InterviewQuestion.category, InterviewQuestion.id).all()
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        grouped_questions = {}
        for question in questions:
            category = question.category or "common"
            if category not in grouped_questions:
                grouped_questions[category] = []
            grouped_questions[category].append({
                "id": question.id,
                "question_text": question.question_text,
                "type": question.type.value,
                "category": question.category,
                "difficulty": question.difficulty,
                "created_at": question.created_at
            })
        
        return {
            "application_id": application_id,
            "job_post_id": application.job_post_id,
            "interview_stage": "ai",
            "questions": grouped_questions,
            "total_count": len(questions)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/job/{job_post_id}/ai-questions")
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (AI ì§ˆë¬¸ ì¡°íšŒ)
def get_ai_interview_questions_by_job(job_post_id: int, db: Session = Depends(get_db)):
    """ê³µê³ ë³„ AI ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ (ê³µí†µ + ì§ë¬´ë³„ + ê²Œì„)"""
    try:
        from app.models.interview_question import InterviewQuestion, QuestionType
        from app.models.job import JobPost
        
        # ê³µê³  ì •ë³´ ì¡°íšŒ
        job = db.query(JobPost).filter(JobPost.id == job_post_id).first()
        if not job:
            raise HTTPException(status_code=404, detail="Job post not found")
        
        # 1. ì§ë¬´ë³„ ì§ˆë¬¸ ì¡°íšŒ (job_post_id ê¸°ë°˜)
        job_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.job_post_id == job_post_id,
            InterviewQuestion.type == QuestionType.AI_INTERVIEW,
            InterviewQuestion.category == "job_specific"
        ).order_by(InterviewQuestion.id).all()
        
        # 2. ê³µí†µ ì§ˆë¬¸ ì¡°íšŒ (job_post_id ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½)
        common_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.job_post_id == job_post_id,
            InterviewQuestion.type == QuestionType.AI_INTERVIEW,
            InterviewQuestion.category == "common"
        ).order_by(InterviewQuestion.id).all()
        
        # 3. ê²Œì„ í…ŒìŠ¤íŠ¸ ì¡°íšŒ (job_post_id ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½)
        game_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.job_post_id == job_post_id,
            InterviewQuestion.type == QuestionType.AI_INTERVIEW,
            InterviewQuestion.category == "game_test"
        ).order_by(InterviewQuestion.id).all()
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        grouped_questions = {
            "common": [
                {
                    "id": q.id,
                    "question_text": q.question_text,
                    "type": q.type.value,
                    "category": q.category,
                    "difficulty": q.difficulty,
                    "created_at": q.created_at
                } for q in common_questions
            ],
            "job_specific": [
                {
                    "id": q.id,
                    "question_text": q.question_text,
                    "type": q.type.value,
                    "category": q.category,
                    "difficulty": q.difficulty,
                    "created_at": q.created_at
                } for q in job_questions
            ],
            "game_test": [
                {
                    "id": q.id,
                    "question_text": q.question_text,
                    "type": q.type.value,
                    "category": q.category,
                    "difficulty": q.difficulty,
                    "created_at": q.created_at
                } for q in game_questions
            ]
        }
        
        total_count = len(common_questions) + len(job_questions) + len(game_questions)
        
        return {
            "job_post_id": job_post_id,
            "company_id": job.company_id if job else None,
            "interview_stage": "ai",
            "questions": grouped_questions,
            "total_count": total_count,
            "breakdown": {
                "common": len(common_questions),
                "job_specific": len(job_questions),
                "game_test": len(game_questions)
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/job/{job_post_id}/common-questions")
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (ê³µí†µ ì§ˆë¬¸ ì¡°íšŒ)
def get_common_questions_for_job_post(
    job_post_id: int,
    db: Session = Depends(get_db)
):
    """ê³µê³ ë³„ ê³µí†µ ì§ˆë¬¸ ì¡°íšŒ"""
    try:
        # í•´ë‹¹ ê³µê³ ì˜ ì²« ë²ˆì§¸ ì§€ì›ìì—ê²Œ ìƒì„±ëœ ê³µí†µ ì§ˆë¬¸ ì¡°íšŒ
        first_application = db.query(Application).filter(
            Application.job_post_id == job_post_id,
            Application.document_status == DocumentStatus.PASSED.value
        ).first()
        
        if not first_application:
            return {"common_questions": []}
        
        common_questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.application_id == first_application.id,
            InterviewQuestion.type == QuestionType.COMMON
        ).all()
        
        return {
            "common_questions": [
                {
                    "id": q.id,
                    "question_text": q.question_text,
                    "category": q.category,
                    "difficulty": q.difficulty,
                    "created_at": q.created_at.isoformat() if q.created_at else None
                }
                for q in common_questions
            ]
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê³µí†µ ì§ˆë¬¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@router.get("/application/{application_id}/questions")
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (ì§ˆë¬¸ ì¡°íšŒ)
def get_questions_for_application(
    application_id: int,
    question_type: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """ì§€ì›ìë³„ ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ"""
    try:
        # ì§€ì›ì ì •ë³´ í™•ì¸
        application = db.query(Application).filter(Application.id == application_id).first()
        if not application:
            raise HTTPException(status_code=404, detail="ì§€ì›ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì§ˆë¬¸ ì¡°íšŒ
        query = db.query(InterviewQuestion).filter(
            InterviewQuestion.application_id == application_id
        )
        
        if question_type:
            query = query.filter(InterviewQuestion.type == QuestionType(question_type))
        
        questions = query.all()
        
        # íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”
        grouped_questions = {}
        for question in questions:
            question_type_key = question.type.value
            if question_type_key not in grouped_questions:
                grouped_questions[question_type_key] = []
            
            grouped_questions[question_type_key].append({
                "id": question.id,
                "question_text": question.question_text,
                "category": question.category,
                "difficulty": question.difficulty,
                "created_at": question.created_at.isoformat() if question.created_at else None
            })
        
        return {
            "application_id": application_id,
            "questions": grouped_questions,
            "total_count": len(questions)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@router.post("/job/{job_post_id}/generate-common-questions")
def generate_common_questions_for_job_post(
    job_post_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """ê³µê³ ë³„ ê³µí†µ ì§ˆë¬¸ ìˆ˜ë™ ìƒì„±"""
    try:
        # ê³µê³  ì •ë³´ ì¡°íšŒ
        job_post = db.query(JobPost).filter(JobPost.id == job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="ê³µê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        company_name = job_post.company.name if job_post.company else ""
        job_info = parse_job_post_data(job_post)
        
        # ê³µí†µ ì§ˆë¬¸ ìƒì„±
        questions = InterviewQuestionService.generate_common_questions_for_job_post(
            db=db,
            job_post_id=job_post_id,
            company_name=company_name,
            job_info=job_info
        )
        
        return {
            "message": f"ê³µí†µ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ: {len(questions)}ê°œ",
            "questions_count": len(questions)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê³µí†µ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@router.post("/application/{application_id}/generate-individual-questions")
def generate_individual_questions_for_application(
    application_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """ì§€ì›ìë³„ ê°œë³„ ì§ˆë¬¸ ìˆ˜ë™ ìƒì„±"""
    try:
        # ì§€ì›ì ì •ë³´ í™•ì¸
        application = db.query(Application).filter(Application.id == application_id).first()
        if not application:
            raise HTTPException(status_code=404, detail="ì§€ì›ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê³µê³  ì •ë³´ ì¡°íšŒ
        job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="ê³µê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        company_name = job_post.company.name if job_post.company else ""
        job_info = parse_job_post_data(job_post)
        
        # ê°œë³„ ì§ˆë¬¸ ìƒì„±
        questions = InterviewQuestionService.generate_individual_questions_for_applicant(
            db=db,
            application_id=application_id,
            job_info=job_info,
            company_name=company_name
        )
        
        return {
            "message": f"ê°œë³„ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ: {len(questions)}ê°œ",
            "questions_count": len(questions)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°œë³„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@router.get("/job/{job_post_id}/questions-status")
@redis_cache(expire=60)  # 1ë¶„ ìºì‹œ (ìƒíƒœ ì¡°íšŒ)
def get_questions_generation_status(
    job_post_id: int,
    db: Session = Depends(get_db)
):
    """ê³µê³ ë³„ ì§ˆë¬¸ ìƒì„± ìƒíƒœ ì¡°íšŒ"""
    try:
        # í•´ë‹¹ ê³µê³ ì˜ ì§€ì›ìë“¤ ì¡°íšŒ
        applications = db.query(Application).filter(
            Application.job_post_id == job_post_id,
            Application.document_status == DocumentStatus.PASSED.value
        ).all()
        
        if not applications:
            return {
                "job_post_id": job_post_id,
                "total_applications": 0,
                "common_questions_generated": False,
                "individual_questions_generated": 0,
                "total_questions": 0
            }
        
        # ê³µí†µ ì§ˆë¬¸ ìƒì„± ì—¬ë¶€ í™•ì¸
        first_app = applications[0]
        common_questions_count = db.query(InterviewQuestion).filter(
            InterviewQuestion.application_id == first_app.id,
            InterviewQuestion.type == QuestionType.COMMON
        ).count()
        
        # ê°œë³„ ì§ˆë¬¸ ìƒì„±ëœ ì§€ì›ì ìˆ˜ í™•ì¸
        individual_questions_count = 0
        total_questions = 0
        
        for app in applications:
            app_questions = db.query(InterviewQuestion).filter(
                InterviewQuestion.application_id == app.id,
                InterviewQuestion.type != QuestionType.COMMON
            ).count()
            
            if app_questions > 0:
                individual_questions_count += 1
                total_questions += app_questions
        
        return {
            "job_post_id": job_post_id,
            "total_applications": len(applications),
            "common_questions_generated": common_questions_count > 0,
            "common_questions_count": common_questions_count,
            "individual_questions_generated": individual_questions_count,
            "total_questions": total_questions + common_questions_count
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# AI ë„êµ¬ í†µí•© API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
class AiToolsRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    company_name: Optional[str] = None
    name: Optional[str] = None
    interview_stage: Optional[str] = None
    evaluator_type: Optional[str] = None

class AiToolsResponse(BaseModel):
    evaluation_tools: dict
    questions: Optional[str] = None

@router.post("/ai-tools", response_model=AiToolsResponse)
@redis_cache(expire=1800)  # 30ë¶„ ìºì‹œ (LLM ìƒì„± ê²°ê³¼)
async def generate_ai_tools(request: AiToolsRequest, db: Session = Depends(get_db)):
    """AI ë©´ì ‘ì„ ìœ„í•œ í†µí•© ë„êµ¬ ìƒì„± (ì²´í¬ë¦¬ìŠ¤íŠ¸, ê°•ì /ì•½ì , ê°€ì´ë“œë¼ì¸, í‰ê°€ ê¸°ì¤€)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ì¡°íšŒ
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="ì´ë ¥ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # Spec ì •ë³´ ì¡°íšŒ
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        
        # í†µí•© ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ìƒì„±
        resume_text = combine_resume_and_specs(resume, specs)
        
        # AI ë©´ì ‘ ë„êµ¬ ìƒì„± í”„ë¡¬í”„íŠ¸
        ai_tools_prompt = f"""
ë‹¤ìŒ ì§€ì›ìì˜ ì´ë ¥ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ AI ë©´ì ‘ì„ ìœ„í•œ ì¢…í•©ì ì¸ í‰ê°€ ë„êµ¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ì§€ì›ì ì •ë³´:
- ì´ë¦„: {request.name or "ì•Œ ìˆ˜ ì—†ìŒ"}
- íšŒì‚¬: {request.company_name or "ì•Œ ìˆ˜ ì—†ìŒ"}
- ë©´ì ‘ ë‹¨ê³„: {request.interview_stage or "AI ë©´ì ‘"}

ì´ë ¥ì„œ ë‚´ìš©:
{resume_text}

ë‹¤ìŒ 4ê°€ì§€ ë„êµ¬ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”:

1. ë©´ì ‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ (pre_interview_checklist, during_interview_checklist, post_interview_checklist, red_flags_to_watch, green_flags_to_confirm)
2. ê°•ì /ì•½ì  ë¶„ì„ (strengths, weaknesses, development_areas, competitive_advantages)
3. ë©´ì ‘ ê°€ì´ë“œë¼ì¸ (interview_approach, key_questions_by_category, evaluation_criteria, time_allocation, follow_up_questions)
4. í‰ê°€ ê¸°ì¤€ (suggested_criteria, weight_recommendations, evaluation_questions, scoring_guidelines)

ì‘ë‹µ í˜•ì‹:
{{
    "evaluation_tools": {{
        "checklist": {{
            "pre_interview_checklist": ["í•­ëª©1", "í•­ëª©2"],
            "during_interview_checklist": ["í•­ëª©1", "í•­ëª©2"],
            "post_interview_checklist": ["í•­ëª©1", "í•­ëª©2"],
            "red_flags_to_watch": ["ì£¼ì˜ì‚¬í•­1", "ì£¼ì˜ì‚¬í•­2"],
            "green_flags_to_confirm": ["ê¸ì •ì‹ í˜¸1", "ê¸ì •ì‹ í˜¸2"]
        }},
        "strengths_weaknesses": {{
            "strengths": [{{"area": "ê¸°ìˆ ì—­ëŸ‰", "description": "ì„¤ëª…", "evidence": "ê·¼ê±°"}}],
            "weaknesses": [{{"area": "ê²½í—˜ë¶€ì¡±", "description": "ì„¤ëª…", "suggestion": "ê°œì„ ë°©ì•ˆ"}}],
            "development_areas": ["ê°œë°œì˜ì—­1", "ê°œë°œì˜ì—­2"],
            "competitive_advantages": ["ê²½ìŸìš°ìœ„1", "ê²½ìŸìš°ìœ„2"]
        }},
        "guideline": {{
            "interview_approach": "ë©´ì ‘ ì ‘ê·¼ ë°©ì‹",
            "key_questions_by_category": {{
                "ê¸°ìˆ ì—­ëŸ‰": ["ì§ˆë¬¸1", "ì§ˆë¬¸2"],
                "í”„ë¡œì íŠ¸ê²½í—˜": ["ì§ˆë¬¸1", "ì§ˆë¬¸2"]
            }},
            "evaluation_criteria": [{{"criterion": "ê¸°ì¤€", "description": "ì„¤ëª…", "weight": 0.3}}],
            "time_allocation": {{"ê¸°ìˆ ì§ˆë¬¸": 0.4, "ê²½í—˜ì§ˆë¬¸": 0.3, "ì†Œí”„íŠ¸ìŠ¤í‚¬": 0.3}},
            "follow_up_questions": ["í›„ì†ì§ˆë¬¸1", "í›„ì†ì§ˆë¬¸2"]
        }},
        "evaluation_criteria": {{
            "suggested_criteria": [{{"criterion": "ê¸°ì¤€", "description": "ì„¤ëª…", "weight": 0.3}}],
            "weight_recommendations": [{{"category": "ì¹´í…Œê³ ë¦¬", "weight": 0.3, "reason": "ì´ìœ "}}],
            "evaluation_questions": ["í‰ê°€ì§ˆë¬¸1", "í‰ê°€ì§ˆë¬¸2"],
            "scoring_guidelines": {{"A": "90-100ì ", "B": "80-89ì ", "C": "70-79ì ", "D": "60-69ì ", "F": "60ì  ë¯¸ë§Œ"}}
        }}
    }}
}}
"""
        
        # OpenAI API í˜¸ì¶œ
        import openai
        import os
        api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        client = openai.OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": ai_tools_prompt}],
            temperature=0.7,
            max_tokens=3000
        )
        
        # ì‘ë‹µ íŒŒì‹±
        try:
            content = response.choices[0].message.content.strip()
            print(f"OpenAI ì‘ë‹µ: {content}")
            
            # JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
            if "```json" in content:
                json_start = content.find("```json") + 7
                json_end = content.find("```", json_start)
                if json_end != -1:
                    content = content[json_start:json_end].strip()
            
            tools_data = json.loads(content)
            return AiToolsResponse(
                evaluation_tools=tools_data.get("evaluation_tools", {}),
                questions=None
            )
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì‘ë‹µ ë‚´ìš©: {response.choices[0].message.content}")
            # ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return AiToolsResponse(
                evaluation_tools={
                    "checklist": {
                        "pre_interview_checklist": ["ì´ë ¥ì„œ ê²€í† ", "ê¸°ìˆ  ìŠ¤íƒ í™•ì¸"],
                        "during_interview_checklist": ["ê¸°ìˆ  ì§ˆë¬¸", "ê²½í—˜ í™•ì¸"],
                        "post_interview_checklist": ["í‰ê°€ ê¸°ë¡", "ê²°ê³¼ ì •ë¦¬"],
                        "red_flags_to_watch": ["ê¸°ìˆ  ë¶€ì¡±", "ê²½í—˜ ë¶€ì¡±"],
                        "green_flags_to_confirm": ["ê¸°ìˆ  ìš°ìˆ˜", "ê²½í—˜ í’ë¶€"]
                    },
                    "strengths_weaknesses": {
                        "strengths": [{"area": "ê¸°ìˆ ì—­ëŸ‰", "description": "ê¸°ìˆ  ìŠ¤íƒì´ ë‹¤ì–‘í•¨", "evidence": "ì´ë ¥ì„œ ê¸°ë°˜"}],
                        "weaknesses": [{"area": "ê²½í—˜ë¶€ì¡±", "description": "ì‹¤ë¬´ ê²½í—˜ ë¶€ì¡±", "suggestion": "í”„ë¡œì íŠ¸ ê²½í—˜ í™•ëŒ€"}],
                        "development_areas": ["ì‹¤ë¬´ ê²½í—˜", "íŒ€ì›Œí¬"],
                        "competitive_advantages": ["ê¸°ìˆ  ë‹¤ì–‘ì„±", "í•™ìŠµ ëŠ¥ë ¥"]
                    },
                    "guideline": {
                        "interview_approach": "ê¸°ìˆ  ì¤‘ì‹¬ ë©´ì ‘",
                        "key_questions_by_category": {
                            "ê¸°ìˆ ì—­ëŸ‰": ["ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€?", "í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–»ê²Œ í™œìš©í–ˆë‚˜?"],
                            "í”„ë¡œì íŠ¸ê²½í—˜": ["ê°€ì¥ ì–´ë ¤ì› ë˜ í”„ë¡œì íŠ¸ëŠ”?", "íŒ€ì—ì„œì˜ ì—­í• ì€?"]
                        },
                        "evaluation_criteria": [{"criterion": "ê¸°ìˆ ì—­ëŸ‰", "description": "ê¸°ìˆ  ìŠ¤íƒ ìˆ™ë ¨ë„", "weight": 0.4}],
                        "time_allocation": {"ê¸°ìˆ ì§ˆë¬¸": 0.5, "ê²½í—˜ì§ˆë¬¸": 0.3, "ì†Œí”„íŠ¸ìŠ¤í‚¬": 0.2},
                        "follow_up_questions": ["êµ¬ì²´ì ì¸ ê¸°ìˆ  í™œìš© ì‚¬ë¡€ëŠ”?", "ë¬¸ì œ í•´ê²° ê³¼ì •ì€?"]
                    },
                    "evaluation_criteria": {
                        "suggested_criteria": [{"criterion": "ê¸°ìˆ ì—­ëŸ‰", "description": "ê¸°ìˆ  ìŠ¤íƒ ìˆ™ë ¨ë„", "weight": 0.4}],
                        "weight_recommendations": [{"category": "ê¸°ìˆ ì—­ëŸ‰", "weight": 0.4, "reason": "í•µì‹¬ ì—­ëŸ‰"}],
                        "evaluation_questions": ["ê¸°ìˆ  ìŠ¤íƒ ìˆ™ë ¨ë„ëŠ”?", "í”„ë¡œì íŠ¸ ê²½í—˜ì€?"],
                        "scoring_guidelines": {"A": "90-100ì ", "B": "80-89ì ", "C": "70-79ì ", "D": "60-69ì ", "F": "60ì  ë¯¸ë§Œ"}
                    }
                }
            )
        
    except Exception as e:
        print(f"AI ë„êµ¬ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"AI ë„êµ¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@router.get("/application/{application_id}/logs")
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (ë¡œê·¸ ì¡°íšŒ)
def get_interview_question_logs_by_application(
    application_id: int, 
    interview_type: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """íŠ¹ì • ì§€ì›ìì˜ ë©´ì ‘ ì§ˆë¬¸+ë‹µë³€(í…ìŠ¤íŠ¸/ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤) ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (DBì—ì„œ ì½ê¸°ë§Œ)"""
    query = db.query(InterviewQuestionLog).filter(InterviewQuestionLog.application_id == application_id)
    if interview_type:
        query = query.filter(InterviewQuestionLog.interview_type == interview_type)
    logs = query.order_by(InterviewQuestionLog.created_at).all()

    result = []
    for log in logs:
        item = {
            "question_id": log.question_id,
            "interview_type": log.interview_type.value if log.interview_type else "AI_INTERVIEW",
            "question_text": log.question_text,
            "answer_text": log.answer_text,
            "answer_audio_url": log.answer_audio_url,
            "answer_video_url": log.answer_video_url,
            "answer_text_transcribed": log.answer_text_transcribed,
            "emotion": log.emotion,
            "attitude": log.attitude,
            "answer_score": log.answer_score,
            "answer_feedback": log.answer_feedback,
            "created_at": log.created_at,
            "updated_at": log.updated_at
        }
        result.append(item)
    return result

@router.get("/application/{application_id}/logs/statistics")
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (í†µê³„ ì¡°íšŒ)
def get_interview_logs_statistics(application_id: int, db: Session = Depends(get_db)):
    """íŠ¹ì • ì§€ì›ìì˜ ë©´ì ‘ ìœ í˜•ë³„ í†µê³„ ë°˜í™˜"""
    # ë©´ì ‘ ìœ í˜•ë³„ ê°œìˆ˜ ì¡°íšŒ
    stats = db.query(
        InterviewQuestionLog.interview_type,
        func.count(InterviewQuestionLog.id).label('count')
    ).filter(
        InterviewQuestionLog.application_id == application_id
    ).group_by(
        InterviewQuestionLog.interview_type
    ).all()
    
    # ì „ì²´ í†µê³„
    total_count = db.query(InterviewQuestionLog).filter(
        InterviewQuestionLog.application_id == application_id
    ).count()
    
    return {
        "total_interviews": total_count,
        "by_type": [
            {
                "interview_type": stat.interview_type.value if stat.interview_type else "AI_INTERVIEW",
                "count": stat.count
            }
            for stat in stats
        ]
    }

@router.post("/application/{application_id}/evaluate-audio")
async def evaluate_audio(
    application_id: int,
    question_id: int,  # ì§ˆë¬¸ IDë„ í”„ë¡ íŠ¸ì—ì„œ ê°™ì´ ë³´ë‚´ì•¼ DB ì €ì¥ ê°€ëŠ¥
    question_text: str,
    audio_file: UploadFile = File(...)
):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ agent ì»¨í…Œì´ë„ˆì— ì „ë‹¬í•˜ì—¬ ì‹¤ì‹œê°„ ë¶„ì„ í›„ ê²°ê³¼ ë°˜í™˜
    """
    import httpx
    
    # 1. ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(await audio_file.read())
        tmp_path = tmp.name

    try:
        # 2. agent ì»¨í…Œì´ë„ˆì— HTTP ìš”ì²­ìœ¼ë¡œ ë¶„ì„ ìš”ì²­
        async with httpx.AsyncClient() as client:
            with open(tmp_path, "rb") as f:
                files = {"audio_file": f}
                data = {
                    "application_id": application_id,
                    "question_id": question_id,
                    "question_text": question_text
                }
                response = await client.post(
                    "http://agent:8001/evaluate-audio",
                    files=files,
                    data=data
                )
                result = response.json()
        
        # 3. DB ì €ì¥
        db = next(get_db())  # Depends ì‚¬ìš© ë¶ˆê°€ ì‹œ ì§ì ‘ í˜¸ì¶œ
        log = db.query(InterviewQuestionLog).filter(
            InterviewQuestionLog.application_id == application_id,
            InterviewQuestionLog.question_id == question_id
        ).first()
        if log:
            log.answer_text_transcribed = result.get("answer_text_transcribed")
            log.emotion = result.get("emotion")
            log.attitude = result.get("attitude")
            log.answer_score = result.get("answer_score")
            log.answer_feedback = result.get("answer_feedback")
            db.commit()
        
        return result
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(tmp_path):
            os.remove(tmp_path)

# --- ê³µê³  ê¸°ë°˜ í‰ê°€ ê¸°ì¤€ ---
@router.post("/evaluation-criteria/job-based", response_model=JobBasedCriteriaResponse)
async def create_job_based_evaluation_criteria(request: JobBasedCriteriaRequest, db: Session = Depends(get_db)):
    """ê³µê³  ê¸°ë°˜ í‰ê°€í•­ëª© ìƒì„± ë° DB ì €ì¥"""
    try:
        job_post = db.query(JobPost).filter(JobPost.id == request.job_post_id).first()
        if not job_post:
            raise HTTPException(status_code=404, detail="Job post not found")
        
        job_info = parse_job_post_data(job_post)
        
        # LangGraphë¥¼ í†µí•œ í‰ê°€í•­ëª© ìƒì„±
        from agent.agents.interview_question_node import suggest_evaluation_criteria
        criteria_result = suggest_evaluation_criteria(
            resume_text="",
            job_info=job_info,
            company_name=request.company_name or ""
        )
        
        # DB ì €ì¥ì€ ì„ì‹œë¡œ ì œê±° (ì—ëŸ¬ ë””ë²„ê¹… ì¤‘)
        print(f"ğŸ” LangGraph ê²°ê³¼: {criteria_result}")
        
        # DB ì €ì¥ ì‹œë„ (ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ë§Œ ì¶œë ¥)
        try:
            from app.services.evaluation_criteria_service import EvaluationCriteriaService
            from app.schemas.evaluation_criteria import EvaluationCriteriaCreate
            
            print("ğŸ” EvaluationCriteriaService import ì„±ê³µ")
            criteria_service = EvaluationCriteriaService(db)
            print("ğŸ” EvaluationCriteriaService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
            
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            existing_criteria = criteria_service.get_evaluation_criteria_by_job_post(request.job_post_id)
            print(f"ğŸ” ê¸°ì¡´ ë°ì´í„° í™•ì¸: {existing_criteria}")
            
            # LangGraph ê²°ê³¼ë¥¼ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
            suggested_criteria = []
            for item in criteria_result.get("suggested_criteria", []):
                if isinstance(item, dict):
                    suggested_criteria.append({
                        "criterion": item.get("criterion", ""),
                        "description": item.get("description", ""),
                        "max_score": item.get("max_score", 10)
                    })
            
            weight_recommendations = []
            for item in criteria_result.get("weight_recommendations", []):
                if isinstance(item, dict):
                    weight_recommendations.append({
                        "criterion": item.get("criterion", ""),
                        "weight": float(item.get("weight", 0.0)),
                        "reason": item.get("reason", "")
                    })
            
            # Pydantic ëª¨ë¸ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
            suggested_criteria_dict = []
            for item in suggested_criteria:
                suggested_criteria_dict.append({
                    "criterion": item["criterion"],
                    "description": item["description"],
                    "max_score": item["max_score"]
                })
            
            weight_recommendations_dict = []
            for item in weight_recommendations:
                weight_recommendations_dict.append({
                    "criterion": item["criterion"],
                    "weight": item["weight"],
                    "reason": item["reason"]
                })
            
            evaluation_questions = criteria_result.get("evaluation_questions", [])
            if not isinstance(evaluation_questions, list):
                evaluation_questions = []
            
            scoring_guidelines = criteria_result.get("scoring_guidelines", {})
            if not isinstance(scoring_guidelines, dict):
                scoring_guidelines = {}
            
            # evaluation_items ì²˜ë¦¬ (ìƒˆë¡œìš´ êµ¬ì²´ì  í‰ê°€ í•­ëª©)
            evaluation_items = criteria_result.get("evaluation_items", [])
            if not isinstance(evaluation_items, list):
                evaluation_items = []
            
            print(f"ğŸ” ë³€í™˜ëœ ë°ì´í„°:")
            print(f"  - suggested_criteria: {suggested_criteria_dict}")
            print(f"  - weight_recommendations: {weight_recommendations_dict}")
            print(f"  - evaluation_questions: {evaluation_questions}")
            print(f"  - scoring_guidelines: {scoring_guidelines}")
            print(f"  - evaluation_items: {evaluation_items}")
            
            criteria_data = EvaluationCriteriaCreate(
                job_post_id=request.job_post_id,
                company_name=request.company_name,
                suggested_criteria=suggested_criteria_dict,
                weight_recommendations=weight_recommendations_dict,
                evaluation_questions=evaluation_questions,
                scoring_guidelines=scoring_guidelines,
                evaluation_items=evaluation_items  # ìƒˆë¡œìš´ êµ¬ì²´ì  í‰ê°€ í•­ëª© ì¶”ê°€
            )
            print(f"ğŸ” criteria_data ìƒì„± ì„±ê³µ: {criteria_data}")
            
            if existing_criteria:
                # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
                criteria_service.update_evaluation_criteria(request.job_post_id, criteria_data)
                print(f"âœ… í‰ê°€í•­ëª© ì—…ë°ì´íŠ¸ ì™„ë£Œ: job_post_id={request.job_post_id}")
            else:
                # ìƒˆë¡œ ìƒì„±
                criteria_service.create_evaluation_criteria(criteria_data)
                print(f"âœ… í‰ê°€í•­ëª© ìƒì„± ì™„ë£Œ: job_post_id={request.job_post_id}")
                
        except Exception as db_error:
            print(f"âš ï¸ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {db_error}")
            print(f"âš ï¸ ì˜¤ë¥˜ íƒ€ì…: {type(db_error)}")
            import traceback
            print(f"âš ï¸ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ LangGraph ê²°ê³¼ëŠ” ë°˜í™˜
            pass
        
        # evaluation_itemsê°€ í¬í•¨ëœ ì‘ë‹µ ë°˜í™˜
        return JobBasedCriteriaResponse(
            suggested_criteria=criteria_result.get("suggested_criteria", []),
            weight_recommendations=criteria_result.get("weight_recommendations", []),
            evaluation_questions=criteria_result.get("evaluation_questions", []),
            scoring_guidelines=criteria_result.get("scoring_guidelines", {}),
            evaluation_items=criteria_result.get("evaluation_items", [])  # ìƒˆë¡œìš´ êµ¬ì²´ì  í‰ê°€ í•­ëª© ì¶”ê°€
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/evaluation-criteria/job/{job_post_id}", response_model=JobBasedCriteriaResponse)
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (DB ì¡°íšŒ)
async def get_job_based_evaluation_criteria(job_post_id: int, db: Session = Depends(get_db)):
    """ê³µê³ ë³„ ì €ì¥ëœ í‰ê°€í•­ëª© ì¡°íšŒ"""
    try:
        from app.services.evaluation_criteria_service import EvaluationCriteriaService
        
        criteria_service = EvaluationCriteriaService(db)
        criteria = criteria_service.get_evaluation_criteria_by_job_post(job_post_id)
        
        if not criteria:
            raise HTTPException(status_code=404, detail="Evaluation criteria not found for this job post")
        
        return JobBasedCriteriaResponse(
            suggested_criteria=criteria.suggested_criteria,
            weight_recommendations=criteria.weight_recommendations,
            evaluation_questions=criteria.evaluation_questions,
            scoring_guidelines=criteria.scoring_guidelines,
            evaluation_items=criteria.evaluation_items  # ìƒˆë¡œìš´ êµ¬ì²´ì  í‰ê°€ í•­ëª© ì¶”ê°€
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/evaluation-criteria/job/{job_post_id}")
async def delete_job_based_evaluation_criteria(job_post_id: int, db: Session = Depends(get_db)):
    """ê³µê³ ë³„ í‰ê°€í•­ëª© ì‚­ì œ"""
    try:
        from app.services.evaluation_criteria_service import EvaluationCriteriaService
        
        criteria_service = EvaluationCriteriaService(db)
        success = criteria_service.delete_evaluation_criteria(job_post_id)
        
        if not success:
            raise HTTPException(status_code=404, detail="Evaluation criteria not found for this job post")
        
        return {"message": "Evaluation criteria deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/evaluation-criteria/resume-based", response_model=EvaluationCriteriaResponse)
async def create_resume_based_evaluation_criteria(request: EvaluationCriteriaRequest, db: Session = Depends(get_db)):
    """ì´ë ¥ì„œ ê¸°ë°˜ í‰ê°€ ê¸°ì¤€ ìƒì„± ë° DB ì €ì¥"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # ë©´ì ‘ ë‹¨ê³„ë³„ í‰ê°€ ê¸°ì¤€ ìƒì„±
        from agent.agents.interview_question_node import suggest_evaluation_criteria
        
        # ë©´ì ‘ ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        interview_stage = getattr(request, 'interview_stage', 'practical')  # ê¸°ë³¸ê°’: ì‹¤ë¬´ì§„
        
        if interview_stage == 'practical':
            # ì‹¤ë¬´ì§„ ë©´ì ‘: ê¸°ìˆ ì  ì—­ëŸ‰ ì¤‘ì‹¬
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                focus_area="technical_skills"  # ê¸°ìˆ ì  ì—­ëŸ‰ ì¤‘ì‹¬
            )
        elif interview_stage == 'executive':
            # ì„ì›ì§„ ë©´ì ‘: ì¸ì„±/ë¦¬ë”ì‹­ ì¤‘ì‹¬
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬",
                focus_area="leadership_potential"  # ë¦¬ë”ì‹­/ì¸ì„± ì¤‘ì‹¬
            )
        else:
            # ê¸°ë³¸: ì¢…í•©ì  í‰ê°€
            criteria_result = await suggest_evaluation_criteria(
                resume_text=resume_text,
                job_info=job_info,
                company_name=request.company_name or "íšŒì‚¬"
            )
        
        # DBì— ì €ì¥
        print(f"ğŸ” LangGraph ê²°ê³¼: {criteria_result}")
        try:
            from app.services.evaluation_criteria_service import EvaluationCriteriaService
            from app.schemas.evaluation_criteria import EvaluationCriteriaCreate
            
            print("ğŸ” EvaluationCriteriaService import ì„±ê³µ")
            criteria_service = EvaluationCriteriaService(db)
            print("ğŸ” EvaluationCriteriaService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
            
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            existing_criteria = criteria_service.get_evaluation_criteria_by_resume(
                request.resume_id, 
                request.application_id,
                interview_stage
            )
            print(f"ğŸ” ê¸°ì¡´ ë°ì´í„° í™•ì¸: {existing_criteria}")
            
            # LangGraph ê²°ê³¼ë¥¼ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
            suggested_criteria = []
            for item in criteria_result.get("suggested_criteria", []):
                if isinstance(item, dict):
                    suggested_criteria.append({
                        "criterion": item.get("criterion", ""),
                        "description": item.get("description", ""),
                        "max_score": item.get("max_score", 10)
                    })
            
            weight_recommendations = []
            for item in criteria_result.get("weight_recommendations", []):
                if isinstance(item, dict):
                    weight_recommendations.append({
                        "criterion": item.get("criterion", ""),
                        "weight": float(item.get("weight", 0.0)),
                        "reason": item.get("reason", "")
                    })
            
            evaluation_questions = criteria_result.get("evaluation_questions", [])
            if not isinstance(evaluation_questions, list):
                evaluation_questions = []
            
            scoring_guidelines = criteria_result.get("scoring_guidelines", {})
            if not isinstance(scoring_guidelines, dict):
                scoring_guidelines = {}
            
            # evaluation_items ì²˜ë¦¬ (ìƒˆë¡œìš´ êµ¬ì²´ì  í‰ê°€ í•­ëª©)
            evaluation_items = criteria_result.get("evaluation_items", [])
            if not isinstance(evaluation_items, list):
                evaluation_items = []
            
            print(f"ğŸ” ë³€í™˜ëœ ë°ì´í„°:")
            print(f"  - suggested_criteria: {suggested_criteria}")
            print(f"  - weight_recommendations: {weight_recommendations}")
            print(f"  - evaluation_questions: {evaluation_questions}")
            print(f"  - scoring_guidelines: {scoring_guidelines}")
            print(f"  - evaluation_items: {evaluation_items}")

            criteria_data = EvaluationCriteriaCreate(
                job_post_id=None,  # ì´ë ¥ì„œ ê¸°ë°˜ì´ë¯€ë¡œ None
                resume_id=request.resume_id,
                application_id=request.application_id,
                evaluation_type="resume_based",
                company_name=request.company_name,
                suggested_criteria=suggested_criteria,
                weight_recommendations=weight_recommendations,
                evaluation_questions=evaluation_questions,
                scoring_guidelines=scoring_guidelines,
                evaluation_items=evaluation_items  # ìƒˆë¡œìš´ êµ¬ì²´ì  í‰ê°€ í•­ëª© ì¶”ê°€
            )
            print(f"ğŸ” criteria_data ìƒì„± ì„±ê³µ: {criteria_data}")
            
            if existing_criteria:
                # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
                criteria_service.update_evaluation_criteria_by_resume(
                    request.resume_id, 
                    criteria_data,
                    request.application_id,
                    interview_stage
                )
                print(f"âœ… í‰ê°€í•­ëª© ì—…ë°ì´íŠ¸ ì™„ë£Œ: resume_id={request.resume_id}")
            else:
                # ìƒˆë¡œ ìƒì„±
                criteria_service.create_evaluation_criteria(criteria_data)
                print(f"âœ… í‰ê°€í•­ëª© ìƒì„± ì™„ë£Œ: resume_id={request.resume_id}")
                
        except Exception as db_error:
            print(f"âš ï¸ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {db_error}")
            print(f"âš ï¸ ì˜¤ë¥˜ íƒ€ì…: {type(db_error)}")
            import traceback
            print(f"âš ï¸ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ LangGraph ê²°ê³¼ëŠ” ë°˜í™˜
            pass
        
        return criteria_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/evaluation-criteria/resume/{resume_id}", response_model=EvaluationCriteriaResponse)
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ (DB ì¡°íšŒ)
async def get_resume_based_evaluation_criteria(
    resume_id: int, 
    application_id: Optional[int] = None,
    interview_stage: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """ì´ë ¥ì„œ ê¸°ë°˜ ì €ì¥ëœ í‰ê°€ ê¸°ì¤€ ì¡°íšŒ"""
    try:
        from app.services.evaluation_criteria_service import EvaluationCriteriaService
        
        criteria_service = EvaluationCriteriaService(db)
        criteria = criteria_service.get_evaluation_criteria_by_resume(resume_id, application_id, interview_stage)
        
        if not criteria:
            raise HTTPException(status_code=404, detail="Evaluation criteria not found for this resume")
        
        return EvaluationCriteriaResponse(
            suggested_criteria=criteria.suggested_criteria,
            weight_recommendations=criteria.weight_recommendations,
            evaluation_questions=criteria.evaluation_questions,
            scoring_guidelines=criteria.scoring_guidelines,
            evaluation_items=criteria.evaluation_items  # ìƒˆë¡œìš´ êµ¬ì²´ì  í‰ê°€ í•­ëª© ì¶”ê°€
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ìƒˆë¡œìš´ API: ë©´ì ‘ ë‹¨ê³„ë³„ í‰ê°€ í•­ëª© ì¡°íšŒ (Frontendìš©)
class InterviewEvaluationItemsRequest(BaseModel):
    resume_id: int
    application_id: Optional[int] = None
    interview_stage: str  # "practical" ë˜ëŠ” "executive"

class InterviewEvaluationItemsResponse(BaseModel):
    interview_stage: str
    evaluation_items: List[Dict[str, Any]]
    total_weight: float
    max_total_score: int
    message: str = "í‰ê°€ í•­ëª©ì„ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤."

@router.post("/evaluation-items/interview", response_model=InterviewEvaluationItemsResponse)
@redis_cache(expire=300)  # 5ë¶„ ìºì‹œ
async def get_interview_evaluation_items(
    request: InterviewEvaluationItemsRequest,
    db: Session = Depends(get_db)
):
    """ë©´ì ‘ ë‹¨ê³„ë³„ í‰ê°€ í•­ëª© ì¡°íšŒ (ë‹¨ìˆœí™”ëœ ê¸°ë³¸ ê¸°ì¤€)"""
    try:
        # ë‹¨ìˆœí™”ëœ ê¸°ë³¸ í‰ê°€ ê¸°ì¤€ ë°˜í™˜ (DB ì˜ì¡´ì„± ì œê±°)
        if request.interview_stage == "practical":
            evaluation_items = [
                {
                    "item_name": "ê¸°ìˆ  ì—­ëŸ‰",
                    "description": "ì§€ì›ìì˜ ê¸°ìˆ ì  ëŠ¥ë ¥ê³¼ ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - í•´ë‹¹ ë¶„ì•¼ ì „ë¬¸ê°€ ìˆ˜ì¤€",
                        "4ì ": "ì–‘í˜¸ - ì‹¤ë¬´ ê°€ëŠ¥í•œ ìˆ˜ì¤€",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ ìˆ˜ì¤€",
                        "2ì ": "ë¯¸í¡ - ê°œì„  í•„ìš”",
                        "1ì ": "ë¶€ì¡± - í•™ìŠµ í•„ìš”"
                    },
                    "evaluation_questions": [
                        "ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì— ëŒ€í•œ ì´í•´ë„ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì‹¤ë¬´ì—ì„œ í•´ë‹¹ ê¸°ìˆ ì„ ì–´ë–»ê²Œ í™œìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
                    ],
                    "weight": 0.30
                },
                {
                    "item_name": "ê²½í—˜ ë° ì„±ê³¼",
                    "description": "ì§€ì›ìì˜ í”„ë¡œì íŠ¸ ê²½í—˜ê³¼ ì„±ê³¼",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ì„±ê³¼ì™€ ê²½í—˜",
                        "4ì ": "ì–‘í˜¸ - ì¶©ë¶„í•œ ê²½í—˜ê³¼ ì„±ê³¼",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ ê²½í—˜",
                        "2ì ": "ë¯¸í¡ - ê²½í—˜ ë¶€ì¡±",
                        "1ì ": "ë¶€ì¡± - ê²½í—˜ ì—†ìŒ"
                    },
                    "evaluation_questions": [
                        "ê°€ì¥ ì„±ê³µì ì´ì—ˆë˜ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ë³¸ì¸ì˜ ê¸°ì—¬ë„ì™€ ì„±ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.25
                },
                {
                    "item_name": "ë¬¸ì œí•´ê²° ëŠ¥ë ¥",
                    "description": "ì§€ì›ìì˜ ë¬¸ì œ ì¸ì‹ ë° í•´ê²° ëŠ¥ë ¥",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ì°½ì˜ì ì´ê³  íš¨ê³¼ì ì¸ í•´ê²°",
                        "4ì ": "ì–‘í˜¸ - ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ í•´ê²°",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ í•´ê²° ëŠ¥ë ¥",
                        "2ì ": "ë¯¸í¡ - í•´ê²° ëŠ¥ë ¥ ë¶€ì¡±",
                        "1ì ": "ë¶€ì¡± - ë¬¸ì œ ì¸ì‹ ì–´ë ¤ì›€"
                    },
                    "evaluation_questions": [
                        "ì–´ë ¤ìš´ ë¬¸ì œë¥¼ í•´ê²°í•œ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì˜ˆìƒì¹˜ ëª»í•œ ìƒí™©ì— ì–´ë–»ê²Œ ëŒ€ì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
                    ],
                    "weight": 0.20
                },
                {
                    "item_name": "ì˜ì‚¬ì†Œí†µ ë° í˜‘ì—…",
                    "description": "ì§€ì›ìì˜ íŒ€ì›Œí¬ì™€ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ì†Œí†µê³¼ ë¦¬ë”ì‹­",
                        "4ì ": "ì–‘í˜¸ - ì›í™œí•œ ì†Œí†µê³¼ í˜‘ì—…",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ ì†Œí†µ ëŠ¥ë ¥",
                        "2ì ": "ë¯¸í¡ - ì†Œí†µ ëŠ¥ë ¥ ë¶€ì¡±",
                        "1ì ": "ë¶€ì¡± - ì†Œí†µ ì–´ë ¤ì›€"
                    },
                    "evaluation_questions": [
                        "íŒ€ í”„ë¡œì íŠ¸ì—ì„œì˜ ì—­í• ê³¼ ê¸°ì—¬ë„ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ê°ˆë“± ìƒí™©ì„ ì–´ë–»ê²Œ í•´ê²°í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
                    ],
                    "weight": 0.15
                },
                {
                    "item_name": "ì„±ì¥ ì˜ì§€",
                    "description": "ì§€ì›ìì˜ í•™ìŠµ ì˜ì§€ì™€ ì„±ì¥ ê°€ëŠ¥ì„±",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ í•™ìŠµ ì˜ì§€ì™€ ê³„íš",
                        "4ì ": "ì–‘í˜¸ - ì ê·¹ì ì¸ í•™ìŠµ ì˜ì§€",
                        "3ì ": "ë³´í†µ - ê¸°ë³¸ì ì¸ í•™ìŠµ ì˜ì§€",
                        "2ì ": "ë¯¸í¡ - í•™ìŠµ ì˜ì§€ ë¶€ì¡±",
                        "1ì ": "ë¶€ì¡± - í•™ìŠµ ì˜ì§€ ì—†ìŒ"
                    },
                    "evaluation_questions": [
                        "ìƒˆë¡œìš´ ê¸°ìˆ ì„ í•™ìŠµí•œ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì•ìœ¼ë¡œì˜ ì„±ì¥ ê³„íšì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.10
                }
            ]
        else:  # executive
            evaluation_items = [
                {
                    "item_name": "ë¦¬ë”ì‹­",
                    "description": "íŒ€ ë¦¬ë”©ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                        "4ì ": "ì–‘í˜¸ - ì–‘í˜¸í•œ ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                        "3ì ": "ë³´í†µ - ì¼ë°˜ì ì¸ ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                        "2ì ": "ë¯¸í¡ - ì œí•œì ì¸ ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥",
                        "1ì ": "ë¶€ì¡± - ë¦¬ë”ì‹­ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥ ë¶€ì¡±"
                    },
                    "evaluation_questions": [
                        "íŒ€ì„ ì´ëŒì–´ë³¸ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì–´ë ¤ìš´ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦° ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.30
                },
                {
                    "item_name": "ì „ëµì  ì‚¬ê³ ",
                    "description": "ë¹„ì „ ì œì‹œì™€ ì „ëµ ìˆ˜ë¦½ ëŠ¥ë ¥",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥",
                        "4ì ": "ì–‘í˜¸ - ì–‘í˜¸í•œ ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥",
                        "3ì ": "ë³´í†µ - ì¼ë°˜ì ì¸ ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥",
                        "2ì ": "ë¯¸í¡ - ì œí•œì ì¸ ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥",
                        "1ì ": "ë¶€ì¡± - ì „ëµì  ì‚¬ê³ ì™€ ë¹„ì „ ì œì‹œ ëŠ¥ë ¥ ë¶€ì¡±"
                    },
                    "evaluation_questions": [
                        "ì¡°ì§ì˜ ë¯¸ë˜ ë¹„ì „ì„ ì–´ë–»ê²Œ ì„¤ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                        "ì‹œì¥ ë³€í™”ì— ëŒ€ì‘í•˜ëŠ” ì „ëµì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.25
                },
                {
                    "item_name": "ì¸ì„±ê³¼ ê°€ì¹˜ê´€",
                    "description": "ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                        "4ì ": "ì–‘í˜¸ - ì–‘í˜¸í•œ ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                        "3ì ": "ë³´í†µ - ì¼ë°˜ì ì¸ ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                        "2ì ": "ë¯¸í¡ - ì œí•œì ì¸ ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„±",
                        "1ì ": "ë¶€ì¡± - ìœ¤ë¦¬ì˜ì‹ê³¼ ì¡°ì§ ë¬¸í™” ì í•©ì„± ë¶€ì¡±"
                    },
                    "evaluation_questions": [
                        "ìœ¤ë¦¬ì  ë”œë ˆë§ˆ ìƒí™©ì„ ì–´ë–»ê²Œ í•´ê²°í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                        "ì¡°ì§ì˜ ê°€ì¹˜ê´€ê³¼ ë³¸ì¸ì˜ ê°€ì¹˜ê´€ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.25
                },
                {
                    "item_name": "ì„±ì¥ ì ì¬ë ¥",
                    "description": "ë¯¸ë˜ ì„±ì¥ ê°€ëŠ¥ì„±ê³¼ ë™ê¸°ë¶€ì—¬",
                    "max_score": 5,
                    "scoring_criteria": {
                        "5ì ": "ìš°ìˆ˜ - ë›°ì–´ë‚œ ì„±ì¥ ì ì¬ë ¥ê³¼ ê°•í•œ ë™ê¸°ë¶€ì—¬",
                        "4ì ": "ì–‘í˜¸ - ì–‘í˜¸í•œ ì„±ì¥ ì ì¬ë ¥ê³¼ ë™ê¸°ë¶€ì—¬",
                        "3ì ": "ë³´í†µ - ì¼ë°˜ì ì¸ ì„±ì¥ ì ì¬ë ¥ê³¼ ë™ê¸°ë¶€ì—¬",
                        "2ì ": "ë¯¸í¡ - ì œí•œì ì¸ ì„±ì¥ ì ì¬ë ¥ê³¼ ë™ê¸°ë¶€ì—¬",
                        "1ì ": "ë¶€ì¡± - ì„±ì¥ ì ì¬ë ¥ê³¼ ë™ê¸°ë¶€ì—¬ ë¶€ì¡±"
                    },
                    "evaluation_questions": [
                        "ì•ìœ¼ë¡œì˜ ì„±ì¥ ê³„íšì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ì´ ì§ë¬´ì— ì§€ì›í•œ ë™ê¸°ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"
                    ],
                    "weight": 0.20
                }
            ]
        
        # ì´ ê°€ì¤‘ì¹˜ì™€ ìµœëŒ€ ì ìˆ˜ ê³„ì‚°
        total_weight = sum(item.get("weight", 0) for item in evaluation_items)
        max_total_score = sum(item.get("max_score", 5) for item in evaluation_items)
        
        return InterviewEvaluationItemsResponse(
            interview_stage=request.interview_stage,
            evaluation_items=evaluation_items,
            total_weight=total_weight,
            max_total_score=max_total_score
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ì¤‘ì‹¬ APIë“¤ (DB ì €ì¥ ì—†ìŒ)
@router.post("/langgraph/interview-questions", response_model=Dict[str, Any])
async def generate_interview_questions_with_langgraph(request: IntegratedQuestionRequest, db: Session = Depends(get_db)):
    """ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        job_matching_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
                    job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name,
            applicant_name=request.name,
            interview_type="general",
            job_matching_info=job_matching_info
        )
        
        return {
            "success": True,
            "workflow_type": "interview_question_generation",
            "result": workflow_result,
            "executed_at": workflow_result.get("generated_at", "")
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "workflow_type": "interview_question_generation"
        }

@router.post("/langgraph/resume-analysis", response_model=Dict[str, Any])
async def generate_resume_analysis_with_langgraph(request: ResumeAnalysisRequest, db: Session = Depends(get_db)):
    """ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì´ë ¥ì„œ ë¶„ì„ (DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        job_matching_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
                    job_matching_info = analyze_job_matching(resume_text, job_info)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "",
            applicant_name=request.name or "",
            interview_type="general",
            job_matching_info=job_matching_info
        )
        
        return {
            "success": True,
            "workflow_type": "resume_analysis",
            "result": {
                "resume_analysis": workflow_result.get("resume_analysis", {}),
                "evaluation_tools": workflow_result.get("evaluation_tools", {})
            },
            "executed_at": workflow_result.get("generated_at", "")
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "workflow_type": "resume_analysis"
        }

@router.post("/langgraph/ai-interview", response_model=Dict[str, Any])
async def generate_ai_interview_with_langgraph(request: AiInterviewRequest, db: Session = Depends(get_db)):
    """ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ AI ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬",
            applicant_name=request.name or "",
            interview_type="ai"
        )
        
        return {
            "success": True,
            "workflow_type": "ai_interview_question_generation",
            "result": workflow_result,
            "executed_at": workflow_result.get("generated_at", "")
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "workflow_type": "ai_interview_question_generation"
        }

@router.post("/langgraph/evaluation-tools", response_model=Dict[str, Any])
async def generate_evaluation_tools_with_langgraph(request: AiToolsRequest, db: Session = Depends(get_db)):
    """ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ í‰ê°€ ë„êµ¬ ìƒì„± (DB ì €ì¥ ì—†ìŒ)"""
    try:
        # ì´ë ¥ì„œ ì •ë³´ ìˆ˜ì§‘
        resume = db.query(Resume).filter(Resume.id == request.resume_id).first()
        if not resume:
            raise HTTPException(status_code=404, detail="Resume not found")
        
        specs = db.query(Spec).filter(Spec.resume_id == request.resume_id).all()
        resume_text = combine_resume_and_specs(resume, specs)
        
        # ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
        job_info = ""
        if request.application_id:
            application = db.query(Application).filter(Application.id == request.application_id).first()
            if application:
                job_post = db.query(JobPost).filter(JobPost.id == application.job_post_id).first()
                if job_post:
                    job_info = parse_job_post_data(job_post)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../agent'))
        from agent.agents.interview_question_workflow import generate_comprehensive_interview_questions
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=request.company_name or "íšŒì‚¬",
            applicant_name=request.name or "",
            interview_type=request.interview_stage or "general"
        )
        
        return {
            "success": True,
            "workflow_type": "evaluation_tools_generation",
            "result": {
                "evaluation_tools": workflow_result.get("evaluation_tools", {}),
                "resume_analysis": workflow_result.get("resume_analysis", {})
            },
            "executed_at": workflow_result.get("generated_at", "")
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "workflow_type": "evaluation_tools_generation"
        }

# ë°±ê·¸ë¼ìš´ë“œ ì—ì´ì „íŠ¸ ì‹¤í–‰ APIë“¤
@router.post("/background/generate-interview-questions")
async def trigger_background_interview_questions_generation(request: IntegratedQuestionRequest, db: Session = Depends(get_db)):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± íŠ¸ë¦¬ê±°"""
    try:
        if not request.application_id:
            raise HTTPException(status_code=400, detail="application_idê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íŠ¸ë¦¬ê±°
        import asyncio
        from ..scheduler.langgraph_background_scheduler import generate_interview_questions_for_application_async
        
        # ë¹„ë™ê¸°ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰
        asyncio.create_task(generate_interview_questions_for_application_async(request.application_id))
        
        return {
            "success": True,
            "message": f"ì§€ì› {request.application_id}ì— ëŒ€í•œ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "task_type": "interview_questions_generation",
            "application_id": request.application_id
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "task_type": "interview_questions_generation"
        }

@router.post("/background/generate-resume-analysis")
async def trigger_background_resume_analysis_generation(request: ResumeAnalysisRequest, db: Session = Depends(get_db)):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì´ë ¥ì„œ ë¶„ì„ ìƒì„± íŠ¸ë¦¬ê±°"""
    try:
        if not request.application_id:
            raise HTTPException(status_code=400, detail="application_idê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íŠ¸ë¦¬ê±°
        import asyncio
        from ..scheduler.langgraph_background_scheduler import generate_resume_analysis_for_application_async
        
        # ë¹„ë™ê¸°ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰
        asyncio.create_task(generate_resume_analysis_for_application_async(request.application_id))
        
        return {
            "success": True,
            "message": f"ì§€ì› {request.application_id}ì— ëŒ€í•œ ì´ë ¥ì„œ ë¶„ì„ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "task_type": "resume_analysis_generation",
            "application_id": request.application_id
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "task_type": "resume_analysis_generation"
        }

@router.post("/background/generate-evaluation-tools")
async def trigger_background_evaluation_tools_generation(request: AiToolsRequest, db: Session = Depends(get_db)):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ í‰ê°€ ë„êµ¬ ìƒì„± íŠ¸ë¦¬ê±°"""
    try:
        if not request.application_id:
            raise HTTPException(status_code=400, detail="application_idê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íŠ¸ë¦¬ê±°
        import asyncio
        from ..scheduler.langgraph_background_scheduler import generate_evaluation_tools_for_application_async
        
        # ë¹„ë™ê¸°ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰
        asyncio.create_task(generate_evaluation_tools_for_application_async(request.application_id))
        
        return {
            "success": True,
            "message": f"ì§€ì› {request.application_id}ì— ëŒ€í•œ í‰ê°€ ë„êµ¬ ìƒì„±ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "task_type": "evaluation_tools_generation",
            "application_id": request.application_id
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "task_type": "evaluation_tools_generation"
        }

@router.get("/background/status/{application_id}")
async def get_background_task_status(application_id: int, db: Session = Depends(get_db)):
    """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìƒíƒœ í™•ì¸"""
    try:
        # DBì—ì„œ ìƒì„±ëœ ë°ì´í„° í™•ì¸
        questions_count = db.query(InterviewQuestion).filter(
            InterviewQuestion.application_id == application_id
        ).count()
        
        analysis_logs = db.query(InterviewQuestionLog).filter(
            InterviewQuestionLog.application_id == application_id,
            InterviewQuestionLog.interview_type.in_(["resume_analysis", "evaluation_tools"])
        ).count()
        
        return {
            "application_id": application_id,
            "status": {
                "interview_questions_generated": questions_count > 0,
                "questions_count": questions_count,
                "analysis_tools_generated": analysis_logs > 0,
                "analysis_logs_count": analysis_logs
            },
            "last_updated": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "application_id": application_id,
            "error": str(e),
            "status": "error"
        }

@router.get("/personal-questions/{application_id}")
def get_personal_questions(application_id: int, db: Session = Depends(get_db)):
    """ì €ì¥ëœ ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        print(f"ğŸ” ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ ì¡°íšŒ: application_id={application_id}")
        
        # ì§€ì›ì„œ ì •ë³´ í™•ì¸
        application = db.query(Application).filter(Application.id == application_id).first()
        if not application:
            print(f"âŒ Application not found: {application_id}")
            raise HTTPException(status_code=404, detail="Application not found")
        
        # ì €ì¥ëœ ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ ì¡°íšŒ
        personal_result = db.query(PersonalQuestionResult).filter(
            PersonalQuestionResult.application_id == application_id
        ).first()
        
        if not personal_result:
            print(f"âŒ Personal question result not found: {application_id}")
            raise HTTPException(status_code=404, detail="ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
        
        print(f"âœ… ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ ì¡°íšŒ ì™„ë£Œ: ID {personal_result.id}")
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        return {
            "application_id": personal_result.application_id,
            "jobpost_id": personal_result.jobpost_id,
            "company_id": personal_result.company_id,
            "questions": personal_result.questions,
            "question_bundle": personal_result.question_bundle,
            "job_matching_info": personal_result.job_matching_info,
            "analysis_version": personal_result.analysis_version,
            "analysis_duration": personal_result.analysis_duration,
            "created_at": personal_result.created_at,
            "updated_at": personal_result.updated_at
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ê°œì¸ ì§ˆë¬¸ ê²°ê³¼ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
