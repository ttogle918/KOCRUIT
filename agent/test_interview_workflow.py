#!/usr/bin/env python3
"""
LangGraph ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'agent'))

from agent.agents.interview_question_workflow import (
    generate_comprehensive_interview_questions,
    interview_workflow,
    executive_workflow,
    technical_workflow
)

def test_general_interview_workflow():
    """ì¼ë°˜ ë©´ì ‘ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    print("=== ì¼ë°˜ ë©´ì ‘ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    resume_text = """
    í™ê¸¸ë™
    ì„œìš¸ëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—… (2020-2024)
    GPA: 4.2/4.5
    
    ê²½ë ¥:
    - ë„¤ì´ë²„ í´ë¡œë°”íŒ€ ì¸í„´ (2023.06-2023.12)
      * ëŒ€í™”í˜• AI ëª¨ë¸ ê°œë°œ ë° ìµœì í™”
      * Python, TensorFlow, PyTorch ì‚¬ìš©
      * íŒ€ í”„ë¡œì íŠ¸ì—ì„œ 3ëª…ê³¼ í˜‘ì—…í•˜ì—¬ ì„±ëŠ¥ 15% í–¥ìƒ
    
    - ìŠ¤íƒ€íŠ¸ì—… í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ (2022.03-2022.12)
      * React, TypeScriptë¥¼ ì‚¬ìš©í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ
      * ì‚¬ìš©ì ê²½í—˜ ê°œì„ ìœ¼ë¡œ ì „í™˜ìœ¨ 20% ì¦ê°€
    
    ê¸°ìˆ  ìŠ¤íƒ:
    - ì–¸ì–´: Python, JavaScript, TypeScript, Java
    - í”„ë ˆì„ì›Œí¬: React, Node.js, Django, Spring Boot
    - ë°ì´í„°ë² ì´ìŠ¤: PostgreSQL, MongoDB, Redis
    - í´ë¼ìš°ë“œ: AWS, Docker, Kubernetes
    
    í”„ë¡œì íŠ¸:
    1. AI ê¸°ë°˜ ì±„ìš© ë§¤ì¹­ ì‹œìŠ¤í…œ (2023.09-2023.12)
       - LangChainê³¼ OpenAI APIë¥¼ í™œìš©í•œ ì´ë ¥ì„œ ë¶„ì„ ì‹œìŠ¤í…œ
       - ì§€ì›ì-ì§ë¬´ ë§¤ì¹­ ì •í™•ë„ 85% ë‹¬ì„±
       - íŒ€ ë¦¬ë”ë¡œì„œ 5ëª…ê³¼ í˜‘ì—…
    
    2. ì‹¤ì‹œê°„ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ (2022.06-2022.09)
       - WebSocketì„ í™œìš©í•œ ì‹¤ì‹œê°„ ë©”ì‹œì§• ì‹œìŠ¤í…œ
       - Reactì™€ Node.jsë¡œ í’€ìŠ¤íƒ ê°œë°œ
       - 1000ëª… ë™ì‹œ ì ‘ì†ì ì²˜ë¦¬ ê°€ëŠ¥
    """
    
    job_info = """
    ë°±ì—”ë“œ ê°œë°œì (ì‹ ì…/ê²½ë ¥)
    
    ì£¼ìš” ì—…ë¬´:
    - ëŒ€ê·œëª¨ ì›¹ ì„œë¹„ìŠ¤ ë°±ì—”ë“œ ê°œë°œ ë° ìš´ì˜
    - API ì„¤ê³„ ë° êµ¬í˜„
    - ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° ìµœì í™”
    - ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ êµ¬ì¶•
    
    ìê²© ìš”ê±´:
    - ì»´í“¨í„°ê³µí•™ ë˜ëŠ” ê´€ë ¨ ì „ê³µ
    - Python, Java, Node.js ì¤‘ í•˜ë‚˜ ì´ìƒ ìˆ™ë ¨
    - ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° SQL ëŠ¥ìˆ™
    - Gitì„ í™œìš©í•œ í˜‘ì—… ê²½í—˜
    
    ìš°ëŒ€ì‚¬í•­:
    - í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤(AWS, GCP, Azure) ê²½í—˜
    - Docker, Kubernetes ê²½í—˜
    - ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ê²½í—˜
    - AI/ML ê´€ë ¨ í”„ë¡œì íŠ¸ ê²½í—˜
    """
    
    company_name = "ë„¤ì´ë²„"
    applicant_name = "í™ê¸¸ë™"
    
    try:
        result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name=company_name,
            applicant_name=applicant_name,
            interview_type="general"
        )
        
        print(f"ë©´ì ‘ ìœ í˜•: {result.get('interview_type')}")
        print(f"ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜: {result.get('total_questions')}")
        print(f"ìƒì„± ì‹œê°„: {result.get('generated_at')}")
        
        print("\n=== ìƒì„±ëœ ì§ˆë¬¸ë“¤ ===")
        questions = result.get('questions', [])
        for i, question in enumerate(questions[:10], 1):  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"{i}. {question}")
        
        if len(questions) > 10:
            print(f"... ì™¸ {len(questions) - 10}ê°œ ì§ˆë¬¸")
        
        print("\n=== ì§ˆë¬¸ ë²ˆë“¤ ===")
        question_bundle = result.get('question_bundle', {})
        for category, content in question_bundle.items():
            if isinstance(content, dict):
                print(f"\n{category}:")
                for subcategory, subcontent in content.items():
                    if isinstance(subcontent, list):
                        print(f"  - {subcategory}: {len(subcontent)}ê°œ ì§ˆë¬¸")
                    else:
                        print(f"  - {subcategory}: {subcontent}")
            elif isinstance(content, list):
                print(f"\n{category}: {len(content)}ê°œ ì§ˆë¬¸")
            else:
                print(f"\n{category}: {content}")
        
        print("\n=== í‰ê°€ ë„êµ¬ ===")
        evaluation_tools = result.get('evaluation_tools', {})
        for tool_name, tool_content in evaluation_tools.items():
            if isinstance(tool_content, dict):
                print(f"\n{tool_name}:")
                for key, value in tool_content.items():
                    if isinstance(value, list):
                        print(f"  - {key}: {len(value)}ê°œ í•­ëª©")
                    else:
                        print(f"  - {key}: {value}")
            else:
                print(f"\n{tool_name}: {tool_content}")
        
        return True
        
    except Exception as e:
        print(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_executive_interview_workflow():
    """ì„ì›ë©´ì ‘ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    print("\n=== ì„ì›ë©´ì ‘ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===")
    
    resume_text = """
    ê¹€ëŒ€í‘œ
    ì„œìš¸ëŒ€í•™êµ ê²½ì˜í•™ê³¼ ì¡¸ì—… (2010-2014)
    í•˜ë²„ë“œ ê²½ì˜ëŒ€í•™ì› MBA (2016-2018)
    
    ê²½ë ¥:
    - êµ¬ê¸€ í•œêµ­ ì§€ì‚¬ Product Manager (2018-2023)
      * AI ê¸°ë°˜ ì œí’ˆ ì „ëµ ìˆ˜ë¦½ ë° ì‹¤í–‰
      * ì—°ê°„ ë§¤ì¶œ 500ì–µì› ê·œëª¨ ì œí’ˆ ë‹´ë‹¹
      * 50ëª… ê·œëª¨ì˜ í¬ë¡œìŠ¤í‘ì…”ë„ íŒ€ ë¦¬ë“œ
    
    - ìŠ¤íƒ€íŠ¸ì—… CTO (2014-2016)
      * ê¸°ìˆ íŒ€ 30ëª… ê´€ë¦¬
      * ì œí’ˆ ê°œë°œ ë° ê¸°ìˆ  ì „ëµ ìˆ˜ë¦½
      * ì‹œë¦¬ì¦ˆ A íˆ¬ì ìœ ì¹˜ ì„±ê³µ
    
    ì£¼ìš” ì„±ê³¼:
    - êµ¬ê¸€ì—ì„œ AI ì œí’ˆ ë§¤ì¶œ 200% ì„±ì¥ ì£¼ë„
    - ìŠ¤íƒ€íŠ¸ì—…ì—ì„œ 1000ë§Œ ì‚¬ìš©ì í™•ë³´
    - ê¸°ìˆ  íŠ¹í—ˆ 5ê±´ ì¶œì›
    """
    
    job_info = """
    CTO (Chief Technology Officer)
    
    ì£¼ìš” ì—…ë¬´:
    - íšŒì‚¬ ì „ì²´ ê¸°ìˆ  ì „ëµ ìˆ˜ë¦½ ë° ì‹¤í–‰
    - ê¸°ìˆ íŒ€ ì¡°ì§ ê´€ë¦¬ ë° ë¦¬ë”ì‹­
    - ì œí’ˆ ê°œë°œ ë¡œë“œë§µ ìˆ˜ë¦½
    - ê¸°ìˆ ì  ì˜ì‚¬ê²°ì • ë° ì•„í‚¤í…ì²˜ ì„¤ê³„
    
    ìê²© ìš”ê±´:
    - 10ë…„ ì´ìƒì˜ ê¸°ìˆ  ê²½ë ¥
    - ëŒ€ê·œëª¨ ì¡°ì§ ê´€ë¦¬ ê²½í—˜
    - ì œí’ˆ ê°œë°œ ë° ê¸°ìˆ  ì „ëµ ìˆ˜ë¦½ ê²½í—˜
    - MBA ë˜ëŠ” ê´€ë ¨ ê²½ì˜ ê²½í—˜
    
    ìš°ëŒ€ì‚¬í•­:
    - AI/ML ë¶„ì•¼ ì „ë¬¸ì„±
    - ìŠ¤íƒ€íŠ¸ì—… ê²½í—˜
    - íˆ¬ì ìœ ì¹˜ ê²½í—˜
    - ê¸€ë¡œë²Œ ì‹œì¥ ê²½í—˜
    """
    
    try:
        result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name="í…Œí¬ìŠ¤íƒ€íŠ¸ì—…",
            applicant_name="ê¹€ëŒ€í‘œ",
            interview_type="executive"
        )
        
        print(f"ë©´ì ‘ ìœ í˜•: {result.get('interview_type')}")
        print(f"ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜: {result.get('total_questions')}")
        
        print("\n=== ì„ì›ë©´ì ‘ ì§ˆë¬¸ë“¤ ===")
        questions = result.get('questions', [])
        for i, question in enumerate(questions[:5], 1):  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"{i}. {question}")
        
        return True
        
    except Exception as e:
        print(f"ì„ì›ë©´ì ‘ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def test_technical_interview_workflow():
    """ê¸°ìˆ ë©´ì ‘ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    print("\n=== ê¸°ìˆ ë©´ì ‘ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===")
    
    resume_text = """
    ë°•ê¸°ìˆ 
    ì¹´ì´ìŠ¤íŠ¸ ì „ì‚°í•™ê³¼ ì¡¸ì—… (2019-2023)
    GPA: 4.3/4.5
    
    ê²½ë ¥:
    - ì¹´ì¹´ì˜¤ AIíŒ€ ì—°êµ¬ê°œë°œ (2023.03-í˜„ì¬)
      * ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì—°êµ¬ ë° ê°œë°œ
      * PyTorch, TensorFlowë¥¼ í™œìš©í•œ ëª¨ë¸ ìµœì í™”
      * ë…¼ë¬¸ 3í¸ ë°œí‘œ (ICLR, NeurIPS, ACL)
    
    ê¸°ìˆ  ìŠ¤íƒ:
    - ì–¸ì–´: Python, C++, CUDA
    - í”„ë ˆì„ì›Œí¬: PyTorch, TensorFlow, JAX
    - í´ë¼ìš°ë“œ: AWS, GCP
    - ë„êµ¬: Docker, Kubernetes, Git
    
    í”„ë¡œì íŠ¸:
    1. í•œêµ­ì–´ íŠ¹í™” ì–¸ì–´ ëª¨ë¸ ê°œë°œ (2023.06-2023.12)
       - 10B íŒŒë¼ë¯¸í„° ê·œëª¨ ëª¨ë¸ í•™ìŠµ
       - í•œêµ­ì–´ ì„±ëŠ¥ SOTA ë‹¬ì„±
       - íŒ€ ë¦¬ë”ë¡œì„œ 8ëª…ê³¼ í˜‘ì—…
    
    2. ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œìŠ¤í…œ (2022.09-2023.02)
       - TensorFlow Servingì„ í™œìš©í•œ ì‹¤ì‹œê°„ ì¶”ì²œ
       - ì‘ë‹µ ì‹œê°„ 10ms ì´í•˜ ë‹¬ì„±
       - ì •í™•ë„ 95% ë‹¬ì„±
    """
    
    job_info = """
    AI/ML ì—”ì§€ë‹ˆì–´ (ê²½ë ¥)
    
    ì£¼ìš” ì—…ë¬´:
    - ëŒ€ê·œëª¨ AI ëª¨ë¸ ê°œë°œ ë° ìµœì í™”
    - ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
    - ì—°êµ¬ ê²°ê³¼ë¥¼ ì œí’ˆì— ì ìš©
    - AI ì¸í”„ë¼ ì„¤ê³„ ë° ìš´ì˜
    
    ìê²© ìš”ê±´:
    - ì»´í“¨í„°ê³µí•™ ë˜ëŠ” ê´€ë ¨ ì „ê³µ
    - Python, PyTorch/TensorFlow ìˆ™ë ¨
    - ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ì´í•´
    - ë…¼ë¬¸ ë°œí‘œ ë˜ëŠ” ì—°êµ¬ ê²½í—˜
    
    ìš°ëŒ€ì‚¬í•­:
    - ëŒ€ê·œëª¨ ëª¨ë¸ í•™ìŠµ ê²½í—˜
    - ë…¼ë¬¸ ë°œí‘œ ê²½í—˜
    - í´ë¼ìš°ë“œ ì¸í”„ë¼ ê²½í—˜
    - ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ ê²½í—˜
    """
    
    try:
        result = generate_comprehensive_interview_questions(
            resume_text=resume_text,
            job_info=job_info,
            company_name="AIìŠ¤íƒ€íŠ¸ì—…",
            applicant_name="ë°•ê¸°ìˆ ",
            interview_type="second"  # ê¸°ìˆ ë©´ì ‘ì€ 2ì°¨ ë©´ì ‘ìœ¼ë¡œ ì„¤ì •
        )
        
        print(f"ë©´ì ‘ ìœ í˜•: {result.get('interview_type')}")
        print(f"ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜: {result.get('total_questions')}")
        
        print("\n=== ê¸°ìˆ ë©´ì ‘ ì§ˆë¬¸ë“¤ ===")
        questions = result.get('questions', [])
        for i, question in enumerate(questions[:5], 1):  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"{i}. {question}")
        
        return True
        
    except Exception as e:
        print(f"ê¸°ìˆ ë©´ì ‘ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("LangGraph ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ê° ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tests = [
        ("ì¼ë°˜ ë©´ì ‘", test_general_interview_workflow),
        ("ì„ì›ë©´ì ‘", test_executive_interview_workflow),
        ("ê¸°ìˆ ë©´ì ‘", test_technical_interview_workflow)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"{test_name} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
            results.append((test_name, False))
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
    print("=" * 60)
    
    for test_name, success in results:
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        print(f"{test_name}: {status}")
    
    success_count = sum(1 for _, success in results if success)
    total_count = len(results)
    
    print(f"\nì „ì²´ ê²°ê³¼: {success_count}/{total_count} ì„±ê³µ")
    
    if success_count == total_count:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 