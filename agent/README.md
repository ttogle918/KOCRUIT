# ğŸ¤– Kocruit AI Agent

> **LangGraph ê¸°ë°˜ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ**

## ğŸ“‹ ê°œìš”

Kocruitì˜ AI AgentëŠ” LangGraphë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ë ¥ì„œ ë¶„ì„, ë©´ì ‘ í‰ê°€, ì§ˆë¬¸ ìƒì„± ë“± ì±„ìš© í”„ë¡œì„¸ìŠ¤ì˜ í•µì‹¬ AI ê¸°ëŠ¥ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

- **Framework**: FastAPI + LangGraph
- **LLM**: OpenAI GPT-4
- **Vector DB**: ChromaDB
- **Computer Vision**: MediaPipe
- **Speech Processing**: SpeechRecognition
- **Caching**: Redis
- **Workflow**: LangGraph StateGraph

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
agent/
â”œâ”€â”€ agents/              # AI ì—ì´ì „íŠ¸ë“¤
â”‚   â”œâ”€â”€ ai_interview_workflow.py
â”‚   â”œâ”€â”€ interview_question_workflow.py
â”‚   â”œâ”€â”€ application_evaluation_agent.py
â”‚   â”œâ”€â”€ chatbot_graph.py
â”‚   â””â”€â”€ graph_agent.py
â”œâ”€â”€ tools/               # AI ë„êµ¬ë“¤
â”‚   â”œâ”€â”€ resume_tools/
â”‚   â”œâ”€â”€ interview_tools/
â”‚   â””â”€â”€ evaluation_tools/
â”œâ”€â”€ utils/               # ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ data/                # í•™ìŠµ ë°ì´í„°
â””â”€â”€ main.py              # ë©”ì¸ ì„œë²„
```

## ğŸš€ ì£¼ìš” ì—ì´ì „íŠ¸

### ğŸ¤ AI ë©´ì ‘ ì—ì´ì „íŠ¸
**íŒŒì¼**: `agents/ai_interview_workflow.py`

**ê¸°ëŠ¥**:
- ë¹„ë””ì˜¤ ì—…ë¡œë“œ ë° ë¶„ì„
- MediaPipeë¥¼ í†µí•œ í‘œì •/ìì„¸ ë¶„ì„
- ìŒì„± ì¸ì‹ ë° ê°ì • ë¶„ì„
- ì‹¤ì‹œê°„ í‰ê°€ ë° í”¼ë“œë°±

**ì›Œí¬í”Œë¡œìš°**:
```python
initialize_session â†’ generate_scenario_questions â†’ 
start_real_time_analysis â†’ process_audio_analysis â†’ 
process_behavior_analysis â†’ process_game_test â†’ 
calculate_final_score
```

### â“ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì—ì´ì „íŠ¸
**íŒŒì¼**: `agents/interview_question_workflow.py`

**ê¸°ëŠ¥**:
- ì±„ìš©ê³µê³  ìš”êµ¬ì‚¬í•­ ë¶„ì„
- ì§€ì›ì ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„
- ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„±
- ì§ˆë¬¸ ë‚œì´ë„ ë° íƒ€ì… ë¶„ë¥˜

**ì›Œí¬í”Œë¡œìš°**:
```python
analyze_requirements â†’ analyze_portfolio â†’ 
analyze_resume â†’ generate_questions â†’ 
evaluate_questions â†’ result_integrator
```

### ğŸ“Š ì§€ì›ì„œ í‰ê°€ ì—ì´ì „íŠ¸
**íŒŒì¼**: `agents/application_evaluation_agent.py`

**ê¸°ëŠ¥**:
- ì´ë ¥ì„œ ì ìˆ˜ ê³„ì‚°
- í†µê³¼/ë¶ˆí•©ê²© ì‚¬ìœ  ìƒì„±
- ê²½ìŸë ¥ ë¹„êµ ë¶„ì„
- í‚¤ì›Œë“œ ë§¤ì¹­ í‰ê°€

### ğŸ’¬ ì±—ë´‡ ì—ì´ì „íŠ¸
**íŒŒì¼**: `agents/chatbot_graph.py`

**ê¸°ëŠ¥**:
- ìì—°ì–´ ëŒ€í™” ì²˜ë¦¬
- RAG ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€
- ì»¨í…ìŠ¤íŠ¸ ê¸°ì–µ ë° ê´€ë¦¬
- ë©€í‹°í„´ ëŒ€í™” ì§€ì›

## ğŸ”§ AI ë„êµ¬ë“¤

### ğŸ“ ì´ë ¥ì„œ ë¶„ì„ ë„êµ¬
```python
# tools/resume_tools/
- comprehensive_analysis_tool.py    # ì¢…í•© ë¶„ì„
- detailed_analysis_tool.py         # ìƒì„¸ ë¶„ì„
- competitiveness_comparison_tool.py # ê²½ìŸë ¥ ë¹„êµ
- keyword_matching_tool.py          # í‚¤ì›Œë“œ ë§¤ì¹­
- highlight_tool.py                 # í˜•ê´‘íœ í•˜ì´ë¼ì´íŒ…
```

### ğŸ¤ ë©´ì ‘ ë„êµ¬ë“¤
```python
# tools/interview_tools/
- video_analysis_tool.py            # ë¹„ë””ì˜¤ ë¶„ì„
- audio_analysis_tool.py            # ì˜¤ë””ì˜¤ ë¶„ì„
- emotion_analysis_tool.py          # ê°ì • ë¶„ì„
- speaker_diarization_tool.py       # í™”ì ë¶„ë¦¬
```

### ğŸ“Š í‰ê°€ ë„êµ¬ë“¤
```python
# tools/evaluation_tools/
- scoring_tool.py                   # ì ìˆ˜ ê³„ì‚°
- ranking_tool.py                   # ìˆœìœ„ ë§¤ê¸°ê¸°
- feedback_generator_tool.py        # í”¼ë“œë°± ìƒì„±
- report_generator_tool.py          # ë¦¬í¬íŠ¸ ìƒì„±
```

## ğŸ§  RAG ì‹œìŠ¤í…œ

### ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
- **ChromaDB**: ì„ë² ë”© ë²¡í„° ì €ì¥
- **ì„ë² ë”© ëª¨ë¸**: OpenAI text-embedding-ada-002
- **ë©”íƒ€ë°ì´í„°**: ë¬¸ì„œ ì •ë³´ ë° íƒœê·¸ ê´€ë¦¬

### ê²€ìƒ‰ ë° ê²€ìƒ‰
```python
# RAG ì›Œí¬í”Œë¡œìš°
1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
2. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
3. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
4. ì»¨í…ìŠ¤íŠ¸ ì¦ê°•
5. LLM ì‘ë‹µ ìƒì„±
```

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### 1. í™˜ê²½ ì„¤ì •
```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„±
echo "OPENAI_API_KEY=your-openai-key" > .env
echo "REDIS_URL=redis://localhost:6379" >> .env
echo "CHROMA_PERSIST_DIRECTORY=./chroma_db" >> .env
```

### 3. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
```bash
# ChromaDB ì´ˆê¸°í™”
python -c "from utils.vector_store import init_vector_store; init_vector_store()"

# í•™ìŠµ ë°ì´í„° ë¡œë“œ
python -c "from utils.data_loader import load_training_data; load_training_data()"
```

### 4. ì„œë²„ ì‹¤í–‰
```bash
# ê°œë°œ ì„œë²„ ì‹¤í–‰
python main.py

# í”„ë¡œë•ì…˜ ì„œë²„ ì‹¤í–‰
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker
```

### 5. Dockerë¡œ ì‹¤í–‰
```bash
# Docker ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t kocruit-agent .

# Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -p 8001:8001 --env-file .env kocruit-agent
```

## ğŸ”„ LangGraph ì›Œí¬í”Œë¡œìš°

### ìƒíƒœ ê´€ë¦¬
```python
# StateGraph ì •ì˜
workflow = StateGraph(Dict[str, Any])

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("node_name", node_function)

# ì—£ì§€ ì—°ê²°
workflow.add_edge("start", "end")

# ì»´íŒŒì¼
compiled_workflow = workflow.compile()
```

### ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
# ëŒ€í™” ë©”ëª¨ë¦¬
memory = ConversationBufferMemory()

# ì„¸ì…˜ ë©”ëª¨ë¦¬
session_memory = SessionMemory(session_id)

# ì˜êµ¬ ë©”ëª¨ë¦¬
persistent_memory = PersistentMemory()
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### ìºì‹± ì „ëµ
```python
# LLM ê²°ê³¼ ìºì‹±
@cache_llm_result
def analyze_resume(resume_text: str) -> Dict:
    # ë¶„ì„ ë¡œì§
    pass

# Redis ìºì‹±
@redis_cache(expire=3600)
def get_embeddings(text: str) -> List[float]:
    # ì„ë² ë”© ìƒì„±
    pass
```

### ë³‘ë ¬ ì²˜ë¦¬
```python
# ë¹„ë™ê¸° ì²˜ë¦¬
async def process_multiple_documents(documents: List[str]):
    tasks = [analyze_document(doc) for doc in documents]
    results = await asyncio.gather(*tasks)
    return results
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```bash
# ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸
pytest tests/agents/

# ë„êµ¬ í…ŒìŠ¤íŠ¸
pytest tests/tools/

# ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
pytest tests/workflows/
```

### í†µí•© í…ŒìŠ¤íŠ¸
```bash
# ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
pytest tests/integration/

# API í…ŒìŠ¤íŠ¸
pytest tests/api/
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§

### ë¡œê¹…
```python
# êµ¬ì¡°í™”ëœ ë¡œê¹…
import structlog

logger = structlog.get_logger()

logger.info("Agent started", 
           agent_type="interview", 
           session_id=session_id)
```

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘
```python
# ì„±ëŠ¥ ë©”íŠ¸ë¦­
from prometheus_client import Counter, Histogram

request_count = Counter('agent_requests_total', 'Total requests')
request_duration = Histogram('agent_request_duration_seconds', 'Request duration')
```

## ğŸ”’ ë³´ì•ˆ

### API í‚¤ ê´€ë¦¬
```python
# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
import os
from dotenv import load_dotenv

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
```

### ë°ì´í„° ë³´í˜¸
```python
# ë¯¼ê°í•œ ë°ì´í„° ë§ˆìŠ¤í‚¹
def mask_sensitive_data(text: str) -> str:
    # ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ ë¡œì§
    pass
```

## ğŸš€ ë°°í¬

### Docker Compose
```yaml
# docker-compose.yml
version: '3.8'
services:
  agent:
    build: .
    ports:
      - "8001:8001"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
```

### Kubernetes
```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kocruit-agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kocruit-agent
  template:
    spec:
      containers:
      - name: agent
        image: kocruit-agent:latest
        ports:
        - containerPort: 8001
```

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.
